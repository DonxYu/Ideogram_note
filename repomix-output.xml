This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where line numbers have been added.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: modules/**/*.py, backend/**/*.py, frontend/src/components/blocks/**/*.tsx, frontend/src/store/**/*.ts, frontend/src/lib/**/*.ts, frontend/src/app/page.tsx, frontend/src/app/layout.tsx, frontend/src/app/globals.css, data/personas.json, requirements.txt, backend/requirements.txt, frontend/package.json, README.md
- Files matching these patterns are excluded: **/__pycache__/**, **/*.pyc, **/node_modules/**, **/.next/**, **/output/**, **/*.db, **/*.log, **/repomix-output.*
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Line numbers have been added to the beginning of each line
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
backend/
  routers/
    __init__.py
    config.py
    content.py
    media.py
    topics.py
    video.py
  main.py
  requirements.txt
data/
  personas.json
frontend/
  src/
    app/
      globals.css
      layout.tsx
      page.tsx
    components/
      blocks/
        ContentPreview.tsx
        MediaStudio.tsx
        PersonaConfig.tsx
        TopicRadar.tsx
    lib/
      api.ts
      progress-utils.ts
      utils.ts
    store/
      workflow.ts
  package.json
modules/
  __init__.py
  audio.py
  crawler.py
  editor.py
  md_exporter.py
  monitor.py
  painter.py
  persona.py
  quality_checker.py
  storage.py
  trend.py
  utils.py
  writer.py
README.md
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="backend/routers/__init__.py">
1: # Backend Routers
</file>

<file path="backend/routers/video.py">
  1: """
  2: 视频合成 API
  3: """
  4: import os
  5: from pathlib import Path
  6: from typing import List, Optional
  7: 
  8: from fastapi import APIRouter, HTTPException
  9: from pydantic import BaseModel
 10: 
 11: from modules.editor import create_video, get_total_duration, generate_srt
 12: 
 13: router = APIRouter()
 14: 
 15: ROOT_DIR = Path(__file__).parent.parent.parent
 16: 
 17: 
 18: class SceneForVideo(BaseModel):
 19:     narration: str = ""
 20: 
 21: 
 22: class CreateVideoRequest(BaseModel):
 23:     image_paths: List[str]
 24:     audio_paths: List[str]
 25:     scenes: Optional[List[SceneForVideo]] = None  # 用于生成字幕
 26:     bgm_path: Optional[str] = None
 27:     bgm_volume: float = 0.12
 28:     topic: Optional[str] = None
 29: 
 30: 
 31: class VideoResponse(BaseModel):
 32:     video_path: Optional[str] = None
 33:     video_url: Optional[str] = None
 34:     srt_path: Optional[str] = None
 35:     srt_url: Optional[str] = None
 36:     duration: float = 0.0
 37:     error: Optional[str] = None
 38: 
 39: 
 40: class DurationRequest(BaseModel):
 41:     audio_paths: List[str]
 42: 
 43: 
 44: class DurationResponse(BaseModel):
 45:     total_duration: float
 46: 
 47: 
 48: def _path_to_url(path: str, media_type: str) -> Optional[str]:
 49:     """将本地路径转换为静态文件 URL"""
 50:     if not path or not os.path.exists(path):
 51:         return None
 52:     
 53:     output_dir = ROOT_DIR / "output" / media_type
 54:     try:
 55:         # 将两个路径都转为绝对路径再比较
 56:         abs_path = Path(path).resolve()
 57:         abs_output_dir = output_dir.resolve()
 58:         rel_path = abs_path.relative_to(abs_output_dir)
 59:         return f"/static/{media_type}/{rel_path}"
 60:     except ValueError:
 61:         return f"/static/{media_type}/{Path(path).name}"
 62: 
 63: 
 64: @router.post("/create", response_model=VideoResponse)
 65: async def create_video_endpoint(req: CreateVideoRequest):
 66:     """
 67:     合成视频（画音同步 + Ken Burns + BGM）
 68:     """
 69:     if not req.image_paths or not req.audio_paths:
 70:         raise HTTPException(status_code=400, detail="图片和音频路径列表不能为空")
 71:     
 72:     if len(req.image_paths) != len(req.audio_paths):
 73:         raise HTTPException(status_code=400, detail="图片和音频数量必须一致")
 74:     
 75:     # 验证文件存在
 76:     missing_images = [p for p in req.image_paths if not os.path.exists(p)]
 77:     missing_audio = [p for p in req.audio_paths if not os.path.exists(p)]
 78:     
 79:     if missing_images:
 80:         raise HTTPException(status_code=400, detail=f"图片文件不存在: {missing_images}")
 81:     if missing_audio:
 82:         raise HTTPException(status_code=400, detail=f"音频文件不存在: {missing_audio}")
 83:     
 84:     try:
 85:         # 转换 scenes 格式
 86:         scenes = None
 87:         if req.scenes:
 88:             scenes = [{"narration": s.narration} for s in req.scenes]
 89:         
 90:         # 调用视频合成
 91:         video_path = create_video(
 92:             image_paths=req.image_paths,
 93:             audio_paths=req.audio_paths,
 94:             bgm_path=req.bgm_path,
 95:             bgm_volume=req.bgm_volume,
 96:             scenes=scenes,
 97:             topic=req.topic,
 98:         )
 99:         
100:         if not video_path or not os.path.exists(video_path):
101:             return VideoResponse(error="视频合成失败")
102:         
103:         # 获取时长
104:         duration = get_total_duration(req.audio_paths)
105:         
106:         # SRT 路径
107:         srt_path = video_path.rsplit(".", 1)[0] + ".srt"
108:         srt_exists = os.path.exists(srt_path)
109:         
110:         return VideoResponse(
111:             video_path=video_path,
112:             video_url=_path_to_url(video_path, "video"),
113:             srt_path=srt_path if srt_exists else None,
114:             srt_url=_path_to_url(srt_path, "video") if srt_exists else None,
115:             duration=duration,
116:         )
117:         
118:     except Exception as e:
119:         raise HTTPException(status_code=500, detail=f"视频合成失败: {str(e)}")
120: 
121: 
122: @router.post("/duration", response_model=DurationResponse)
123: async def get_duration(req: DurationRequest):
124:     """
125:     计算音频总时长
126:     """
127:     try:
128:         duration = get_total_duration(req.audio_paths)
129:         return DurationResponse(total_duration=duration)
130:     except Exception as e:
131:         raise HTTPException(status_code=500, detail=f"计算时长失败: {str(e)}")
132: 
133: 
134: @router.get("/bgm")
135: async def list_bgm():
136:     """
137:     获取可用的 BGM 列表
138:     """
139:     bgm_dir = ROOT_DIR / "assets/bgm"
140:     if not bgm_dir.exists():
141:         return {"bgm_list": []}
142:     
143:     bgm_files = []
144:     for ext in ["*.mp3", "*.wav", "*.m4a"]:
145:         bgm_files.extend(bgm_dir.glob(ext))
146:     
147:     return {
148:         "bgm_list": [
149:             {
150:                 "name": f.stem,
151:                 "filename": f.name,
152:                 "path": str(f),
153:             }
154:             for f in sorted(bgm_files)
155:         ]
156:     }
</file>

<file path="backend/main.py">
 1: """
 2: FastAPI 后端入口
 3: 提供 REST API 封装现有 Python modules
 4: """
 5: import os
 6: import sys
 7: from pathlib import Path
 8: from contextlib import asynccontextmanager
 9: 
10: from fastapi import FastAPI
11: from fastapi.middleware.cors import CORSMiddleware
12: from fastapi.staticfiles import StaticFiles
13: from dotenv import load_dotenv
14: 
15: # 添加项目根目录到 Python 路径，以便 import modules
16: ROOT_DIR = Path(__file__).parent.parent
17: sys.path.insert(0, str(ROOT_DIR))
18: 
19: load_dotenv(ROOT_DIR / ".env")
20: 
21: from backend.routers import topics, content, media, video, config
22: 
23: 
24: @asynccontextmanager
25: async def lifespan(app: FastAPI):
26:     """应用生命周期管理"""
27:     # 启动时：确保输出目录存在
28:     (ROOT_DIR / "output/images").mkdir(parents=True, exist_ok=True)
29:     (ROOT_DIR / "output/audio").mkdir(parents=True, exist_ok=True)
30:     (ROOT_DIR / "output/video").mkdir(parents=True, exist_ok=True)
31:     print("[Backend] 输出目录已就绪")
32:     yield
33:     # 关闭时清理（如需要）
34: 
35: 
36: app = FastAPI(
37:     title="小红书内容工作流 API",
38:     description="Notion 风格 UI 的后端 API 服务",
39:     version="2.0.0",
40:     lifespan=lifespan,
41: )
42: 
43: # CORS 配置（允许本地开发）
44: app.add_middleware(
45:     CORSMiddleware,
46:     allow_origins=[
47:         "http://localhost:3000",
48:         "http://127.0.0.1:3000",
49:         "http://localhost:3001",
50:         "http://localhost:3002",
51:         "http://127.0.0.1:3002",
52:     ],
53:     allow_credentials=True,
54:     allow_methods=["*"],
55:     allow_headers=["*"],
56: )
57: 
58: # 挂载静态文件（输出的图片/音频/视频）
59: app.mount("/static/images", StaticFiles(directory=str(ROOT_DIR / "output/images")), name="images")
60: app.mount("/static/audio", StaticFiles(directory=str(ROOT_DIR / "output/audio")), name="audio")
61: app.mount("/static/video", StaticFiles(directory=str(ROOT_DIR / "output/video")), name="video")
62: 
63: # 注册路由
64: app.include_router(topics.router, prefix="/api/topics", tags=["选题分析"])
65: app.include_router(content.router, prefix="/api/content", tags=["内容生成"])
66: app.include_router(media.router, prefix="/api/media", tags=["素材生成"])
67: app.include_router(video.router, prefix="/api/video", tags=["视频合成"])
68: app.include_router(config.router, prefix="/api/config", tags=["配置"])
69: 
70: 
71: @app.get("/")
72: async def root():
73:     return {"message": "小红书内容工作流 API", "version": "2.0.0"}
74: 
75: 
76: @app.get("/health")
77: async def health_check():
78:     """健康检查"""
79:     return {
80:         "status": "ok",
81:         "openrouter": bool(os.getenv("OPENROUTER_API_KEY")),
82:         "replicate": bool(os.getenv("REPLICATE_API_TOKEN")),
83:         "ark": bool(os.getenv("ARK_API_KEY")),
84:         "volc_tts": bool(os.getenv("VOLC_TTS_APPID")),
85:     }
86: 
87: 
88: if __name__ == "__main__":
89:     import uvicorn
90:     uvicorn.run("main:app", host="0.0.0.0", port=8501, reload=True)
</file>

<file path="backend/requirements.txt">
 1: # FastAPI Backend
 2: fastapi>=0.109.0
 3: uvicorn[standard]>=0.27.0
 4: python-multipart>=0.0.6
 5: pydantic>=2.5.0
 6: 
 7: # Async SSE
 8: sse-starlette>=1.8.0
 9: 
10: # CORS
11: python-dotenv>=1.0.0
12: 
13: # Forward compatibility with existing modules
14: openai>=1.12.0
15: replicate>=0.23.0
16: requests>=2.31.0
17: edge-tts>=6.1.10
18: moviepy>=2.0.0
19: Pillow>=10.2.0
20: oss2>=2.18.0
</file>

<file path="frontend/src/app/globals.css">
  1: @import "tailwindcss";
  2: @import "tw-animate-css";
  3: 
  4: @custom-variant dark (&:is(.dark *));
  5: 
  6: /* ========== Notion-like Design System ========== */
  7: 
  8: @theme inline {
  9:   --color-background: var(--background);
 10:   --color-foreground: var(--foreground);
 11:   --font-sans: var(--font-geist-sans);
 12:   --font-mono: var(--font-geist-mono);
 13:   --color-sidebar-ring: var(--sidebar-ring);
 14:   --color-sidebar-border: var(--sidebar-border);
 15:   --color-sidebar-accent-foreground: var(--sidebar-accent-foreground);
 16:   --color-sidebar-accent: var(--sidebar-accent);
 17:   --color-sidebar-primary-foreground: var(--sidebar-primary-foreground);
 18:   --color-sidebar-primary: var(--sidebar-primary);
 19:   --color-sidebar-foreground: var(--sidebar-foreground);
 20:   --color-sidebar: var(--sidebar);
 21:   --color-chart-5: var(--chart-5);
 22:   --color-chart-4: var(--chart-4);
 23:   --color-chart-3: var(--chart-3);
 24:   --color-chart-2: var(--chart-2);
 25:   --color-chart-1: var(--chart-1);
 26:   --color-ring: var(--ring);
 27:   --color-input: var(--input);
 28:   --color-border: var(--border);
 29:   --color-destructive: var(--destructive);
 30:   --color-accent-foreground: var(--accent-foreground);
 31:   --color-accent: var(--accent);
 32:   --color-muted-foreground: var(--muted-foreground);
 33:   --color-muted: var(--muted);
 34:   --color-secondary-foreground: var(--secondary-foreground);
 35:   --color-secondary: var(--secondary);
 36:   --color-primary-foreground: var(--primary-foreground);
 37:   --color-primary: var(--primary);
 38:   --color-popover-foreground: var(--popover-foreground);
 39:   --color-popover: var(--popover);
 40:   --color-card-foreground: var(--card-foreground);
 41:   --color-card: var(--card);
 42:   --radius-sm: calc(var(--radius) - 4px);
 43:   --radius-md: calc(var(--radius) - 2px);
 44:   --radius-lg: var(--radius);
 45:   --radius-xl: calc(var(--radius) + 4px);
 46: }
 47: 
 48: /* Light Mode - Notion-inspired warm neutrals */
 49: :root {
 50:   --radius: 0.5rem;
 51:   --background: oklch(0.99 0.002 90);
 52:   --foreground: oklch(0.23 0.01 250);
 53:   --card: oklch(1 0 0);
 54:   --card-foreground: oklch(0.23 0.01 250);
 55:   --popover: oklch(1 0 0);
 56:   --popover-foreground: oklch(0.23 0.01 250);
 57:   --primary: oklch(0.45 0.12 250);
 58:   --primary-foreground: oklch(0.99 0 0);
 59:   --secondary: oklch(0.96 0.005 90);
 60:   --secondary-foreground: oklch(0.35 0.01 250);
 61:   --muted: oklch(0.96 0.005 90);
 62:   --muted-foreground: oklch(0.55 0.01 250);
 63:   --accent: oklch(0.96 0.02 80);
 64:   --accent-foreground: oklch(0.35 0.02 80);
 65:   --destructive: oklch(0.55 0.2 25);
 66:   --border: oklch(0.92 0.005 90);
 67:   --input: oklch(0.92 0.005 90);
 68:   --ring: oklch(0.45 0.12 250);
 69:   --chart-1: oklch(0.6 0.18 250);
 70:   --chart-2: oklch(0.65 0.15 160);
 71:   --chart-3: oklch(0.7 0.12 80);
 72:   --chart-4: oklch(0.6 0.2 320);
 73:   --chart-5: oklch(0.55 0.18 30);
 74:   --sidebar: oklch(0.98 0.003 90);
 75:   --sidebar-foreground: oklch(0.35 0.01 250);
 76:   --sidebar-primary: oklch(0.45 0.12 250);
 77:   --sidebar-primary-foreground: oklch(0.99 0 0);
 78:   --sidebar-accent: oklch(0.94 0.01 90);
 79:   --sidebar-accent-foreground: oklch(0.35 0.01 250);
 80:   --sidebar-border: oklch(0.92 0.005 90);
 81:   --sidebar-ring: oklch(0.45 0.12 250);
 82: }
 83: 
 84: /* Dark Mode - Notion-inspired deep neutrals */
 85: .dark {
 86:   --background: oklch(0.16 0.01 250);
 87:   --foreground: oklch(0.92 0.01 90);
 88:   --card: oklch(0.2 0.01 250);
 89:   --card-foreground: oklch(0.92 0.01 90);
 90:   --popover: oklch(0.2 0.01 250);
 91:   --popover-foreground: oklch(0.92 0.01 90);
 92:   --primary: oklch(0.7 0.12 250);
 93:   --primary-foreground: oklch(0.16 0 0);
 94:   --secondary: oklch(0.25 0.01 250);
 95:   --secondary-foreground: oklch(0.85 0.01 90);
 96:   --muted: oklch(0.25 0.01 250);
 97:   --muted-foreground: oklch(0.6 0.01 90);
 98:   --accent: oklch(0.28 0.02 250);
 99:   --accent-foreground: oklch(0.85 0.01 90);
100:   --destructive: oklch(0.65 0.2 25);
101:   --border: oklch(0.28 0.01 250);
102:   --input: oklch(0.28 0.01 250);
103:   --ring: oklch(0.7 0.12 250);
104:   --chart-1: oklch(0.65 0.2 250);
105:   --chart-2: oklch(0.7 0.15 160);
106:   --chart-3: oklch(0.75 0.12 80);
107:   --chart-4: oklch(0.65 0.2 320);
108:   --chart-5: oklch(0.6 0.18 30);
109:   --sidebar: oklch(0.14 0.01 250);
110:   --sidebar-foreground: oklch(0.85 0.01 90);
111:   --sidebar-primary: oklch(0.7 0.12 250);
112:   --sidebar-primary-foreground: oklch(0.16 0 0);
113:   --sidebar-accent: oklch(0.22 0.01 250);
114:   --sidebar-accent-foreground: oklch(0.85 0.01 90);
115:   --sidebar-border: oklch(0.28 0.01 250);
116:   --sidebar-ring: oklch(0.7 0.12 250);
117: }
118: 
119: @layer base {
120:   * {
121:     @apply border-border outline-ring/50;
122:   }
123:   body {
124:     @apply bg-background text-foreground;
125:   }
126: }
127: 
128: /* ========== Notion-like Typography ========== */
129: 
130: @layer base {
131:   h1 {
132:     @apply text-3xl font-semibold tracking-tight;
133:   }
134:   h2 {
135:     @apply text-2xl font-semibold tracking-tight;
136:   }
137:   h3 {
138:     @apply text-xl font-medium;
139:   }
140:   p {
141:     @apply leading-relaxed;
142:   }
143: }
144: 
145: /* ========== Custom Components ========== */
146: 
147: /* Block hover effect - Notion style */
148: .notion-block {
149:   @apply relative rounded-lg transition-all duration-200;
150: }
151: 
152: .notion-block:hover {
153:   @apply bg-accent/50;
154: }
155: 
156: /* Smooth scrollbar */
157: ::-webkit-scrollbar {
158:   width: 8px;
159:   height: 8px;
160: }
161: 
162: ::-webkit-scrollbar-track {
163:   @apply bg-transparent;
164: }
165: 
166: ::-webkit-scrollbar-thumb {
167:   @apply bg-border rounded-full;
168: }
169: 
170: ::-webkit-scrollbar-thumb:hover {
171:   @apply bg-muted-foreground/30;
172: }
173: 
174: /* Drag handle - Notion style */
175: .drag-handle {
176:   @apply opacity-0 transition-opacity duration-150;
177: }
178: 
179: .notion-block:hover .drag-handle {
180:   @apply opacity-100;
181: }
182: 
183: /* Status badges */
184: .status-pending {
185:   @apply bg-amber-100 text-amber-800 dark:bg-amber-900/30 dark:text-amber-200;
186: }
187: 
188: .status-generating {
189:   @apply bg-blue-100 text-blue-800 dark:bg-blue-900/30 dark:text-blue-200;
190: }
191: 
192: .status-success {
193:   @apply bg-emerald-100 text-emerald-800 dark:bg-emerald-900/30 dark:text-emerald-200;
194: }
195: 
196: .status-error {
197:   @apply bg-red-100 text-red-800 dark:bg-red-900/30 dark:text-red-200;
198: }
199: 
200: /* Animation utilities */
201: @keyframes fade-in {
202:   from {
203:     opacity: 0;
204:     transform: translateY(8px);
205:   }
206:   to {
207:     opacity: 1;
208:     transform: translateY(0);
209:   }
210: }
211: 
212: @keyframes slide-in-left {
213:   from {
214:     opacity: 0;
215:     transform: translateX(-16px);
216:   }
217:   to {
218:     opacity: 1;
219:     transform: translateX(0);
220:   }
221: }
222: 
223: .animate-fade-in {
224:   animation: fade-in 0.3s ease-out forwards;
225: }
226: 
227: .animate-slide-in-left {
228:   animation: slide-in-left 0.3s ease-out forwards;
229: }
230: 
231: /* Stagger animation delays */
232: .stagger-1 { animation-delay: 0.05s; }
233: .stagger-2 { animation-delay: 0.1s; }
234: .stagger-3 { animation-delay: 0.15s; }
235: .stagger-4 { animation-delay: 0.2s; }
236: .stagger-5 { animation-delay: 0.25s; }
</file>

<file path="frontend/src/lib/progress-utils.ts">
  1: /**
  2:  * Progress simulation utilities
  3:  * 模拟进度条，用于在等待API响应时给用户提供视觉反馈
  4:  */
  5: 
  6: import type { Step } from "@/components/ui/step-progress";
  7: 
  8: export interface ProgressConfig {
  9:   steps: Step[];
 10:   onStepChange: (steps: Step[]) => void;
 11:   actualTask: () => Promise<void>;
 12:   onCancel?: () => void;
 13: }
 14: 
 15: /**
 16:  * 模拟步骤进度
 17:  * 按顺序执行每个步骤，根据 estimatedTime 延迟
 18:  * 如果实际任务提前完成，立即完成所有步骤
 19:  */
 20: export function simulateStepProgress(config: ProgressConfig): {
 21:   promise: Promise<void>;
 22:   cancel: () => void;
 23: } {
 24:   const { steps, onStepChange, actualTask, onCancel } = config;
 25:   
 26:   let cancelled = false;
 27:   let taskCompleted = false;
 28:   let taskError: Error | null = null;
 29: 
 30:   const cancel = () => {
 31:     cancelled = true;
 32:     onCancel?.();
 33:   };
 34: 
 35:   const promise = new Promise<void>(async (resolve, reject) => {
 36:     // 启动实际任务（在后台执行）
 37:     const taskPromise = actualTask()
 38:       .then(() => {
 39:         taskCompleted = true;
 40:       })
 41:       .catch((error) => {
 42:         taskError = error;
 43:       });
 44: 
 45:     // 逐步执行模拟进度
 46:     for (let i = 0; i < steps.length; i++) {
 47:       if (cancelled) {
 48:         // 用户取消
 49:         const updatedSteps = steps.map((s, idx) => ({
 50:           ...s,
 51:           status: idx < i ? ("completed" as const) : ("pending" as const),
 52:         }));
 53:         onStepChange(updatedSteps);
 54:         reject(new Error("User cancelled"));
 55:         return;
 56:       }
 57: 
 58:       // 更新当前步骤为 loading
 59:       const loadingSteps = steps.map((s, idx) => ({
 60:         ...s,
 61:         status:
 62:           idx < i
 63:             ? ("completed" as const)
 64:             : idx === i
 65:             ? ("loading" as const)
 66:             : ("pending" as const),
 67:       }));
 68:       onStepChange(loadingSteps);
 69: 
 70:       // 如果任务已完成，立即完成所有剩余步骤
 71:       if (taskCompleted) {
 72:         const completedSteps = steps.map((s) => ({
 73:           ...s,
 74:           status: "completed" as const,
 75:         }));
 76:         onStepChange(completedSteps);
 77:         resolve();
 78:         return;
 79:       }
 80: 
 81:       // 如果任务出错，标记当前步骤为 error
 82:       if (taskError) {
 83:         const errorSteps = steps.map((s, idx) => ({
 84:           ...s,
 85:           status:
 86:             idx < i
 87:               ? ("completed" as const)
 88:               : idx === i
 89:               ? ("error" as const)
 90:               : ("pending" as const),
 91:         }));
 92:         onStepChange(errorSteps);
 93:         reject(taskError);
 94:         return;
 95:       }
 96: 
 97:       // 等待该步骤的预估时间
 98:       const delay = steps[i].estimatedTime || 3;
 99:       await sleep(delay * 1000);
100: 
101:       // 完成当前步骤
102:       const completedSteps = steps.map((s, idx) => ({
103:         ...s,
104:         status:
105:           idx <= i ? ("completed" as const) : ("pending" as const),
106:       }));
107:       onStepChange(completedSteps);
108:     }
109: 
110:     // 所有步骤完成后，等待实际任务完成
111:     try {
112:       await taskPromise;
113:       resolve();
114:     } catch (error) {
115:       reject(error);
116:     }
117:   });
118: 
119:   return { promise, cancel };
120: }
121: 
122: /**
123:  * Sleep helper
124:  */
125: function sleep(ms: number): Promise<void> {
126:   return new Promise((resolve) => setTimeout(resolve, ms));
127: }
128: 
129: /**
130:  * 创建默认步骤
131:  */
132: export function createDefaultSteps(labels: Array<{ label: string; time?: number }>): Step[] {
133:   return labels.map((item, index) => ({
134:     id: `step-${index}`,
135:     label: item.label,
136:     status: "pending",
137:     estimatedTime: item.time || 3,
138:   }));
139: }
</file>

<file path="frontend/src/lib/utils.ts">
1: import { clsx, type ClassValue } from "clsx"
2: import { twMerge } from "tailwind-merge"
3: 
4: export function cn(...inputs: ClassValue[]) {
5:   return twMerge(clsx(inputs))
6: }
</file>

<file path="frontend/package.json">
 1: {
 2:   "name": "frontend",
 3:   "version": "0.1.0",
 4:   "private": true,
 5:   "scripts": {
 6:     "dev": "next dev",
 7:     "build": "next build",
 8:     "start": "next start",
 9:     "lint": "eslint"
10:   },
11:   "dependencies": {
12:     "@radix-ui/react-accordion": "^1.2.12",
13:     "@radix-ui/react-collapsible": "^1.1.12",
14:     "@radix-ui/react-scroll-area": "^1.2.10",
15:     "@radix-ui/react-select": "^2.2.6",
16:     "@radix-ui/react-separator": "^1.1.8",
17:     "@radix-ui/react-slider": "^1.3.6",
18:     "@radix-ui/react-slot": "^1.2.4",
19:     "@radix-ui/react-tabs": "^1.1.13",
20:     "@radix-ui/react-tooltip": "^1.2.8",
21:     "class-variance-authority": "^0.7.1",
22:     "clsx": "^2.1.1",
23:     "framer-motion": "^12.23.25",
24:     "lucide-react": "^0.555.0",
25:     "next": "16.0.7",
26:     "next-themes": "^0.4.6",
27:     "react": "19.2.0",
28:     "react-dom": "19.2.0",
29:     "sonner": "^2.0.7",
30:     "tailwind-merge": "^3.4.0",
31:     "zustand": "^5.0.9"
32:   },
33:   "devDependencies": {
34:     "@tailwindcss/postcss": "^4",
35:     "@types/node": "^20",
36:     "@types/react": "^19",
37:     "@types/react-dom": "^19",
38:     "babel-plugin-react-compiler": "1.0.0",
39:     "eslint": "^9",
40:     "eslint-config-next": "16.0.7",
41:     "tailwindcss": "^4",
42:     "tw-animate-css": "^1.4.0",
43:     "typescript": "^5"
44:   }
45: }
</file>

<file path="modules/__init__.py">
1: 
</file>

<file path="modules/audio.py">
  1: """
  2: 音频生成模块 (Edge TTS + 火山引擎 TTS)
  3: 支持并发生成：EdgeTTS 使用 asyncio.Semaphore，火山引擎使用 ThreadPoolExecutor
  4: 支持主题命名：文件按主题组织
  5: """
  6: import os
  7: import asyncio
  8: import uuid
  9: import json
 10: import base64
 11: from pathlib import Path
 12: from typing import Optional, Tuple, List
 13: from concurrent.futures import ThreadPoolExecutor, as_completed
 14: from dotenv import load_dotenv
 15: from modules.utils import sanitize_filename, get_unique_dir
 16: from modules.storage import upload_file_to_oss_by_topic
 17: 
 18: load_dotenv()
 19: 
 20: # 默认输出目录
 21: DEFAULT_OUTPUT_DIR = Path("output/audio")
 22: DEFAULT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
 23: 
 24: 
 25: # ========== 单段音频生成（核心函数） ==========
 26: 
 27: def _generate_single_edge(text: str, voice: str, index: int) -> Tuple[Optional[str], Optional[str]]:
 28:     """
 29:     使用 Edge TTS 生成单段音频
 30:     
 31:     Returns:
 32:         (文件路径, 错误信息) - 成功时错误为 None
 33:     """
 34:     try:
 35:         if not text:
 36:             return None, "文本为空"
 37:         
 38:         import edge_tts
 39:         
 40:         file_path = str(DEFAULT_OUTPUT_DIR / f"scene_{index+1:02d}.mp3")
 41:         
 42:         async def _run():
 43:             # rate="+50%" 实现 1.5 倍速
 44:             communicate = edge_tts.Communicate(text, voice, rate="+50%")
 45:             await communicate.save(file_path)
 46:         
 47:         asyncio.run(_run())
 48:         
 49:         if os.path.exists(file_path):
 50:             print(f"[Edge TTS] 场景 {index+1} 完成: {file_path}")
 51:             return file_path, None
 52:         else:
 53:             return None, "文件生成失败"
 54:             
 55:     except Exception as e:
 56:         error_msg = str(e)
 57:         print(f"[Edge TTS Error] 场景 {index+1} 失败: {error_msg}")
 58:         return None, error_msg
 59: 
 60: 
 61: def _generate_single_volc(text: str, voice: str, index: int) -> Tuple[Optional[str], Optional[str]]:
 62:     """
 63:     使用火山引擎 TTS 生成单段音频
 64:     
 65:     Returns:
 66:         (文件路径, 错误信息)
 67:     """
 68:     import requests
 69:     
 70:     try:
 71:         if not text:
 72:             return None, "文本为空"
 73:         
 74:         appid = os.getenv("VOLC_TTS_APPID")
 75:         token = os.getenv("VOLC_TTS_TOKEN")
 76:         cluster = os.getenv("VOLC_TTS_CLUSTER", "volcano_tts")
 77:         uid = os.getenv("VOLC_TTS_UID", "user_001")
 78:         resource_id = os.getenv("VOLC_TTS_RESOURCE_ID", "volc.tts_async.default")
 79:         
 80:         if not appid or not token:
 81:             return None, "缺少 VOLC_TTS_APPID 或 VOLC_TTS_TOKEN"
 82:         
 83:         file_path = str(DEFAULT_OUTPUT_DIR / f"scene_{index+1:02d}.mp3")
 84:         
 85:         api_url = "https://openspeech.bytedance.com/api/v1/tts"
 86:         
 87:         headers = {
 88:             "Content-Type": "application/json",
 89:             "Authorization": f"Bearer;{token}",
 90:         }
 91:         
 92:         request_json = {
 93:             "app": {"appid": appid, "token": token, "cluster": cluster},
 94:             "user": {"uid": uid},
 95:             "audio": {
 96:                 "voice_type": voice,
 97:                 "encoding": "mp3",
 98:                 "speed_ratio": 1.5,  # 1.5 倍速
 99:                 "volume_ratio": 1.0,
100:                 "pitch_ratio": 1.0,
101:                 "extra_param": json.dumps({"aigc_watermark": False})
102:             },
103:             "request": {
104:                 "reqid": str(uuid.uuid4()),
105:                 "text": text,
106:                 "operation": "query"
107:             }
108:         }
109:         
110:         resp = requests.post(api_url, headers=headers, json=request_json, timeout=60)
111:         
112:         if resp.status_code != 200:
113:             return None, f"HTTP {resp.status_code}"
114:         
115:         # 解析 JSON 响应
116:         result = resp.json()
117:         
118:         # 检查返回码 (3000 = 成功)
119:         if result.get("code") != 3000:
120:             return None, f"API错误: {result.get('message', 'Unknown')}"
121:         
122:         # Base64 解码音频数据
123:         audio_base64 = result.get("data", "")
124:         if not audio_base64:
125:             return None, "返回的音频数据为空"
126:         
127:         audio_data = base64.b64decode(audio_base64)
128:         
129:         with open(file_path, "wb") as f:
130:             f.write(audio_data)
131:         
132:         print(f"[Volc TTS] 场景 {index+1} 完成: {file_path} ({len(audio_data)} bytes)")
133:         return file_path, None
134:         
135:     except Exception as e:
136:         error_msg = str(e)
137:         print(f"[Volc TTS Error] 场景 {index+1} 失败: {error_msg}")
138:         return None, error_msg
139: 
140: 
141: # ========== 兼容旧接口 ==========
142: 
143: def generate_edge_audio(text: str, voice: str = "zh-CN-XiaoxiaoNeural", file_path: str = None) -> str:
144:     """使用 Edge TTS 生成音频（兼容旧接口）"""
145:     if not file_path:
146:         file_path = str(DEFAULT_OUTPUT_DIR / f"edge_{uuid.uuid4().hex[:8]}.mp3")
147:     
148:     try:
149:         import edge_tts
150:         
151:         async def _run():
152:             communicate = edge_tts.Communicate(text, voice)
153:             await communicate.save(file_path)
154:         
155:         asyncio.run(_run())
156:         
157:         if os.path.exists(file_path):
158:             print(f"[Edge TTS] 生成成功: {file_path}")
159:             return file_path
160:     except Exception as e:
161:         print(f"[Edge TTS Error] {e}")
162:     
163:     return None
164: 
165: 
166: def generate_volc_audio(text: str, voice_type: str = "zh_female_meilinvyou_moon_bigtts", file_path: str = None) -> str:
167:     """使用火山引擎 TTS 生成音频（兼容旧接口）"""
168:     import requests
169:     
170:     appid = os.getenv("VOLC_TTS_APPID")
171:     token = os.getenv("VOLC_TTS_TOKEN")
172:     cluster = os.getenv("VOLC_TTS_CLUSTER", "volcano_tts")
173:     uid = os.getenv("VOLC_TTS_UID", "user_001")
174:     resource_id = os.getenv("VOLC_TTS_RESOURCE_ID", "volc.tts_async.default")
175:     
176:     if not appid or not token:
177:         print("[Volc TTS Error] 缺少 VOLC_TTS_APPID 或 VOLC_TTS_TOKEN")
178:         return None
179:     
180:     if not file_path:
181:         file_path = str(DEFAULT_OUTPUT_DIR / f"volc_{uuid.uuid4().hex[:8]}.mp3")
182:     
183:     api_url = "https://openspeech.bytedance.com/api/v1/tts"
184:     
185:     headers = {
186:         "Content-Type": "application/json",
187:         "Authorization": f"Bearer;{token}",
188:     }
189:     
190:     request_json = {
191:         "app": {"appid": appid, "token": token, "cluster": cluster},
192:         "user": {"uid": uid},
193:         "audio": {
194:             "voice_type": voice_type,
195:             "encoding": "mp3",
196:             "speed_ratio": 1.0,
197:             "volume_ratio": 1.0,
198:             "pitch_ratio": 1.0
199:         },
200:         "request": {
201:             "reqid": str(uuid.uuid4()),
202:             "text": text,
203:             "operation": "query"
204:         }
205:     }
206:     
207:     try:
208:         resp = requests.post(api_url, headers=headers, json=request_json, timeout=60)
209:         
210:         if resp.status_code != 200:
211:             print(f"[Volc TTS Error] HTTP {resp.status_code}: {resp.text[:200]}")
212:             return None
213:         
214:         # 解析 JSON 响应
215:         result = resp.json()
216:         
217:         # 检查返回码 (3000 = 成功)
218:         if result.get("code") != 3000:
219:             print(f"[Volc TTS Error] API错误: {result.get('message', 'Unknown')}")
220:             return None
221:         
222:         # Base64 解码音频数据
223:         audio_base64 = result.get("data", "")
224:         if not audio_base64:
225:             print("[Volc TTS Error] 返回的音频数据为空")
226:             return None
227:         
228:         audio_data = base64.b64decode(audio_base64)
229:         
230:         with open(file_path, "wb") as f:
231:             f.write(audio_data)
232:         
233:         print(f"[Volc TTS] 生成成功: {file_path} ({len(audio_data)} bytes)")
234:         return file_path
235:         
236:     except Exception as e:
237:         print(f"[Volc TTS Error] {e}")
238:         return None
239: 
240: 
241: # ========== 统一入口 ==========
242: 
243: def generate_audio(text: str, provider: str = "edge", voice: str = None, output_path: str = None) -> str:
244:     """统一音频生成入口"""
245:     if provider == "edge":
246:         voice = voice or "zh-CN-XiaoxiaoNeural"
247:         return generate_edge_audio(text, voice, output_path)
248:     elif provider == "volcengine":
249:         voice = voice or "zh_female_meilinvyou_moon_bigtts"
250:         return generate_volc_audio(text, voice, output_path)
251:     else:
252:         print(f"[Audio Error] 未知的 provider: {provider}")
253:         return None
254: 
255: 
256: # 并发配置
257: EDGE_SEMAPHORE_LIMIT = 3  # EdgeTTS 并发限制（防止被微软封 IP）
258: VOLC_MAX_WORKERS = 5  # 火山引擎线程池大小
259: 
260: 
261: async def _generate_edge_async(text: str, voice: str, index: int, semaphore: asyncio.Semaphore, output_dir: Path = None, topic: str = None) -> Tuple[int, Optional[str]]:
262:     """异步生成单段 Edge TTS 音频（带信号量限制）"""
263:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
264:     
265:     async with semaphore:
266:         try:
267:             if not text:
268:                 return index, None
269:             
270:             import edge_tts
271:             
272:             # 文件命名：主题_scene_01.mp3
273:             safe_topic = sanitize_filename(topic) if topic else ""
274:             filename = f"{safe_topic}_scene_{index+1:02d}.mp3" if safe_topic else f"scene_{index+1:02d}.mp3"
275:             file_path = str(output_dir / filename)
276:             
277:             # rate="+50%" 实现 1.5 倍速
278:             communicate = edge_tts.Communicate(text, voice, rate="+50%")
279:             await communicate.save(file_path)
280:             
281:             if os.path.exists(file_path):
282:                 print(f"[Edge TTS] 场景 {index+1} 完成")
283:                 # 上传到 OSS（按主题分类）
284:                 oss_url = None
285:                 if topic:
286:                     oss_url = upload_file_to_oss_by_topic(file_path, topic, "audio")
287:                 return index, oss_url or file_path
288:             else:
289:                 return index, None
290:                 
291:         except Exception as e:
292:             print(f"[Edge TTS Error] 场景 {index+1} 失败: {e}")
293:             return index, None
294: 
295: 
296: def _generate_edge_concurrent(scenes: list, voice: str, output_dir: Path = None, topic: str = None) -> list:
297:     """EdgeTTS 异步并发生成"""
298:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
299:     
300:     async def _run_all():
301:         semaphore = asyncio.Semaphore(EDGE_SEMAPHORE_LIMIT)
302:         tasks = []
303:         
304:         for i, scene in enumerate(scenes):
305:             narration = scene.get("narration", "")
306:             task = _generate_edge_async(narration, voice, i, semaphore, output_dir, topic)
307:             tasks.append(task)
308:         
309:         results = await asyncio.gather(*tasks, return_exceptions=True)
310:         return results
311:     
312:     # 运行异步任务
313:     raw_results = asyncio.run(_run_all())
314:     
315:     # 整理结果（保持顺序）
316:     audio_paths = [None] * len(scenes)
317:     for result in raw_results:
318:         if isinstance(result, Exception):
319:             continue
320:         index, path = result
321:         audio_paths[index] = path
322:     
323:     return audio_paths
324: 
325: 
326: def _generate_volc_concurrent(scenes: list, voice: str, output_dir: Path = None, topic: str = None) -> list:
327:     """火山引擎 ThreadPoolExecutor 并发生成"""
328:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
329:     
330:     def _generate_one(args):
331:         index, scene = args
332:         narration = scene.get("narration", "")
333:         if not narration:
334:             return index, None
335:         
336:         # 文件命名：主题_scene_01.mp3
337:         safe_topic = sanitize_filename(topic) if topic else ""
338:         filename = f"{safe_topic}_scene_{index+1:02d}.mp3" if safe_topic else f"scene_{index+1:02d}.mp3"
339:         file_path = str(output_dir / filename)
340:         
341:         path, _ = _generate_single_volc(narration, voice, index)
342:         # 如果成功，重命名到正确位置
343:         if path and os.path.exists(path):
344:             import shutil
345:             shutil.move(path, file_path)
346:             # 上传到 OSS（按主题分类）
347:             oss_url = None
348:             if topic:
349:                 oss_url = upload_file_to_oss_by_topic(file_path, topic, "audio")
350:             return index, oss_url or file_path
351:         return index, None
352:     
353:     audio_paths = [None] * len(scenes)
354:     
355:     with ThreadPoolExecutor(max_workers=VOLC_MAX_WORKERS) as executor:
356:         futures = {executor.submit(_generate_one, (i, scene)): i for i, scene in enumerate(scenes)}
357:         
358:         for future in as_completed(futures):
359:             try:
360:                 index, path = future.result()
361:                 audio_paths[index] = path
362:             except Exception as e:
363:                 index = futures[future]
364:                 print(f"[Volc TTS Error] 场景 {index+1} Future 异常: {e}")
365:     
366:     return audio_paths
367: 
368: 
369: def generate_audio_for_scenes(scenes: list, provider: str = "edge", voice: str = None, topic: str = None) -> list:
370:     """
371:     批量为分镜生成音频（并发版本）
372:     
373:     文件按主题组织，重复生成时自动添加数字后缀。
374:     
375:     Args:
376:         scenes: 分镜列表
377:         provider: "edge" 或 "volcengine"
378:         voice: 语音角色
379:         topic: 主题名称（用于创建子目录和文件命名）
380:     
381:     Returns:
382:         音频路径列表（顺序与 scenes 一致，失败项为 None）
383:     """
384:     if not scenes:
385:         return []
386:     
387:     voice = voice or ("zh-CN-XiaoxiaoNeural" if provider == "edge" else "zh_female_meilinvyou_moon_bigtts")
388:     
389:     # 创建主题目录
390:     if topic:
391:         output_dir = get_unique_dir(DEFAULT_OUTPUT_DIR, topic)
392:         print(f"[Audio] 输出目录: {output_dir}")
393:     else:
394:         output_dir = DEFAULT_OUTPUT_DIR
395:     
396:     print(f"[Audio] 开始并发生成 {len(scenes)} 段音频 ({provider})...")
397:     
398:     if provider == "edge":
399:         audio_paths = _generate_edge_concurrent(scenes, voice, output_dir, topic)
400:     else:
401:         audio_paths = _generate_volc_concurrent(scenes, voice, output_dir, topic)
402:     
403:     success_count = sum(1 for p in audio_paths if p is not None)
404:     print(f"[Audio] 并发生成完成: {success_count}/{len(scenes)} 成功")
405:     
406:     return audio_paths
407: 
408: 
409: def generate_single_audio(scene: dict, index: int, provider: str = "edge", voice: str = None, output_dir: Path = None, topic: str = None) -> Tuple[Optional[str], Optional[str]]:
410:     """
411:     生成单段音频（用于重试）
412:     
413:     Args:
414:         scene: 分镜字典，需包含 'narration' 字段
415:         index: 场景索引（0-based）
416:         provider: "edge" 或 "volcengine"
417:         voice: 语音角色
418:         output_dir: 输出目录
419:         topic: 主题名称
420:     
421:     Returns:
422:         (文件路径, 错误信息)
423:     """
424:     narration = scene.get("narration", "")
425:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
426:     
427:     # 文件命名：主题_scene_01.mp3
428:     safe_topic = sanitize_filename(topic) if topic else ""
429:     filename = f"{safe_topic}_scene_{index+1:02d}.mp3" if safe_topic else f"scene_{index+1:02d}.mp3"
430:     file_path = str(output_dir / filename)
431:     
432:     if provider == "edge":
433:         voice = voice or "zh-CN-XiaoxiaoNeural"
434:         path, error = _generate_single_edge(narration, voice, index)
435:         # 移动到正确位置
436:         if path and os.path.exists(path) and path != file_path:
437:             import shutil
438:             shutil.move(path, file_path)
439:             return file_path, None
440:         return path, error
441:     elif provider == "volcengine":
442:         voice = voice or "zh_female_meilinvyou_moon_bigtts"
443:         path, error = _generate_single_volc(narration, voice, index)
444:         if path and os.path.exists(path) and path != file_path:
445:             import shutil
446:             shutil.move(path, file_path)
447:             return file_path, None
448:         return path, error
449:     else:
450:         return None, f"未知的 provider: {provider}"
451: 
452: 
453: # ========== 语音角色列表 ==========
454: 
455: EDGE_VOICES = {
456:     "小晓 (女)": "zh-CN-XiaoxiaoNeural",
457:     "云扬 (男)": "zh-CN-YunyangNeural",
458:     "云希 (男)": "zh-CN-YunxiNeural",
459:     "晓涵 (女)": "zh-CN-XiaohanNeural",
460:     "晓墨 (女)": "zh-CN-XiaomoNeural",
461:     "晓秋 (女)": "zh-CN-XiaoqiuNeural",
462:     "晓睿 (女)": "zh-CN-XiaoruiNeural",
463: }
464: 
465: VOLC_VOICES = {
466:     "魅力女声": "zh_female_meilinvyou_moon_bigtts",
467:     "甜美女声": "zh_female_tianmei_moon_bigtts",
468:     "知性女声": "zh_female_zhixing_moon_bigtts",
469:     "温柔女声": "zh_female_wenrou_moon_bigtts",
470:     "磁性男声": "zh_male_cixing_moon_bigtts",
471:     "阳光男声": "zh_male_yangguang_moon_bigtts",
472: }
</file>

<file path="modules/crawler.py">
 1: """
 2: DrissionPage 爬虫模块
 3: """
 4: from DrissionPage import ChromiumPage
 5: 
 6: 
 7: def fetch_note_content(url: str) -> dict:
 8:     """
 9:     抓取小红书笔记内容
10:     
11:     Args:
12:         url: 小红书笔记 URL
13:     
14:     Returns:
15:         {'title': '...', 'content': '...'} 或失败时返回空 dict
16:     """
17:     page = None
18:     try:
19:         page = ChromiumPage()
20:         page.get(url)
21:         page.wait.load_start()
22:         
23:         # 提取标题 (h1 标签)
24:         title_el = page.ele('tag:h1')
25:         title = title_el.text if title_el else ''
26:         
27:         # 提取正文内容 (小红书笔记正文通常在 desc 区域)
28:         desc_el = page.ele('.note-content') or page.ele('#detail-desc') or page.ele('tag:article')
29:         content = desc_el.text if desc_el else ''
30:         
31:         return {'title': title, 'content': content}
32:     
33:     except Exception as e:
34:         print(f"[Crawler Error] 抓取失败: {e}")
35:         return {}
36:     
37:     finally:
38:         if page:
39:             page.quit()
</file>

<file path="modules/editor.py">
  1: """
  2: 视频剪辑模块 (MoviePy)
  3: 实现分镜对齐的画音同步视频合成 + Ken Burns 动态运镜 + BGM 混音
  4: 支持主题命名：视频和字幕按主题组织
  5: """
  6: import os
  7: from pathlib import Path
  8: from typing import Optional
  9: from dotenv import load_dotenv
 10: from modules.utils import sanitize_filename, get_unique_dir
 11: from modules.storage import upload_file_to_oss_by_topic
 12: 
 13: load_dotenv()
 14: 
 15: # 默认输出目录
 16: DEFAULT_OUTPUT_DIR = Path("output/video")
 17: DEFAULT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
 18: 
 19: # 视频尺寸 (9:16 竖屏)
 20: TARGET_WIDTH = 1080
 21: TARGET_HEIGHT = 1920
 22: 
 23: 
 24: def _apply_ken_burns(image_clip, duration: float, zoom_ratio: float = 0.15):
 25:     """
 26:     应用 Ken Burns 效果（缓慢推拉）
 27:     
 28:     原理：
 29:     1. 先将图片放大到 (1 + zoom_ratio) 倍，确保动画过程中不会出现黑边
 30:     2. 然后通过 crop 动画实现从中心向外的缓慢推进效果
 31:     
 32:     Args:
 33:         image_clip: ImageClip 对象
 34:         duration: 片段时长
 35:         zoom_ratio: 缩放比例 (0.15 = 最终放大 15%)
 36:     
 37:     Returns:
 38:         带 Ken Burns 效果的 clip
 39:     """
 40:     from moviepy import vfx
 41:     
 42:     # 获取原始尺寸
 43:     w, h = image_clip.size
 44:     
 45:     # 先放大图片以留出动画空间
 46:     scale_factor = 1 + zoom_ratio
 47:     enlarged = image_clip.resized(scale_factor)
 48:     new_w, new_h = enlarged.size
 49:     
 50:     # 计算 crop 区域（保持目标尺寸）
 51:     def make_frame_crop(get_frame):
 52:         def crop_frame(t):
 53:             # 线性插值：从 1.0 放大到 (1 + zoom_ratio)
 54:             progress = t / duration if duration > 0 else 0
 55:             current_scale = 1 + (zoom_ratio * progress)
 56:             
 57:             # 计算当前 crop 区域大小
 58:             crop_w = w / current_scale
 59:             crop_h = h / current_scale
 60:             
 61:             # 居中 crop
 62:             x1 = (new_w - crop_w) / 2
 63:             y1 = (new_h - crop_h) / 2
 64:             x2 = x1 + crop_w
 65:             y2 = y1 + crop_h
 66:             
 67:             frame = get_frame(t)
 68:             # 裁切并缩放回原尺寸
 69:             cropped = frame[int(y1):int(y2), int(x1):int(x2)]
 70:             return cropped
 71:         return crop_frame
 72:     
 73:     # 使用 resize 实现动态缩放效果（更简单可靠的方式）
 74:     def zoom_func(t):
 75:         progress = t / duration if duration > 0 else 0
 76:         return 1 + (zoom_ratio * progress)
 77:     
 78:     zoomed = image_clip.resized(zoom_func)
 79:     
 80:     # 裁切到目标尺寸（居中）
 81:     final_w, final_h = TARGET_WIDTH, TARGET_HEIGHT
 82:     zoomed = zoomed.with_position(('center', 'center'))
 83:     
 84:     return zoomed
 85: 
 86: 
 87: def _prepare_image_clip(img_path: str, duration: float, apply_zoom: bool = True) -> Optional[any]:
 88:     """
 89:     准备单个图片 clip：调整尺寸 + Ken Burns 效果
 90:     
 91:     Args:
 92:         img_path: 图片路径
 93:         duration: 片段时长
 94:         apply_zoom: 是否应用 Ken Burns 效果
 95:     
 96:     Returns:
 97:         处理后的 ImageClip
 98:     """
 99:     from moviepy import ImageClip
100:     from PIL import Image
101:     import numpy as np
102:     
103:     # 加载并调整图片尺寸
104:     img = Image.open(img_path)
105:     img_w, img_h = img.size
106:     
107:     # 计算缩放比例，确保覆盖目标尺寸（用于 Ken Burns 动画空间）
108:     zoom_buffer = 1.2 if apply_zoom else 1.0  # 预留 20% 空间给动画
109:     scale = max(TARGET_WIDTH * zoom_buffer / img_w, TARGET_HEIGHT * zoom_buffer / img_h)
110:     
111:     new_w = int(img_w * scale)
112:     new_h = int(img_h * scale)
113:     img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
114:     
115:     # 居中裁切到目标尺寸（带缓冲）
116:     crop_w = int(TARGET_WIDTH * zoom_buffer)
117:     crop_h = int(TARGET_HEIGHT * zoom_buffer)
118:     left = (new_w - crop_w) // 2
119:     top = (new_h - crop_h) // 2
120:     img = img.crop((left, top, left + crop_w, top + crop_h))
121:     
122:     # 转换为 numpy array
123:     img_array = np.array(img.convert('RGB'))
124:     
125:     # 创建 ImageClip
126:     clip = ImageClip(img_array, duration=duration)
127:     
128:     if apply_zoom:
129:         # 应用 Ken Burns 效果
130:         def zoom_func(t):
131:             progress = t / duration if duration > 0 else 0
132:             return 1.0 / (1 + 0.15 * progress)  # 从 1.0 缩小到 ~0.87，实现 zoom in 效果
133:         
134:         clip = clip.resized(zoom_func)
135:     
136:     # 最终裁切到精确的目标尺寸
137:     clip = clip.cropped(
138:         x_center=clip.w / 2,
139:         y_center=clip.h / 2,
140:         width=TARGET_WIDTH,
141:         height=TARGET_HEIGHT
142:     )
143:     
144:     return clip
145: 
146: 
147: def create_video(
148:     image_paths: list, 
149:     audio_paths: list, 
150:     output_path: str = None,
151:     bgm_path: str = None,
152:     bgm_volume: float = 0.12,
153:     scenes: list = None,
154:     topic: str = None
155: ) -> str:
156:     """
157:     拉链式组合图片和音频，生成画音同步视频 + SRT 字幕
158:     
159:     文件按主题命名，重复生成时自动添加数字后缀。
160:     
161:     Args:
162:         image_paths: 图片路径列表
163:         audio_paths: 音频路径列表（长度必须与 image_paths 相等）
164:         output_path: 输出视频路径，为空则自动生成
165:         bgm_path: 背景音乐路径（可选）
166:         bgm_volume: BGM 音量 (0.0-1.0)，默认 0.12
167:         scenes: 分镜列表（含 narration），用于生成 SRT 字幕
168:         topic: 主题名称（用于文件命名）
169:     
170:     Returns:
171:         成功返回视频文件路径，失败返回 None
172:     
173:     核心逻辑：
174:         每张图片的展示时长 = 对应音频的时长
175:         clips[N] = image[N] + audio[N] + Ken Burns 效果
176:         final_video = concat(clips) + BGM 混音
177:         同时生成 .srt 字幕文件（与视频同名）
178:     """
179:     from moviepy import ImageClip, AudioFileClip, concatenate_videoclips, CompositeAudioClip
180:     from moviepy import audio as afx
181:     
182:     if len(image_paths) != len(audio_paths):
183:         print(f"[Editor Error] 图片数量({len(image_paths)})与音频数量({len(audio_paths)})不匹配")
184:         return None
185:     
186:     # 创建主题目录并生成文件路径
187:     if not output_path:
188:         if topic:
189:             output_dir = get_unique_dir(DEFAULT_OUTPUT_DIR, topic)
190:             safe_topic = sanitize_filename(topic)
191:             output_path = str(output_dir / f"{safe_topic}.mp4")
192:             print(f"[Editor] 输出目录: {output_dir}")
193:         else:
194:             output_path = str(DEFAULT_OUTPUT_DIR / "output.mp4")
195:     
196:     clips = []
197:     voice_clips = []  # 收集所有人声音频
198:     
199:     for i, (img_path, aud_path) in enumerate(zip(image_paths, audio_paths)):
200:         # 跳过缺失的素材
201:         if not img_path or not os.path.exists(img_path):
202:             print(f"[Editor Warning] 场景 {i+1} 图片不存在，跳过")
203:             continue
204:         if not aud_path or not os.path.exists(aud_path):
205:             print(f"[Editor Warning] 场景 {i+1} 音频不存在，跳过")
206:             continue
207:         
208:         try:
209:             # 1. 加载音频
210:             audio_clip = AudioFileClip(aud_path)
211:             duration = audio_clip.duration
212:             voice_clips.append(audio_clip)
213:             
214:             # 2. 加载图片 + Ken Burns 效果
215:             image_clip = _prepare_image_clip(img_path, duration, apply_zoom=True)
216:             
217:             if image_clip is None:
218:                 print(f"[Editor Warning] 场景 {i+1} 图片处理失败，使用原始方式")
219:                 image_clip = ImageClip(img_path, duration=duration)
220:             
221:             # 3. 设置帧率
222:             image_clip = image_clip.with_fps(24)
223:             
224:             # 4. 绑定音频
225:             video_clip = image_clip.with_audio(audio_clip)
226:             
227:             clips.append(video_clip)
228:             print(f"[Editor] 场景 {i+1} 处理完成 (时长: {duration:.2f}s, Ken Burns: ✓)")
229:             
230:         except Exception as e:
231:             print(f"[Editor Error] 场景 {i+1} 处理失败: {e}")
232:             continue
233:     
234:     if not clips:
235:         print("[Editor Error] 没有可用的视频片段")
236:         return None
237:     
238:     try:
239:         # 为分镜添加淡入淡出过渡效果
240:         CROSSFADE_DURATION = 0.3  # 过渡时长（秒）
241:         
242:         if len(clips) > 1:
243:             print(f"[Editor] 正在添加分镜过渡效果 ({CROSSFADE_DURATION}s crossfade)...")
244:             from moviepy import vfx
245:             
246:             processed_clips = []
247:             for i, clip in enumerate(clips):
248:                 # 第一个片段只加淡出
249:                 if i == 0:
250:                     clip = clip.with_effects([vfx.CrossFadeOut(CROSSFADE_DURATION)])
251:                 # 最后一个片段只加淡入
252:                 elif i == len(clips) - 1:
253:                     clip = clip.with_effects([vfx.CrossFadeIn(CROSSFADE_DURATION)])
254:                 # 中间片段加淡入淡出
255:                 else:
256:                     clip = clip.with_effects([
257:                         vfx.CrossFadeIn(CROSSFADE_DURATION),
258:                         vfx.CrossFadeOut(CROSSFADE_DURATION)
259:                     ])
260:                 processed_clips.append(clip)
261:             clips = processed_clips
262:         
263:         # 拼接所有片段（使用 compose 方法支持过渡）
264:         print(f"[Editor] 正在拼接 {len(clips)} 个片段...")
265:         final_clip = concatenate_videoclips(clips, method="compose", padding=-CROSSFADE_DURATION if len(clips) > 1 else 0)
266:         total_duration = final_clip.duration
267:         
268:         # BGM 混音
269:         if bgm_path and os.path.exists(bgm_path):
270:             print(f"[Editor] 正在混入 BGM: {bgm_path}")
271:             try:
272:                 bgm_clip = AudioFileClip(bgm_path)
273:                 
274:                 # 循环或截取 BGM 到视频长度
275:                 if bgm_clip.duration < total_duration:
276:                     # BGM 比视频短，循环播放
277:                     loops_needed = int(total_duration / bgm_clip.duration) + 1
278:                     bgm_clip = afx.audio_loop(bgm_clip, nloops=loops_needed)
279:                 
280:                 # 截取到视频长度
281:                 bgm_clip = bgm_clip.subclipped(0, total_duration)
282:                 
283:                 # 调整 BGM 音量
284:                 bgm_clip = bgm_clip.with_volume_scaled(bgm_volume)
285:                 
286:                 # 合成人声（音量保持 1.0）和 BGM
287:                 original_audio = final_clip.audio
288:                 mixed_audio = CompositeAudioClip([original_audio, bgm_clip])
289:                 final_clip = final_clip.with_audio(mixed_audio)
290:                 
291:                 print(f"[Editor] BGM 混音完成 (音量: {bgm_volume})")
292:             except Exception as e:
293:                 print(f"[Editor Warning] BGM 混音失败: {e}，继续无 BGM 导出")
294:         
295:         # 导出视频
296:         print(f"[Editor] 正在导出视频: {output_path}")
297:         final_clip.write_videofile(
298:             output_path,
299:             codec="libx264",
300:             audio_codec="aac",
301:             fps=24,
302:             preset="medium",
303:             threads=4,
304:             logger=None  # 减少日志输出
305:         )
306:         
307:         # 清理资源
308:         final_clip.close()
309:         for clip in clips:
310:             clip.close()
311:         
312:         print(f"[Editor] 视频导出成功: {output_path} (总时长: {total_duration:.2f}s)")
313:         
314:         # 自动生成 SRT 字幕文件
315:         srt_path = None
316:         if scenes:
317:             srt_path = output_path.rsplit('.', 1)[0] + '.srt'
318:             generate_srt(scenes, audio_paths, srt_path)
319:         
320:         # 上传到 OSS（按主题分类）
321:         video_url = output_path
322:         srt_url = srt_path
323:         if topic:
324:             oss_video_url = upload_file_to_oss_by_topic(output_path, topic, "video")
325:             if oss_video_url:
326:                 video_url = oss_video_url
327:             if srt_path and os.path.exists(srt_path):
328:                 oss_srt_url = upload_file_to_oss_by_topic(srt_path, topic, "video")
329:                 if oss_srt_url:
330:                     srt_url = oss_srt_url
331:         
332:         return video_url
333:         
334:     except Exception as e:
335:         print(f"[Editor Error] 视频导出失败: {e}")
336:         return None
337: 
338: 
339: def get_audio_duration(audio_path: str) -> float:
340:     """获取音频时长（秒）"""
341:     from moviepy import AudioFileClip
342:     
343:     try:
344:         audio = AudioFileClip(audio_path)
345:         duration = audio.duration
346:         audio.close()
347:         return duration
348:     except Exception as e:
349:         print(f"[Editor Error] 获取音频时长失败: {e}")
350:         return 0.0
351: 
352: 
353: def get_total_duration(audio_paths: list) -> float:
354:     """计算所有音频的总时长"""
355:     total = 0.0
356:     for path in audio_paths:
357:         if path and os.path.exists(path):
358:             total += get_audio_duration(path)
359:     return total
360: 
361: 
362: def _format_srt_time(seconds: float) -> str:
363:     """将秒数转换为 SRT 时间格式 (HH:MM:SS,mmm)"""
364:     hours = int(seconds // 3600)
365:     minutes = int((seconds % 3600) // 60)
366:     secs = int(seconds % 60)
367:     millis = int((seconds % 1) * 1000)
368:     return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
369: 
370: 
371: def generate_srt(scenes: list, audio_paths: list, output_path: str = None, topic: str = None) -> Optional[str]:
372:     """
373:     根据分镜和音频时长生成 SRT 字幕文件
374:     
375:     Args:
376:         scenes: 分镜列表，每个元素需包含 'narration' 字段
377:         audio_paths: 音频路径列表（用于计算时间轴）
378:         output_path: 输出路径，为空则自动生成
379:         topic: 主题名称（用于文件命名）
380:     
381:     Returns:
382:         SRT 文件路径，失败返回 None
383:     """
384:     if not scenes or not audio_paths:
385:         print("[SRT] 缺少分镜或音频数据")
386:         return None
387:     
388:     if not output_path:
389:         if topic:
390:             output_dir = get_unique_dir(DEFAULT_OUTPUT_DIR, topic)
391:             safe_topic = sanitize_filename(topic)
392:             output_path = str(output_dir / f"{safe_topic}.srt")
393:         else:
394:             output_path = str(DEFAULT_OUTPUT_DIR / "output.srt")
395:     
396:     srt_lines = []
397:     current_time = 0.0
398:     subtitle_index = 1
399:     
400:     for i, (scene, aud_path) in enumerate(zip(scenes, audio_paths)):
401:         # 获取该段音频时长
402:         if aud_path and os.path.exists(aud_path):
403:             duration = get_audio_duration(aud_path)
404:         else:
405:             duration = 3.0  # 默认 3 秒
406:         
407:         # 获取字幕文本
408:         narration = scene.get('narration', '')
409:         if not narration:
410:             current_time += duration
411:             continue
412:         
413:         # 计算时间戳
414:         start_time = current_time
415:         end_time = current_time + duration
416:         
417:         # 写入 SRT 格式
418:         srt_lines.append(str(subtitle_index))
419:         srt_lines.append(f"{_format_srt_time(start_time)} --> {_format_srt_time(end_time)}")
420:         srt_lines.append(narration)
421:         srt_lines.append("")  # 空行分隔
422:         
423:         subtitle_index += 1
424:         current_time = end_time
425:     
426:     if not srt_lines:
427:         print("[SRT] 无有效字幕内容")
428:         return None
429:     
430:     try:
431:         with open(output_path, "w", encoding="utf-8") as f:
432:             f.write("\n".join(srt_lines))
433:         print(f"[SRT] 字幕文件生成成功: {output_path}")
434:         return output_path
435:     except Exception as e:
436:         print(f"[SRT Error] 字幕文件生成失败: {e}")
437:         return None
</file>

<file path="modules/monitor.py">
  1: """
  2: 监控模块 - 数据采集与存储
  3: """
  4: import os
  5: import sqlite3
  6: import uuid
  7: from datetime import datetime, timedelta
  8: from pathlib import Path
  9: from typing import Optional
 10: 
 11: # 数据库路径
 12: DB_PATH = Path(__file__).parent.parent / "data" / "monitor.db"
 13: 
 14: 
 15: def _get_conn():
 16:     """获取数据库连接"""
 17:     DB_PATH.parent.mkdir(parents=True, exist_ok=True)
 18:     conn = sqlite3.connect(str(DB_PATH))
 19:     conn.row_factory = sqlite3.Row
 20:     return conn
 21: 
 22: 
 23: def init_db():
 24:     """初始化数据库表"""
 25:     conn = _get_conn()
 26:     cursor = conn.cursor()
 27:     
 28:     # API 调用记录
 29:     cursor.execute("""
 30:         CREATE TABLE IF NOT EXISTS api_calls (
 31:             id INTEGER PRIMARY KEY AUTOINCREMENT,
 32:             model TEXT NOT NULL,
 33:             tokens_in INTEGER DEFAULT 0,
 34:             tokens_out INTEGER DEFAULT 0,
 35:             created_at DATETIME DEFAULT CURRENT_TIMESTAMP
 36:         )
 37:     """)
 38:     
 39:     # 访问日志
 40:     cursor.execute("""
 41:         CREATE TABLE IF NOT EXISTS access_logs (
 42:             id INTEGER PRIMARY KEY AUTOINCREMENT,
 43:             session_id TEXT,
 44:             ip_address TEXT,
 45:             created_at DATETIME DEFAULT CURRENT_TIMESTAMP
 46:         )
 47:     """)
 48:     
 49:     # 生成历史
 50:     cursor.execute("""
 51:         CREATE TABLE IF NOT EXISTS generation_history (
 52:             id INTEGER PRIMARY KEY AUTOINCREMENT,
 53:             topic TEXT NOT NULL,
 54:             persona TEXT,
 55:             titles TEXT,
 56:             content_preview TEXT,
 57:             created_at DATETIME DEFAULT CURRENT_TIMESTAMP
 58:         )
 59:     """)
 60:     
 61:     conn.commit()
 62:     conn.close()
 63: 
 64: 
 65: # 初始化数据库
 66: init_db()
 67: 
 68: 
 69: def log_api_call(model: str, tokens_in: int = 0, tokens_out: int = 0):
 70:     """记录 API 调用"""
 71:     try:
 72:         conn = _get_conn()
 73:         cursor = conn.cursor()
 74:         cursor.execute(
 75:             "INSERT INTO api_calls (model, tokens_in, tokens_out) VALUES (?, ?, ?)",
 76:             (model, tokens_in, tokens_out)
 77:         )
 78:         conn.commit()
 79:         conn.close()
 80:     except Exception as e:
 81:         print(f"[Monitor] API 日志记录失败: {e}")
 82: 
 83: 
 84: def log_access(session_id: Optional[str] = None, ip_address: Optional[str] = None):
 85:     """记录访问日志"""
 86:     try:
 87:         conn = _get_conn()
 88:         cursor = conn.cursor()
 89:         cursor.execute(
 90:             "INSERT INTO access_logs (session_id, ip_address) VALUES (?, ?)",
 91:             (session_id or str(uuid.uuid4())[:8], ip_address)
 92:         )
 93:         conn.commit()
 94:         conn.close()
 95:     except Exception as e:
 96:         print(f"[Monitor] 访问日志记录失败: {e}")
 97: 
 98: 
 99: def log_generation(topic: str, persona: str, titles: list, content_preview: str):
100:     """记录生成历史"""
101:     try:
102:         conn = _get_conn()
103:         cursor = conn.cursor()
104:         titles_str = " | ".join(titles) if titles else ""
105:         cursor.execute(
106:             "INSERT INTO generation_history (topic, persona, titles, content_preview) VALUES (?, ?, ?, ?)",
107:             (topic, persona, titles_str, content_preview[:500])
108:         )
109:         conn.commit()
110:         conn.close()
111:     except Exception as e:
112:         print(f"[Monitor] 生成历史记录失败: {e}")
113: 
114: 
115: def get_stats() -> dict:
116:     """获取统计数据"""
117:     conn = _get_conn()
118:     cursor = conn.cursor()
119:     
120:     # 总调用次数
121:     cursor.execute("SELECT COUNT(*) as cnt FROM api_calls")
122:     total_calls = cursor.fetchone()['cnt']
123:     
124:     # 总 Token 消耗
125:     cursor.execute("SELECT COALESCE(SUM(tokens_in), 0) as t_in, COALESCE(SUM(tokens_out), 0) as t_out FROM api_calls")
126:     token_row = cursor.fetchone()
127:     total_tokens_in = token_row['t_in']
128:     total_tokens_out = token_row['t_out']
129:     
130:     # 今日调用
131:     today = datetime.now().strftime("%Y-%m-%d")
132:     cursor.execute("SELECT COUNT(*) as cnt FROM api_calls WHERE DATE(created_at) = ?", (today,))
133:     today_calls = cursor.fetchone()['cnt']
134:     
135:     # 今日 Token
136:     cursor.execute(
137:         "SELECT COALESCE(SUM(tokens_in), 0) as t_in, COALESCE(SUM(tokens_out), 0) as t_out FROM api_calls WHERE DATE(created_at) = ?",
138:         (today,)
139:     )
140:     today_token_row = cursor.fetchone()
141:     today_tokens_in = today_token_row['t_in']
142:     today_tokens_out = today_token_row['t_out']
143:     
144:     # 总访问次数
145:     cursor.execute("SELECT COUNT(*) as cnt FROM access_logs")
146:     total_access = cursor.fetchone()['cnt']
147:     
148:     # 总生成次数
149:     cursor.execute("SELECT COUNT(*) as cnt FROM generation_history")
150:     total_generations = cursor.fetchone()['cnt']
151:     
152:     conn.close()
153:     
154:     return {
155:         "total_calls": total_calls,
156:         "total_tokens_in": total_tokens_in,
157:         "total_tokens_out": total_tokens_out,
158:         "today_calls": today_calls,
159:         "today_tokens_in": today_tokens_in,
160:         "today_tokens_out": today_tokens_out,
161:         "total_access": total_access,
162:         "total_generations": total_generations,
163:     }
164: 
165: 
166: def get_api_calls(limit: int = 50) -> list:
167:     """获取最近 API 调用记录"""
168:     conn = _get_conn()
169:     cursor = conn.cursor()
170:     cursor.execute(
171:         "SELECT * FROM api_calls ORDER BY created_at DESC LIMIT ?",
172:         (limit,)
173:     )
174:     rows = [dict(row) for row in cursor.fetchall()]
175:     conn.close()
176:     return rows
177: 
178: 
179: def get_access_logs(limit: int = 50) -> list:
180:     """获取最近访问日志"""
181:     conn = _get_conn()
182:     cursor = conn.cursor()
183:     cursor.execute(
184:         "SELECT * FROM access_logs ORDER BY created_at DESC LIMIT ?",
185:         (limit,)
186:     )
187:     rows = [dict(row) for row in cursor.fetchall()]
188:     conn.close()
189:     return rows
190: 
191: 
192: def get_generation_history(limit: int = 50, search: str = None) -> list:
193:     """获取生成历史"""
194:     conn = _get_conn()
195:     cursor = conn.cursor()
196:     
197:     if search:
198:         cursor.execute(
199:             "SELECT * FROM generation_history WHERE topic LIKE ? OR titles LIKE ? ORDER BY created_at DESC LIMIT ?",
200:             (f"%{search}%", f"%{search}%", limit)
201:         )
202:     else:
203:         cursor.execute(
204:             "SELECT * FROM generation_history ORDER BY created_at DESC LIMIT ?",
205:             (limit,)
206:         )
207:     
208:     rows = [dict(row) for row in cursor.fetchall()]
209:     conn.close()
210:     return rows
211: 
212: 
213: def get_daily_stats(days: int = 7) -> list:
214:     """获取每日统计（用于趋势图）"""
215:     conn = _get_conn()
216:     cursor = conn.cursor()
217:     
218:     results = []
219:     for i in range(days - 1, -1, -1):
220:         date = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
221:         
222:         cursor.execute(
223:             "SELECT COUNT(*) as calls, COALESCE(SUM(tokens_in + tokens_out), 0) as tokens FROM api_calls WHERE DATE(created_at) = ?",
224:             (date,)
225:         )
226:         row = cursor.fetchone()
227:         
228:         results.append({
229:             "date": date,
230:             "calls": row['calls'],
231:             "tokens": row['tokens']
232:         })
233:     
234:     conn.close()
235:     return results
</file>

<file path="modules/persona.py">
 1: """
 2: 人设库读取模块
 3: """
 4: import os
 5: import json
 6: 
 7: DATA_PATH = os.path.join(os.path.dirname(__file__), '..', 'data', 'personas.json')
 8: 
 9: 
10: def load_personas() -> dict:
11:     """加载人设库"""
12:     with open(DATA_PATH, 'r', encoding='utf-8') as f:
13:         return json.load(f)
14: 
15: 
16: def get_categories() -> list:
17:     """获取所有场景分类"""
18:     personas = load_personas()
19:     return list(personas.keys())
20: 
21: 
22: def get_personas_by_category(category: str) -> list:
23:     """获取指定分类下的所有人设"""
24:     personas = load_personas()
25:     return personas.get(category, [])
26: 
27: 
28: def get_persona_prompt(category: str, name: str) -> str:
29:     """获取指定人设的完整 prompt"""
30:     personas = get_personas_by_category(category)
31:     for p in personas:
32:         if p['name'] == name:
33:             return p.get('prompt', '')
34:     return ''
</file>

<file path="modules/quality_checker.py">
  1: """
  2: 文案质量检测模块
  3: 检测 AI 生成文案的质量，识别 AI 套话、缺乏具体性等问题
  4: """
  5: import re
  6: 
  7: 
  8: # AI 套话黑名单
  9: AI_CLICHES = [
 10:     "众所周知", "不得不说", "可以说是", "值得一提的是",
 11:     "在.*?方面", "进行.*?操作", "相关的",
 12:     "总而言之", "综上所述", "由此可见",
 13:     "首先.*?其次.*?最后", "第一.*?第二.*?第三",
 14: ]
 15: 
 16: # 强情绪词白名单（应该出现）
 17: EMOTION_WORDS = [
 18:     "绝了", "太爱了", "崩溃", "yyds", "救命", "爱了爱了",
 19:     "真的", "超级", "巨", "疯了", "炸了", "绝绝子",
 20:     "！", "？", "🔥", "💯", "✨", "❤️", "😭", "🥺"
 21: ]
 22: 
 23: 
 24: def check_content_quality(content: str) -> dict:
 25:     """
 26:     检测文案质量，返回评分和问题诊断
 27:     
 28:     Args:
 29:         content: 待检测的文案内容
 30:     
 31:     Returns:
 32:         {
 33:             "score": 0-100,
 34:             "is_acceptable": bool,  # 分数 >= 70 为合格
 35:             "issues": ["过于AI", "缺乏具体案例"],
 36:             "suggestions": ["增加个人经历", "添加具体数字"],
 37:             "details": {
 38:                 "ai_cliche_count": 数量,
 39:                 "number_count": 数量,
 40:                 "emotion_count": 数量,
 41:                 "length": 字数
 42:             }
 43:         }
 44:     """
 45:     score = 100
 46:     issues = []
 47:     suggestions = []
 48:     
 49:     # 1. 检测 AI 套话（每出现一次扣 10 分）
 50:     ai_cliche_count = 0
 51:     for cliche in AI_CLICHES:
 52:         matches = re.findall(cliche, content)
 53:         ai_cliche_count += len(matches)
 54:     
 55:     if ai_cliche_count > 0:
 56:         score -= min(ai_cliche_count * 10, 40)  # 最多扣 40 分
 57:         issues.append(f"检测到 {ai_cliche_count} 处 AI 套话")
 58:         suggestions.append("避免使用'众所周知'、'不得不说'等机械表达")
 59:     
 60:     # 2. 检测具体数字（至少应有 2 个）
 61:     number_pattern = r'\d+\.?\d*[万千百十]?[年月日天小时分钟秒次个人块元]|\d+%'
 62:     numbers = re.findall(number_pattern, content)
 63:     number_count = len(numbers)
 64:     
 65:     if number_count < 2:
 66:         score -= 15
 67:         issues.append(f"具体数字不足（仅 {number_count} 处）")
 68:         suggestions.append("增加具体数字：如'涨粉 3000'、'连续 15 天'等")
 69:     
 70:     # 3. 检测个人经历标记（"我"、"我朋友"、"我同事"等）
 71:     personal_patterns = [
 72:         r'我[的是有在]', r'我朋友', r'我同事', r'我见过',
 73:         r'上次.*?时', r'那天', r'当时',
 74:     ]
 75:     personal_count = sum(len(re.findall(p, content)) for p in personal_patterns)
 76:     
 77:     if personal_count < 1:
 78:         score -= 15
 79:         issues.append("缺乏个人经历")
 80:         suggestions.append("加入个人故事：'我有个朋友...'、'上次我...'")
 81:     
 82:     # 4. 检测强情绪表达（至少 3 处）
 83:     emotion_count = sum(content.count(word) for word in EMOTION_WORDS)
 84:     
 85:     if emotion_count < 3:
 86:         score -= 10
 87:         issues.append(f"情绪表达不足（仅 {emotion_count} 处）")
 88:         suggestions.append("增加强情绪词：'绝了'、'太爱了'、感叹号、emoji 等")
 89:     
 90:     # 5. 检测反问句（至少 1 处）
 91:     question_count = content.count("？") + content.count("吗？") + content.count("呢？")
 92:     if question_count < 1:
 93:         score -= 10
 94:         issues.append("缺乏互动性反问")
 95:         suggestions.append("加入反问句：'你知道为什么吗？'、'是不是很离谱？'")
 96:     
 97:     # 6. 检测字数（图文模式要求 800+ 字）
 98:     length = len(content)
 99:     if length < 800:
100:         score -= 20
101:         issues.append(f"字数不足（仅 {length} 字，要求 800+ 字）")
102:         suggestions.append("深化内容：每个要点展开至少 150-200 字")
103:     
104:     # 确保分数在 0-100 范围内
105:     score = max(0, min(100, score))
106:     
107:     return {
108:         "score": score,
109:         "is_acceptable": score >= 70,
110:         "issues": issues,
111:         "suggestions": suggestions,
112:         "details": {
113:             "ai_cliche_count": ai_cliche_count,
114:             "number_count": number_count,
115:             "personal_count": personal_count,
116:             "emotion_count": emotion_count,
117:             "question_count": question_count,
118:             "length": length,
119:         }
120:     }
121: 
122: 
123: def format_quality_report(quality: dict) -> str:
124:     """格式化质量报告为可读文本"""
125:     report = f"【质量评分】{quality['score']}/100\n"
126:     
127:     if quality['is_acceptable']:
128:         report += "✅ 质量合格\n"
129:     else:
130:         report += "❌ 质量不达标\n"
131:     
132:     if quality['issues']:
133:         report += "\n【问题诊断】\n"
134:         for issue in quality['issues']:
135:             report += f"  - {issue}\n"
136:     
137:     if quality['suggestions']:
138:         report += "\n【优化建议】\n"
139:         for suggestion in quality['suggestions']:
140:             report += f"  - {suggestion}\n"
141:     
142:     return report
</file>

<file path="modules/utils.py">
  1: """
  2: 工具模块 - 状态缓存、安全调用、统一提示、文件命名
  3: """
  4: import os
  5: import re
  6: import json
  7: import traceback
  8: from pathlib import Path
  9: from typing import Any, Callable, Optional
 10: from functools import wraps
 11: 
 12: # 缓存目录
 13: CACHE_DIR = Path("output/.cache")
 14: CACHE_DIR.mkdir(parents=True, exist_ok=True)
 15: 
 16: 
 17: # ========== 文件命名工具 ==========
 18: 
 19: def sanitize_filename(name: str, max_length: int = 50) -> str:
 20:     """
 21:     清理文件名中的非法字符，生成安全的文件名
 22:     
 23:     Args:
 24:         name: 原始名称（如主题）
 25:         max_length: 最大长度
 26:     
 27:     Returns:
 28:         安全的文件名
 29:     """
 30:     if not name:
 31:         return "untitled"
 32:     
 33:     # 替换非法字符为下划线
 34:     # Windows 非法字符: \ / : * ? " < > |
 35:     # 加上空格和一些特殊符号
 36:     illegal_chars = r'[\\/:*?"<>|\s\n\r\t]+'
 37:     safe_name = re.sub(illegal_chars, '_', name)
 38:     
 39:     # 移除开头和结尾的下划线
 40:     safe_name = safe_name.strip('_')
 41:     
 42:     # 限制长度
 43:     if len(safe_name) > max_length:
 44:         safe_name = safe_name[:max_length].rstrip('_')
 45:     
 46:     return safe_name or "untitled"
 47: 
 48: 
 49: def get_unique_dir(base_dir: Path, topic: str) -> Path:
 50:     """
 51:     创建基于主题的唯一目录，重复时自动添加数字后缀
 52:     
 53:     Args:
 54:         base_dir: 基础目录（如 output/images）
 55:         topic: 主题名称
 56:     
 57:     Returns:
 58:         唯一的目录路径（已创建）
 59:     
 60:     Example:
 61:         topic = "职场攻略"
 62:         第一次: output/images/职场攻略/
 63:         第二次: output/images/职场攻略_2/
 64:         第三次: output/images/职场攻略_3/
 65:     """
 66:     safe_topic = sanitize_filename(topic)
 67:     
 68:     # 尝试基础名称
 69:     target_dir = base_dir / safe_topic
 70:     if not target_dir.exists():
 71:         target_dir.mkdir(parents=True, exist_ok=True)
 72:         return target_dir
 73:     
 74:     # 已存在，添加数字后缀
 75:     counter = 2
 76:     while True:
 77:         target_dir = base_dir / f"{safe_topic}_{counter}"
 78:         if not target_dir.exists():
 79:             target_dir.mkdir(parents=True, exist_ok=True)
 80:             return target_dir
 81:         counter += 1
 82:         if counter > 1000:  # 防止无限循环
 83:             raise RuntimeError(f"无法创建目录: {base_dir}/{safe_topic}")
 84: 
 85: 
 86: def get_topic_output_dir(topic: str, asset_type: str = "images") -> Path:
 87:     """
 88:     获取基于主题的输出目录
 89:     
 90:     Args:
 91:         topic: 主题名称
 92:         asset_type: 资产类型 ("images", "audio", "video")
 93:     
 94:     Returns:
 95:         目录路径（已创建）
 96:     """
 97:     base_dirs = {
 98:         "images": Path("output/images"),
 99:         "audio": Path("output/audio"),
100:         "video": Path("output/video"),
101:     }
102:     base_dir = base_dirs.get(asset_type, Path(f"output/{asset_type}"))
103:     return get_unique_dir(base_dir, topic)
104: 
105: 
106: # ========== 状态缓存 ==========
107: 
108: def save_state(key: str, data: Any) -> bool:
109:     """
110:     保存状态到本地缓存
111:     
112:     Args:
113:         key: 缓存键名
114:         data: 要缓存的数据（需支持 JSON 序列化）
115:     
116:     Returns:
117:         成功返回 True，失败返回 False
118:     """
119:     try:
120:         cache_file = CACHE_DIR / f"{key}.json"
121:         with open(cache_file, "w", encoding="utf-8") as f:
122:             json.dump(data, f, ensure_ascii=False, indent=2)
123:         return True
124:     except Exception as e:
125:         print(f"[Cache Error] 保存 {key} 失败: {e}")
126:         return False
127: 
128: 
129: def load_state(key: str, default: Any = None) -> Any:
130:     """
131:     从本地缓存加载状态
132:     
133:     Args:
134:         key: 缓存键名
135:         default: 缓存不存在时的默认值
136:     
137:     Returns:
138:         缓存数据或默认值
139:     """
140:     try:
141:         cache_file = CACHE_DIR / f"{key}.json"
142:         if cache_file.exists():
143:             with open(cache_file, "r", encoding="utf-8") as f:
144:                 return json.load(f)
145:         return default
146:     except Exception as e:
147:         print(f"[Cache Error] 加载 {key} 失败: {e}")
148:         return default
149: 
150: 
151: def clear_state(key: str = None) -> bool:
152:     """
153:     清除缓存
154:     
155:     Args:
156:         key: 指定键名，为空则清除所有缓存
157:     
158:     Returns:
159:         成功返回 True
160:     """
161:     try:
162:         if key:
163:             cache_file = CACHE_DIR / f"{key}.json"
164:             if cache_file.exists():
165:                 cache_file.unlink()
166:         else:
167:             for f in CACHE_DIR.glob("*.json"):
168:                 f.unlink()
169:         return True
170:     except Exception as e:
171:         print(f"[Cache Error] 清除缓存失败: {e}")
172:         return False
173: 
174: 
175: # ========== 安全调用 ==========
176: 
177: def safe_call(func: Callable, *args, default: Any = None, error_msg: str = None, **kwargs) -> Any:
178:     """
179:     安全调用函数，捕获所有异常
180:     
181:     Args:
182:         func: 要调用的函数
183:         *args: 位置参数
184:         default: 异常时的默认返回值
185:         error_msg: 自定义错误消息前缀
186:         **kwargs: 关键字参数
187:     
188:     Returns:
189:         函数返回值或默认值
190:     """
191:     try:
192:         return func(*args, **kwargs)
193:     except Exception as e:
194:         prefix = error_msg or f"[{func.__name__}]"
195:         print(f"{prefix} 调用失败: {e}")
196:         traceback.print_exc()
197:         return default
198: 
199: 
200: def retry_call(func: Callable, *args, retries: int = 3, delay: float = 1.0, default: Any = None, **kwargs) -> Any:
201:     """
202:     带重试的安全调用
203:     
204:     Args:
205:         func: 要调用的函数
206:         *args: 位置参数
207:         retries: 最大重试次数
208:         delay: 重试间隔（秒）
209:         default: 全部失败后的默认值
210:         **kwargs: 关键字参数
211:     
212:     Returns:
213:         函数返回值或默认值
214:     """
215:     import time
216:     
217:     last_error = None
218:     for attempt in range(retries):
219:         try:
220:             return func(*args, **kwargs)
221:         except Exception as e:
222:             last_error = e
223:             print(f"[Retry] 第 {attempt + 1}/{retries} 次尝试失败: {e}")
224:             if attempt < retries - 1:
225:                 time.sleep(delay)
226:     
227:     print(f"[Retry] 全部 {retries} 次尝试均失败")
228:     return default
229: 
230: 
231: # ========== 结果包装 ==========
232: 
233: class Result:
234:     """统一的结果包装类"""
235:     
236:     def __init__(self, success: bool, data: Any = None, error: str = None):
237:         self.success = success
238:         self.data = data
239:         self.error = error
240:     
241:     @classmethod
242:     def ok(cls, data: Any = None):
243:         return cls(success=True, data=data)
244:     
245:     @classmethod
246:     def fail(cls, error: str):
247:         return cls(success=False, error=error)
248:     
249:     def __bool__(self):
250:         return self.success
251:     
252:     def to_dict(self) -> dict:
253:         return {
254:             "success": self.success,
255:             "data": self.data,
256:             "error": self.error
257:         }
258: 
259: 
260: # ========== 素材状态 ==========
261: 
262: class AssetStatus:
263:     """素材生成状态追踪"""
264:     
265:     PENDING = "pending"      # 待生成
266:     GENERATING = "generating"  # 生成中
267:     SUCCESS = "success"      # 成功
268:     FAILED = "failed"        # 失败
269:     
270:     def __init__(self, total: int):
271:         self.total = total
272:         self.statuses = [self.PENDING] * total
273:         self.paths = [None] * total
274:         self.errors = [None] * total
275:     
276:     def set_generating(self, index: int):
277:         self.statuses[index] = self.GENERATING
278:     
279:     def set_success(self, index: int, path: str):
280:         self.statuses[index] = self.SUCCESS
281:         self.paths[index] = path
282:     
283:     def set_failed(self, index: int, error: str):
284:         self.statuses[index] = self.FAILED
285:         self.errors[index] = error
286:     
287:     @property
288:     def success_count(self) -> int:
289:         return self.statuses.count(self.SUCCESS)
290:     
291:     @property
292:     def failed_count(self) -> int:
293:         return self.statuses.count(self.FAILED)
294:     
295:     @property
296:     def pending_indices(self) -> list:
297:         return [i for i, s in enumerate(self.statuses) if s == self.PENDING]
298:     
299:     @property
300:     def failed_indices(self) -> list:
301:         return [i for i, s in enumerate(self.statuses) if s == self.FAILED]
302:     
303:     @property
304:     def all_done(self) -> bool:
305:         return all(s in [self.SUCCESS, self.FAILED] for s in self.statuses)
306:     
307:     @property
308:     def all_success(self) -> bool:
309:         return all(s == self.SUCCESS for s in self.statuses)
310:     
311:     def get_status_icon(self, index: int) -> str:
312:         status = self.statuses[index]
313:         return {
314:             self.PENDING: "⏳",
315:             self.GENERATING: "🔄",
316:             self.SUCCESS: "✅",
317:             self.FAILED: "❌"
318:         }.get(status, "❓")
319:     
320:     def to_dict(self) -> dict:
321:         return {
322:             "total": self.total,
323:             "statuses": self.statuses,
324:             "paths": self.paths,
325:             "errors": self.errors
326:         }
327:     
328:     @classmethod
329:     def from_dict(cls, data: dict) -> "AssetStatus":
330:         obj = cls(data["total"])
331:         obj.statuses = data["statuses"]
332:         obj.paths = data["paths"]
333:         obj.errors = data["errors"]
334:         return obj
335: 
336: 
337: # ========== Streamlit 辅助 ==========
338: 
339: def init_session_key(st, key: str, default: Any = None, load_cache: bool = False):
340:     """
341:     初始化 session state 键，可选从缓存恢复
342:     
343:     Args:
344:         st: streamlit 模块
345:         key: 键名
346:         default: 默认值
347:         load_cache: 是否尝试从缓存加载
348:     """
349:     if key not in st.session_state:
350:         if load_cache:
351:             cached = load_state(key)
352:             st.session_state[key] = cached if cached is not None else default
353:         else:
354:             st.session_state[key] = default
355: 
356: 
357: def auto_save_state(st, key: str):
358:     """
359:     自动保存 session state 到缓存
360:     
361:     Args:
362:         st: streamlit 模块
363:         key: 要保存的键名
364:     """
365:     if key in st.session_state and st.session_state[key] is not None:
366:         save_state(key, st.session_state[key])
</file>

<file path="backend/routers/config.py">
  1: """
  2: 配置 API（语音列表、模型列表、人设库等）
  3: """
  4: from fastapi import APIRouter
  5: from pydantic import BaseModel
  6: from typing import List, Dict
  7: 
  8: from modules.persona import get_categories, get_personas_by_category
  9: from modules.audio import EDGE_VOICES, VOLC_VOICES
 10: 
 11: router = APIRouter()
 12: 
 13: 
 14: # ========== 模型配置 ==========
 15: 
 16: AVAILABLE_MODELS = {
 17:     "DeepSeek Chat (高情商/国产梗)": "deepseek/deepseek-chat",
 18:     "Claude 3.5 Sonnet (拟人感最强)": "anthropic/claude-3.5-sonnet",
 19:     "GPT-4o (逻辑严密)": "openai/gpt-4o",
 20:     "Gemini Pro 1.5 (长文强)": "google/gemini-pro-1.5",
 21:     "Grok 2 (马斯克/幽默)": "x-ai/grok-2-1212",
 22: }
 23: 
 24: IMAGE_PROVIDERS = {
 25:     "replicate": "Replicate (二次元)",
 26:     "volcengine": "火山引擎 (Seedream)",
 27:     "gemini": "Nano Banana Pro (超高质量)",
 28: }
 29: 
 30: TTS_PROVIDERS = {
 31:     "edge": "Edge TTS (免费)",
 32:     "volcengine": "火山引擎 TTS",
 33: }
 34: 
 35: 
 36: class VoiceOption(BaseModel):
 37:     label: str
 38:     value: str
 39: 
 40: 
 41: class ModelOption(BaseModel):
 42:     label: str
 43:     value: str
 44: 
 45: 
 46: class PersonaItem(BaseModel):
 47:     name: str
 48:     prompt: str
 49: 
 50: 
 51: class PersonaCategory(BaseModel):
 52:     category: str
 53:     personas: List[PersonaItem]
 54: 
 55: 
 56: @router.get("/models")
 57: async def get_models():
 58:     """获取可用的 LLM 模型列表"""
 59:     return {
 60:         "models": [
 61:             ModelOption(label=label, value=value)
 62:             for label, value in AVAILABLE_MODELS.items()
 63:         ]
 64:     }
 65: 
 66: 
 67: @router.get("/image-providers")
 68: async def get_image_providers():
 69:     """获取生图服务列表"""
 70:     return {
 71:         "providers": [
 72:             {"label": label, "value": value}
 73:             for value, label in IMAGE_PROVIDERS.items()
 74:         ]
 75:     }
 76: 
 77: 
 78: @router.get("/tts-providers")
 79: async def get_tts_providers():
 80:     """获取 TTS 服务列表"""
 81:     return {
 82:         "providers": [
 83:             {"label": label, "value": value}
 84:             for value, label in TTS_PROVIDERS.items()
 85:         ]
 86:     }
 87: 
 88: 
 89: @router.get("/voices")
 90: async def get_voices():
 91:     """获取所有可用语音角色"""
 92:     return {
 93:         "edge": [
 94:             VoiceOption(label=label, value=value)
 95:             for label, value in EDGE_VOICES.items()
 96:         ],
 97:         "volcengine": [
 98:             VoiceOption(label=label, value=value)
 99:             for label, value in VOLC_VOICES.items()
100:         ],
101:     }
102: 
103: 
104: @router.get("/voices/{provider}")
105: async def get_voices_by_provider(provider: str):
106:     """获取指定 TTS 服务的语音角色"""
107:     if provider == "edge":
108:         voices = EDGE_VOICES
109:     elif provider == "volcengine":
110:         voices = VOLC_VOICES
111:     else:
112:         return {"voices": []}
113:     
114:     return {
115:         "voices": [
116:             VoiceOption(label=label, value=value)
117:             for label, value in voices.items()
118:         ]
119:     }
120: 
121: 
122: @router.get("/personas")
123: async def get_personas():
124:     """获取所有人设分类和人设"""
125:     categories = get_categories()
126:     
127:     result = []
128:     for cat in categories:
129:         personas = get_personas_by_category(cat)
130:         result.append(PersonaCategory(
131:             category=cat,
132:             personas=[
133:                 PersonaItem(name=p["name"], prompt=p.get("prompt", ""))
134:                 for p in personas
135:             ],
136:         ))
137:     
138:     return {"categories": result}
139: 
140: 
141: @router.get("/personas/{category}")
142: async def get_personas_in_category(category: str):
143:     """获取指定分类下的人设"""
144:     personas = get_personas_by_category(category)
145:     return {
146:         "personas": [
147:             PersonaItem(name=p["name"], prompt=p.get("prompt", ""))
148:             for p in personas
149:         ]
150:     }
</file>

<file path="backend/routers/topics.py">
  1: """
  2: 选题分析 API
  3: """
  4: from fastapi import APIRouter, HTTPException
  5: from pydantic import BaseModel
  6: from typing import List, Optional, Dict
  7: from datetime import datetime, timedelta
  8: 
  9: from modules.trend import analyze_trends
 10: 
 11: router = APIRouter()
 12: 
 13: # 简单内存缓存（生产环境建议用 Redis）
 14: _topics_cache: Dict[str, dict] = {}
 15: 
 16: 
 17: class TopicItem(BaseModel):
 18:     title: str
 19:     source: str = ""
 20:     summary: str = ""
 21:     outline: List[str] = []
 22:     why_hot: str = ""
 23: 
 24: 
 25: class AnalyzeRequest(BaseModel):
 26:     keyword: str
 27:     mode: str = "websearch"  # "websearch" | "llm"
 28: 
 29: 
 30: class AnalyzeResponse(BaseModel):
 31:     topics: List[TopicItem]
 32:     source: str  # "websearch" | "fallback" | "error"
 33: 
 34: 
 35: @router.post("/analyze", response_model=AnalyzeResponse)
 36: async def analyze_topic(req: AnalyzeRequest):
 37:     """
 38:     根据关键词分析热门选题
 39:     
 40:     使用火山引擎联网搜索，获取小红书/抖音/微博热点
 41:     支持 6 小时缓存，相同关键词直接返回缓存结果
 42:     """
 43:     if not req.keyword or not req.keyword.strip():
 44:         raise HTTPException(status_code=400, detail="关键词不能为空")
 45:     
 46:     # 统一关键词格式（小写，避免大小写重复）
 47:     keyword = req.keyword.strip().lower()
 48:     
 49:     # 快速模式：直接用 LLM 推荐（不联网搜索）
 50:     if req.mode == "llm":
 51:         print(f"[Topics LLM Mode] 快速推荐: {keyword}")
 52:         topics_raw, source = analyze_trends(req.keyword.strip(), force_fallback=True)
 53:         
 54:         topics = []
 55:         for t in topics_raw:
 56:             if isinstance(t, str):
 57:                 topics.append(TopicItem(title=t))
 58:             elif isinstance(t, dict):
 59:                 topics.append(TopicItem(
 60:                     title=t.get("title", ""),
 61:                     source=t.get("source", "AI推荐"),
 62:                     summary=t.get("summary", ""),
 63:                     outline=t.get("outline", []),
 64:                     why_hot=t.get("why_hot", ""),
 65:                 ))
 66:         
 67:         return AnalyzeResponse(topics=topics, source="llm")
 68:     
 69:     # 检查缓存（仅 websearch 模式）
 70:     if keyword in _topics_cache:
 71:         cached = _topics_cache[keyword]
 72:         cached_time = datetime.fromisoformat(cached['timestamp'])
 73:         
 74:         # 6小时内有效
 75:         if datetime.now() - cached_time < timedelta(hours=6):
 76:             print(f"[Topics Cache Hit] 使用缓存数据: {keyword}")
 77:             return AnalyzeResponse(
 78:                 topics=cached['topics'],
 79:                 source=cached['source'] + "_cached"
 80:             )
 81:         else:
 82:             # 缓存过期，删除
 83:             print(f"[Topics Cache Expired] 缓存已过期: {keyword}")
 84:             del _topics_cache[keyword]
 85:     
 86:     # 缓存未命中，执行实际搜索
 87:     print(f"[Topics Cache Miss] 执行实际搜索: {keyword}")
 88:     
 89:     try:
 90:         topics_raw, source = analyze_trends(req.keyword.strip())
 91:         
 92:         # 标准化数据格式
 93:         topics = []
 94:         for t in topics_raw:
 95:             if isinstance(t, str):
 96:                 # 兼容旧格式
 97:                 topics.append(TopicItem(title=t))
 98:             elif isinstance(t, dict):
 99:                 topics.append(TopicItem(
100:                     title=t.get("title", ""),
101:                     source=t.get("source", ""),
102:                     summary=t.get("summary", ""),
103:                     outline=t.get("outline", []),
104:                     why_hot=t.get("why_hot", ""),
105:                 ))
106:         
107:         # 只缓存成功的搜索结果（source == "websearch"）
108:         if source == "websearch" and topics:
109:             _topics_cache[keyword] = {
110:                 'topics': [t.dict() for t in topics],
111:                 'source': source,
112:                 'timestamp': datetime.now().isoformat()
113:             }
114:             print(f"[Topics Cache Saved] 缓存已保存: {keyword}, 过期时间: {datetime.now() + timedelta(hours=6)}")
115:         else:
116:             print(f"[Topics Cache Skip] 跳过缓存（source={source}，仅缓存成功的websearch结果）")
117:         
118:         return AnalyzeResponse(topics=topics, source=source)
119:         
120:     except Exception as e:
121:         raise HTTPException(status_code=500, detail=f"选题分析失败: {str(e)}")
</file>

<file path="frontend/src/app/layout.tsx">
 1: import type { Metadata } from "next";
 2: import { Plus_Jakarta_Sans, JetBrains_Mono } from "next/font/google";
 3: import { Toaster } from "@/components/ui/sonner";
 4: import { ThemeProvider } from "@/components/theme-provider";
 5: import "./globals.css";
 6: 
 7: const jakarta = Plus_Jakarta_Sans({
 8:   variable: "--font-geist-sans",
 9:   subsets: ["latin"],
10:   display: "swap",
11: });
12: 
13: const jetbrainsMono = JetBrains_Mono({
14:   variable: "--font-geist-mono",
15:   subsets: ["latin"],
16:   display: "swap",
17: });
18: 
19: export const metadata: Metadata = {
20:   title: "小红书内容工作流",
21:   description: "AI 驱动的小红书内容创作平台",
22: };
23: 
24: export default function RootLayout({
25:   children,
26: }: Readonly<{
27:   children: React.ReactNode;
28: }>) {
29:   return (
30:     <html lang="zh-CN" suppressHydrationWarning>
31:       <body
32:         className={`${jakarta.variable} ${jetbrainsMono.variable} antialiased font-sans`}
33:       >
34:         <ThemeProvider
35:           attribute="class"
36:           defaultTheme="system"
37:           enableSystem
38:           disableTransitionOnChange
39:         >
40:           {children}
41:           <Toaster position="bottom-right" richColors />
42:         </ThemeProvider>
43:       </body>
44:     </html>
45:   );
46: }
</file>

<file path="frontend/src/app/page.tsx">
  1: "use client";
  2: 
  3: import { useState, useEffect } from "react";
  4: import { motion, AnimatePresence } from "framer-motion";
  5: import { cn } from "@/lib/utils";
  6: import { Sidebar, Header } from "@/components/layout";
  7: import {
  8:   TopicRadar,
  9:   PersonaConfig,
 10:   ContentPreview,
 11:   MediaStudio,
 12: } from "@/components/blocks";
 13: import { useWorkflowStore } from "@/store/workflow";
 14: import { checkHealth, getModels, getVoices, getPersonas, getBgmList, exportNote } from "@/lib/api";
 15: import { toast } from "sonner";
 16: import { Badge } from "@/components/ui/badge";
 17: import { Separator } from "@/components/ui/separator";
 18: import { Button } from "@/components/ui/button";
 19: import { Download, Loader2 } from "lucide-react";
 20: 
 21: export default function Home() {
 22:   const [sidebarCollapsed, setSidebarCollapsed] = useState(false);
 23:   const [mounted, setMounted] = useState(false);
 24:   const [isExporting, setIsExporting] = useState(false);
 25:   const {
 26:     mode,
 27:     currentStep,
 28:     generatedContent,
 29:     selectedTopic,
 30:     selectedTitleIndex,
 31:     imageResults,
 32:     setAvailableModels,
 33:     setAvailableVoices,
 34:     setAvailablePersonas,
 35:     setAvailableBgm,
 36:   } = useWorkflowStore();
 37: 
 38:   // Hydration fix
 39:   useEffect(() => {
 40:     setMounted(true);
 41:   }, []);
 42: 
 43:   // Load config data on mount
 44:   useEffect(() => {
 45:     const loadConfig = async () => {
 46:       try {
 47:         // Check health
 48:         const health = await checkHealth();
 49:         if (!health.openrouter) {
 50:           toast.warning("OpenRouter API 未配置，写作功能可能受限");
 51:         }
 52: 
 53:         // Load models, voices, personas
 54:         const [modelsRes, voicesRes, personasRes] = await Promise.all([
 55:           getModels().catch(() => ({ models: [] })),
 56:           getVoices().catch(() => ({ edge: [], volcengine: [] })),
 57:           getPersonas().catch(() => ({ categories: [] })),
 58:         ]);
 59: 
 60:         setAvailableModels(modelsRes.models);
 61:         setAvailableVoices(voicesRes);
 62:         setAvailablePersonas(personasRes.categories);
 63: 
 64:         // Load BGM list if in video mode
 65:         if (mode === "video") {
 66:           const bgmRes = await getBgmList().catch(() => ({ bgm_list: [] }));
 67:           setAvailableBgm(bgmRes.bgm_list);
 68:         }
 69:       } catch (error) {
 70:         console.error("Failed to load config:", error);
 71:         toast.error("后端连接失败，请确保服务已启动");
 72:       }
 73:     };
 74: 
 75:     loadConfig();
 76:   }, [mode, setAvailableModels, setAvailableVoices, setAvailablePersonas, setAvailableBgm]);
 77: 
 78:   const handleExportNote = async () => {
 79:     if (!generatedContent || !selectedTopic) return;
 80:     
 81:     setIsExporting(true);
 82:     try {
 83:       const title = generatedContent.titles[selectedTitleIndex] || generatedContent.titles[0];
 84:       const imageUrls = imageResults
 85:         .filter((r) => r?.url)
 86:         .map((r) => r.url as string);
 87:       
 88:       const response = await exportNote({
 89:         topic: selectedTopic.title,
 90:         title,
 91:         content: generatedContent.content,
 92:         image_urls: imageUrls.length > 0 ? imageUrls : undefined,
 93:         tags: ["小红书", selectedTopic.source || "自动生成"],
 94:       });
 95:       
 96:       if (response.success) {
 97:         toast.success("笔记已导出到 Obsidian");
 98:       } else {
 99:         toast.error("导出失败: " + (response.error || "未知错误"));
100:       }
101:     } catch (error) {
102:       toast.error("导出失败: " + (error as Error).message);
103:     } finally {
104:       setIsExporting(false);
105:     }
106:   };
107: 
108:   if (!mounted) {
109:     return null;
110:   }
111: 
112:   return (
113:     <div className="flex h-screen overflow-hidden bg-background">
114:       {/* Sidebar */}
115:       <Sidebar collapsed={sidebarCollapsed} onToggle={() => setSidebarCollapsed(!sidebarCollapsed)} />
116: 
117:       {/* Main Content */}
118:       <div className="flex-1 flex flex-col overflow-hidden">
119:         <Header />
120: 
121:         <main className="flex-1 overflow-auto">
122:           <div className="max-w-4xl mx-auto px-6 py-8 space-y-8">
123:             {/* Step 1: Topic Radar */}
124:             <motion.div
125:               initial={{ opacity: 0, y: 20 }}
126:               animate={{ opacity: 1, y: 0 }}
127:               transition={{ duration: 0.3 }}
128:             >
129:               <TopicRadar />
130:             </motion.div>
131: 
132:             <Separator className="my-8" />
133: 
134:             {/* Step 2: Persona Config */}
135:             <motion.div
136:               initial={{ opacity: 0, y: 20 }}
137:               animate={{ opacity: 1, y: 0 }}
138:               transition={{ duration: 0.3, delay: 0.1 }}
139:             >
140:               <PersonaConfig />
141:             </motion.div>
142: 
143:             <Separator className="my-8" />
144: 
145:             {/* Step 3: Content Preview */}
146:             <motion.div
147:               initial={{ opacity: 0, y: 20 }}
148:               animate={{ opacity: 1, y: 0 }}
149:               transition={{ duration: 0.3, delay: 0.2 }}
150:             >
151:               <ContentPreview />
152:             </motion.div>
153: 
154:             <Separator className="my-8" />
155: 
156:             {/* Step 4: Media Studio */}
157:             <motion.div
158:               initial={{ opacity: 0, y: 20 }}
159:               animate={{ opacity: 1, y: 0 }}
160:               transition={{ duration: 0.3, delay: 0.3 }}
161:             >
162:               <MediaStudio />
163:             </motion.div>
164: 
165:             <Separator className="my-8" />
166: 
167:             {/* Export Section - Page Bottom */}
168:             <motion.div
169:               initial={{ opacity: 0, y: 20 }}
170:               animate={{ opacity: 1, y: 0 }}
171:               transition={{ duration: 0.3, delay: 0.4 }}
172:               className="flex justify-center pb-8"
173:             >
174:               <Button
175:                 size="lg"
176:                 variant="outline"
177:                 onClick={handleExportNote}
178:                 disabled={isExporting || !generatedContent || !selectedTopic}
179:                 className="gap-2 min-w-[200px]"
180:               >
181:                 {isExporting ? (
182:                   <Loader2 className="w-5 h-5 animate-spin" />
183:                 ) : (
184:                   <Download className="w-5 h-5" />
185:                 )}
186:                 {isExporting ? "导出中..." : "导出笔记到 Obsidian"}
187:               </Button>
188:             </motion.div>
189: 
190:             {/* Footer Padding */}
191:             <div className="h-8" />
192:         </div>
193:       </main>
194:       </div>
195:     </div>
196:   );
197: }
</file>

<file path="frontend/src/store/workflow.ts">
  1: /**
  2:  * Zustand Store - Workflow State Management
  3:  */
  4: import { create } from "zustand";
  5: import { persist } from "zustand/middleware";
  6: import type {
  7:   TopicItem,
  8:   GenerateResponse,
  9:   MediaResult,
 10:   VoiceOption,
 11:   ModelOption,
 12:   PersonaCategory,
 13: } from "@/lib/api";
 14: 
 15: // ========== Types ==========
 16: 
 17: export type WorkflowMode = "image" | "video" | "wechat";
 18: export type WorkflowStep = "topic" | "persona" | "preview" | "studio";
 19: 
 20: export interface WorkflowState {
 21:   // Mode & Navigation
 22:   mode: WorkflowMode;
 23:   currentStep: WorkflowStep;
 24: 
 25:   // Config
 26:   selectedModel: string;
 27:   imageProvider: "replicate" | "volcengine" | "gemini";
 28:   animeModel: "anything-v4" | "flux-anime";
 29:   ttsProvider: "edge" | "volcengine";
 30:   selectedVoice: string;
 31: 
 32:   // Step 1: Topic Selection
 33:   keyword: string;
 34:   topics: TopicItem[];
 35:   topicsSource: string;
 36:   selectedTopic: TopicItem | null;
 37: 
 38:   // Step 2: Persona Config
 39:   selectedCategory: string;
 40:   selectedPersona: string;
 41:   customPersona: string;
 42:   referenceUrl: string;
 43: 
 44:   // Step 3: Content Preview
 45:   generatedContent: GenerateResponse | null;
 46:   selectedTitleIndex: number;
 47:   
 48:   // Dual Model Mode
 49:   dualModelMode: boolean;
 50:   secondModel: string;
 51:   dualResults: {
 52:     model1: GenerateResponse;
 53:     model2: GenerateResponse;
 54:   } | null;
 55:   selectedVersion: 'model1' | 'model2';
 56:   
 57:   // Advanced Settings
 58:   temperature: number;
 59: 
 60:   // Step 4: Media Studio
 61:   imageResults: MediaResult[];
 62:   audioResults: MediaResult[];
 63:   videoPath: string | null;
 64:   videoUrl: string | null;
 65:   srtPath: string | null;
 66:   selectedBgm: string | null;
 67:   bgmVolume: number;
 68: 
 69:   // Loading States
 70:   isAnalyzing: boolean;
 71:   isGenerating: boolean;
 72:   isGeneratingImages: boolean;
 73:   isGeneratingAudio: boolean;
 74:   isCreatingVideo: boolean;
 75: 
 76:   // Config Data (from API)
 77:   availableModels: ModelOption[];
 78:   availableVoices: { edge: VoiceOption[]; volcengine: VoiceOption[] };
 79:   availablePersonas: PersonaCategory[];
 80:   availableBgm: Array<{ name: string; filename: string; path: string }>;
 81: }
 82: 
 83: export interface WorkflowActions {
 84:   // Mode & Navigation
 85:   setMode: (mode: WorkflowMode) => void;
 86:   setStep: (step: WorkflowStep) => void;
 87: 
 88:   // Config
 89:   setSelectedModel: (model: string) => void;
 90:   setImageProvider: (provider: "replicate" | "volcengine" | "gemini") => void;
 91:   setAnimeModel: (model: "anything-v4" | "flux-anime") => void;
 92:   setTtsProvider: (provider: "edge" | "volcengine") => void;
 93:   setSelectedVoice: (voice: string) => void;
 94: 
 95:   // Step 1
 96:   setKeyword: (keyword: string) => void;
 97:   setTopics: (topics: TopicItem[], source: string) => void;
 98:   selectTopic: (topic: TopicItem | null) => void;
 99: 
100:   // Step 2
101:   setSelectedCategory: (category: string) => void;
102:   setSelectedPersona: (persona: string) => void;
103:   setCustomPersona: (persona: string) => void;
104:   setReferenceUrl: (url: string) => void;
105: 
106:   // Step 3
107:   setGeneratedContent: (content: GenerateResponse | null) => void;
108:   setSelectedTitleIndex: (index: number) => void;
109:   
110:   // Dual Model Mode
111:   setDualModelMode: (enabled: boolean) => void;
112:   setSecondModel: (model: string) => void;
113:   setDualResults: (results: { model1: GenerateResponse; model2: GenerateResponse } | null) => void;
114:   setSelectedVersion: (version: 'model1' | 'model2') => void;
115:   
116:   // Advanced Settings
117:   setTemperature: (temp: number) => void;
118: 
119:   // Step 4
120:   setImageResults: (results: MediaResult[]) => void;
121:   updateImageResult: (index: number, result: MediaResult) => void;
122:   setAudioResults: (results: MediaResult[]) => void;
123:   updateAudioResult: (index: number, result: MediaResult) => void;
124:   setVideoResult: (path: string | null, url: string | null, srtPath: string | null) => void;
125:   setSelectedBgm: (bgm: string | null) => void;
126:   setBgmVolume: (volume: number) => void;
127: 
128:   // Loading States
129:   setIsAnalyzing: (value: boolean) => void;
130:   setIsGenerating: (value: boolean) => void;
131:   setIsGeneratingImages: (value: boolean) => void;
132:   setIsGeneratingAudio: (value: boolean) => void;
133:   setIsCreatingVideo: (value: boolean) => void;
134: 
135:   // Config Data
136:   setAvailableModels: (models: ModelOption[]) => void;
137:   setAvailableVoices: (voices: { edge: VoiceOption[]; volcengine: VoiceOption[] }) => void;
138:   setAvailablePersonas: (personas: PersonaCategory[]) => void;
139:   setAvailableBgm: (bgm: Array<{ name: string; filename: string; path: string }>) => void;
140: 
141:   // Utility
142:   resetDownstream: (fromStep: WorkflowStep) => void;
143:   resetAll: () => void;
144: }
145: 
146: // ========== Initial State ==========
147: 
148: const initialState: WorkflowState = {
149:   mode: "image",
150:   currentStep: "topic",
151: 
152:   selectedModel: "deepseek/deepseek-chat",
153:   imageProvider: "replicate",
154:   animeModel: "anything-v4",
155:   ttsProvider: "edge",
156:   selectedVoice: "zh-CN-XiaoxiaoNeural",
157: 
158:   keyword: "",
159:   topics: [],
160:   topicsSource: "",
161:   selectedTopic: null,
162: 
163:   selectedCategory: "硬核技术/AI",
164:   selectedPersona: "全栈AI架构师",
165:   customPersona: "",
166:   referenceUrl: "",
167: 
168:   generatedContent: null,
169:   selectedTitleIndex: 0,
170:   
171:   dualModelMode: true,
172:   secondModel: "anthropic/claude-3.5-sonnet",
173:   dualResults: null,
174:   selectedVersion: 'model1',
175:   
176:   temperature: 0.4,
177: 
178:   imageResults: [],
179:   audioResults: [],
180:   videoPath: null,
181:   videoUrl: null,
182:   srtPath: null,
183:   selectedBgm: null,
184:   bgmVolume: 0.12,
185: 
186:   isAnalyzing: false,
187:   isGenerating: false,
188:   isGeneratingImages: false,
189:   isGeneratingAudio: false,
190:   isCreatingVideo: false,
191: 
192:   availableModels: [],
193:   availableVoices: { edge: [], volcengine: [] },
194:   availablePersonas: [],
195:   availableBgm: [],
196: };
197: 
198: // ========== Store ==========
199: 
200: export const useWorkflowStore = create<WorkflowState & WorkflowActions>()(
201:   persist(
202:     (set, get) => ({
203:       ...initialState,
204: 
205:       // Mode & Navigation
206:       setMode: (mode) => {
207:         set({ mode });
208:         
209:         // 切换模式时自动调整默认人设
210:         if (mode === "wechat") {
211:           // 公众号模式：技术分类
212:           set({
213:             selectedCategory: "硬核技术/AI",
214:             selectedPersona: "全栈AI架构师",
215:           });
216:         } else {
217:           // 小红书模式：职场分类
218:           set({
219:             selectedCategory: "职场",
220:             selectedPersona: "职场清醒女王",
221:           });
222:         }
223:         
224:         get().resetDownstream("topic");
225:       },
226:       setStep: (step) => set({ currentStep: step }),
227: 
228:       // Config
229:       setSelectedModel: (model) => set({ selectedModel: model }),
230:       setImageProvider: (provider) => set({ imageProvider: provider }),
231:       setAnimeModel: (model) => set({ animeModel: model }),
232:       setTtsProvider: (provider) => set({ ttsProvider: provider }),
233:       setSelectedVoice: (voice) => set({ selectedVoice: voice }),
234: 
235:       // Step 1
236:       setKeyword: (keyword) => set({ keyword }),
237:       setTopics: (topics, source) => set({ topics, topicsSource: source }),
238:       selectTopic: (topic) => {
239:         set({ selectedTopic: topic });
240:         if (topic) {
241:           get().resetDownstream("persona");
242:         }
243:       },
244: 
245:       // Step 2
246:       setSelectedCategory: (category) => set({ selectedCategory: category, selectedPersona: "" }),
247:       setSelectedPersona: (persona) => set({ selectedPersona: persona }),
248:       setCustomPersona: (persona) => set({ customPersona: persona }),
249:       setReferenceUrl: (url) => set({ referenceUrl: url }),
250: 
251:       // Step 3
252:       setGeneratedContent: (content) => {
253:         set({ generatedContent: content, selectedTitleIndex: 0 });
254:         if (content) {
255:           // Initialize media results arrays
256:           const count = content.visual_scenes?.length || content.image_designs?.length || 0;
257:           set({
258:             imageResults: Array(count).fill(null).map((_, i) => ({ index: i, path: null, url: null, error: null })),
259:             audioResults: Array(count).fill(null).map((_, i) => ({ index: i, path: null, url: null, error: null })),
260:           });
261:         }
262:       },
263:       setSelectedTitleIndex: (index) => set({ selectedTitleIndex: index }),
264:       
265:       // Dual Model Mode
266:       setDualModelMode: (enabled) => {
267:         set({ dualModelMode: enabled });
268:         if (!enabled) {
269:           set({ dualResults: null });
270:         }
271:       },
272:       setSecondModel: (model) => set({ secondModel: model }),
273:       setDualResults: (results) => {
274:         set({ dualResults: results });
275:         // Auto-select first version when results arrive
276:         if (results) {
277:           set({ selectedVersion: 'model1' });
278:           // Set the selected version as the main generatedContent
279:           set({ generatedContent: results.model1 });
280:         }
281:       },
282:       setSelectedVersion: (version) => {
283:         set({ selectedVersion: version });
284:         const { dualResults } = get();
285:         if (dualResults) {
286:           // Update main content to selected version
287:           set({ generatedContent: dualResults[version] });
288:         }
289:       },
290:       
291:       // Advanced Settings
292:       setTemperature: (temp) => set({ temperature: temp }),
293: 
294:       // Step 4
295:       setImageResults: (results) => set({ imageResults: results }),
296:       updateImageResult: (index, result) =>
297:         set((state) => ({
298:           imageResults: state.imageResults.map((r, i) => (i === index ? result : r)),
299:         })),
300:       setAudioResults: (results) => set({ audioResults: results }),
301:       updateAudioResult: (index, result) =>
302:         set((state) => ({
303:           audioResults: state.audioResults.map((r, i) => (i === index ? result : r)),
304:         })),
305:       setVideoResult: (path, url, srtPath) =>
306:         set({ videoPath: path, videoUrl: url, srtPath }),
307:       setSelectedBgm: (bgm) => set({ selectedBgm: bgm }),
308:       setBgmVolume: (volume) => set({ bgmVolume: volume }),
309: 
310:       // Loading States
311:       setIsAnalyzing: (value) => set({ isAnalyzing: value }),
312:       setIsGenerating: (value) => set({ isGenerating: value }),
313:       setIsGeneratingImages: (value) => set({ isGeneratingImages: value }),
314:       setIsGeneratingAudio: (value) => set({ isGeneratingAudio: value }),
315:       setIsCreatingVideo: (value) => set({ isCreatingVideo: value }),
316: 
317:       // Config Data
318:       setAvailableModels: (models) => set({ availableModels: models }),
319:       setAvailableVoices: (voices) => set({ availableVoices: voices }),
320:       setAvailablePersonas: (personas) => set({ availablePersonas: personas }),
321:       setAvailableBgm: (bgm) => set({ availableBgm: bgm }),
322: 
323:       // Utility
324:       resetDownstream: (fromStep) => {
325:         const steps: WorkflowStep[] = ["topic", "persona", "preview", "studio"];
326:         const idx = steps.indexOf(fromStep);
327: 
328:         if (idx <= 0) {
329:           // Reset from topic - clear everything
330:           set({
331:             selectedTopic: null,
332:             generatedContent: null,
333:             imageResults: [],
334:             audioResults: [],
335:             videoPath: null,
336:             videoUrl: null,
337:             srtPath: null,
338:           });
339:         } else if (idx <= 1) {
340:           // Reset from persona - clear content and media
341:           set({
342:             generatedContent: null,
343:             imageResults: [],
344:             audioResults: [],
345:             videoPath: null,
346:             videoUrl: null,
347:             srtPath: null,
348:           });
349:         } else if (idx <= 2) {
350:           // Reset from preview - clear media
351:           set({
352:             imageResults: [],
353:             audioResults: [],
354:             videoPath: null,
355:             videoUrl: null,
356:             srtPath: null,
357:           });
358:         }
359:       },
360:       resetAll: () => set(initialState),
361:     }),
362:     {
363:       name: "workflow-storage",
364:       partialize: (state) => ({
365:         // Only persist user selections, not loading states
366:         mode: state.mode,
367:         selectedModel: state.selectedModel,
368:         imageProvider: state.imageProvider,
369:         animeModel: state.animeModel,
370:         ttsProvider: state.ttsProvider,
371:         selectedVoice: state.selectedVoice,
372:         keyword: state.keyword,
373:         topics: state.topics,
374:         selectedTopic: state.selectedTopic,
375:         // 不持久化人设，让其根据 mode 使用默认值
376:         // selectedCategory: state.selectedCategory,
377:         // selectedPersona: state.selectedPersona,
378:         generatedContent: state.generatedContent,
379:         bgmVolume: state.bgmVolume,
380:       }),
381:     }
382:   )
383: );
</file>

<file path="requirements.txt">
 1: streamlit
 2: openai>=1.0
 3: replicate
 4: oss2
 5: DrissionPage
 6: python-dotenv
 7: requests
 8: pandas
 9: moviepy
10: edge-tts
11: pydub
12: google-genai>=1.0.0
13: pillow
</file>

<file path="modules/painter.py">
  1: """
  2: 生图模块 (Replicate + 火山引擎 Seedream + Google Nano Banana Pro)
  3: 支持多种模式：
  4: - 视频模式：使用 Replicate 或豆包批量生成分镜图
  5: - 图文模式：主图用 Nano Banana Pro 超高质量生成，配图用豆包
  6: 支持并发生成：ThreadPoolExecutor 加速批量处理
  7: 支持主题命名：文件按主题组织
  8: """
  9: import os
 10: import time
 11: from pathlib import Path
 12: from typing import Optional, Tuple, List
 13: from concurrent.futures import ThreadPoolExecutor, as_completed
 14: from dotenv import load_dotenv
 15: import replicate
 16: import requests
 17: from modules.storage import upload_to_oss, upload_to_oss_by_topic
 18: from modules.utils import sanitize_filename, get_unique_dir
 19: 
 20: load_dotenv()
 21: 
 22: # 默认输出目录
 23: DEFAULT_OUTPUT_DIR = Path("output/images")
 24: DEFAULT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
 25: 
 26: 
 27: # ========== 二次元风格库（英文版，用于 Replicate）==========
 28: 
 29: ANIME_STYLES_EN = {
 30:     "可爱治愈": "anime style, chibi, pastel colors, soft lighting, Ghibli inspired, cute and wholesome, highly detailed, 4k",
 31:     "严肃深度": "anime style, seinen manga aesthetic, dark atmosphere, dramatic shadows, muted colors, serious expression, sharp lines, detailed background",
 32:     "日常生活": "anime style, slice of life, natural lighting, detailed urban or home setting, warm colors, Kyoto Animation style",
 33:     "热血励志": "anime style, shonen jump style, dynamic pose, intense effects, bright and vivid colors, determined expression, speed lines",
 34:     "悲伤低沉": "anime style, melancholic atmosphere, rain, cold colors, lonely character, emotional, tearful, shallow depth of field",
 35:     "职场日常": "anime style, modern office girl, casual business outfit (cardigan, blouse, skirt or jeans), realistic modern office or cafe background, natural lighting, slice of life, detailed environment, professional but casual, warm atmosphere, urban setting, detailed"
 36: }
 37: 
 38: BASE_NEGATIVE_EN = "low quality, ugly, deformed, bad anatomy, extra fingers, watermark, text, blurry, disfigured, malformed limbs, extra limbs, missing arms, missing legs, fused fingers, too many fingers, long neck"
 39: 
 40: DEFAULT_STYLE_EN = "anime style, high quality, detailed, vibrant colors, professional illustration"
 41: 
 42: # ========== 二次元风格库（中文版，用于火山引擎豆包）==========
 43: 
 44: ANIME_STYLES_CN = {
 45:     "可爱治愈": "二次元动漫风格，Q版可爱，粉嫩柔和色调，柔光效果，吉卜力风格，治愈系，精细绘制，高清画质",
 46:     "严肃深度": "二次元动漫风格，青年漫画美学，暗色氛围，戏剧性阴影，沉稳色调，严肃表情，锐利线条，精细背景",
 47:     "日常生活": "二次元动漫风格，日常番风格，自然光照，都市或家居场景，温暖色调，京阿尼风格，生活气息",
 48:     "热血励志": "二次元动漫风格，少年漫画风格，动感姿势，强烈特效，明亮鲜艳色彩，坚定表情，速度线",
 49:     "悲伤低沉": "二次元动漫风格，忧郁氛围，雨天，冷色调，孤独角色，情感充沛，泪眼，浅景深",
 50:     "职场日常": "二次元动漫风格，现代职场女性，生活化商务穿搭（针织衫、衬衫、半身裙或牛仔裤），真实感现代办公室或咖啡厅背景，自然光照，日常番风格，精细环境描绘，职业但休闲，温暖氛围，都市场景"
 51: }
 52: 
 53: NEGATIVE_PROMPT_CN = "文字，字母，拼音，水印，logo，签名，用户名，错误，低质量，模糊，变形，多余手指，解剖错误，畸形"
 54: 
 55: DEFAULT_STYLE_CN = "二次元动漫风格，高质量，精细绘制，鲜艳色彩，专业插画"
 56: 
 57: # 兼容旧代码
 58: ANIME_STYLES = ANIME_STYLES_EN
 59: BASE_NEGATIVE = BASE_NEGATIVE_EN
 60: DEFAULT_STYLE = DEFAULT_STYLE_EN
 61: 
 62: # ========== 极客美学风格库（用于公众号架构图）==========
 63: 
 64: GEEK_STYLES_EN = {
 65:     "architecture": "cyberpunk style, system architecture diagram, glowing nodes and connections, dark blue/purple background, neon accents, futuristic tech aesthetic, holographic UI elements, detailed technical diagram, 4k, sharp focus",
 66:     "flow": "dark mode technical diagram, data flow visualization, glowing arrows and boxes, minimalist cyber aesthetic, dark background with bright neon highlights, clean information design, professional tech illustration",
 67:     "comparison": "tech comparison infographic, split view design, dark background, neon color coding (electric blue vs orange), modern UI style, clean and professional, side-by-side comparison, glowing divider line"
 68: }
 69: 
 70: GEEK_STYLES_CN = {
 71:     "architecture": "赛博朋克风格，系统架构图，发光节点和连接线，深蓝紫色背景，霓虹灯强调色，未来科技美学，全息UI元素，精细技术示意图，高清画质，锐利焦点",
 72:     "flow": "深色模式技术示意图，数据流可视化，发光箭头和方框，极简赛博美学，深色背景带明亮霓虹高光，清爽信息设计，专业技术插画",
 73:     "comparison": "科技对比信息图，分屏设计，深色背景，霓虹色彩编码（电蓝vs橙色），现代UI风格，清爽专业，并排对比，发光分割线"
 74: }
 75: 
 76: GEEK_NEGATIVE_EN = "low quality, blurry, text, letters, watermark, messy, cluttered, amateur, cartoon style, bright background, colorful chaos"
 77: GEEK_NEGATIVE_CN = "低质量，模糊，文字，水印，杂乱，业余，卡通风格，明亮背景，混乱配色"
 78: 
 79: 
 80: # ========== Prompt 组装 ==========
 81: 
 82: def _build_anime_prompt(scene: dict, provider: str = "replicate") -> Tuple[str, str]:
 83:     """
 84:     根据场景的 sentiment 和 provider 组装风格化 Prompt
 85:     
 86:     Args:
 87:         scene: 分镜字典，包含 prompt 和可选的 sentiment
 88:         provider: "replicate" 使用英文，"volcengine" 使用中文
 89:     
 90:     Returns:
 91:         (final_prompt, negative_prompt)
 92:     """
 93:     base_prompt = scene.get('prompt', '')
 94:     sentiment = scene.get('sentiment', '')
 95:     
 96:     if provider == "volcengine":
 97:         # 火山引擎豆包：使用中文风格库
 98:         style_modifiers = ANIME_STYLES_CN.get(sentiment, DEFAULT_STYLE_CN)
 99:         negative_prompt = NEGATIVE_PROMPT_CN
100:     else:
101:         # Replicate：使用英文风格库
102:         style_modifiers = ANIME_STYLES_EN.get(sentiment, DEFAULT_STYLE_EN)
103:         negative_prompt = BASE_NEGATIVE_EN
104:     
105:     # 组装最终 Prompt
106:     final_prompt = f"{style_modifiers}，{base_prompt}" if provider == "volcengine" else f"{style_modifiers}, {base_prompt}"
107:     
108:     return final_prompt, negative_prompt
109: 
110: 
111: # ========== 单张图片生成（核心函数） ==========
112: 
113: def _generate_single_anime(scene: dict, index: int, anime_model: str = "anything-v4", output_dir: Path = None, topic: str = None) -> Tuple[Optional[str], Optional[str]]:
114:     """
115:     使用 Replicate 二次元模型生成单张图片
116:     
117:     Args:
118:         scene: 分镜字典，包含 prompt 和可选的 sentiment
119:         index: 场景索引
120:         anime_model: "anything-v4" 或 "flux-anime"
121:         output_dir: 输出目录（为空则使用默认）
122:         topic: 主题名称（用于文件命名）
123:     
124:     Returns:
125:         (本地路径, 错误信息)
126:     """
127:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
128:     
129:     try:
130:         # 组装英文风格化 Prompt（Replicate 模型）
131:         prompt, negative_prompt = _build_anime_prompt(scene, provider="replicate")
132:         
133:         if not prompt:
134:             return None, "prompt 为空"
135:         
136:         sentiment = scene.get('sentiment', '默认')
137:         print(f"[Anime] 场景 {index+1} ({sentiment}) 生成中...")
138:         print(f"[Anime] Prompt: {prompt[:100]}...")
139:         
140:         if anime_model == "flux-anime":
141:             # Flux Dev Anime 模型（不指定版本，使用最新）
142:             output = replicate.run(
143:                 "lucataco/flux-dev-anime",
144:                 input={
145:                     "prompt": prompt,
146:                     "aspect_ratio": "3:4",
147:                     "output_format": "webp",
148:                     "output_quality": 90,
149:                     "num_inference_steps": 28,
150:                     "guidance_scale": 3.5,
151:                 }
152:             )
153:         else:
154:             # Anything V4.0 模型
155:             output = replicate.run(
156:                 "cjwbw/anything-v4.0",
157:                 input={
158:                     "prompt": prompt,
159:                     "negative_prompt": negative_prompt,
160:                     "width": 512,
161:                     "height": 768,
162:                     "num_inference_steps": 25,
163:                     "guidance_scale": 7,
164:                     "scheduler": "DPMSolverMultistep",
165:                 }
166:             )
167:         
168:         # 处理输出
169:         if isinstance(output, list):
170:             image_url = output[0] if output else None
171:         else:
172:             image_url = str(output) if output else None
173:         
174:         if not image_url:
175:             return None, "模型未返回图片"
176:         
177:         resp = requests.get(image_url, timeout=60)
178:         resp.raise_for_status()
179:         image_data = resp.content
180:         
181:         # 文件命名：主题_scene_01.ext
182:         ext = "webp" if anime_model == "flux-anime" else "png"
183:         safe_topic = sanitize_filename(topic) if topic else ""
184:         filename = f"{safe_topic}_scene_{index+1:02d}.{ext}" if safe_topic else f"scene_{index+1:02d}.{ext}"
185:         local_path = str(output_dir / filename)
186:         
187:         with open(local_path, "wb") as f:
188:             f.write(image_data)
189:         
190:         # 上传到 OSS（按主题分类）
191:         oss_url = None
192:         if topic:
193:             oss_url = upload_to_oss_by_topic(image_data, topic, filename, "images")
194:         
195:         print(f"[Anime] 场景 {index+1} 完成: {local_path}")
196:         # 优先返回 OSS URL，否则返回本地路径
197:         return oss_url or local_path, None
198:         
199:     except Exception as e:
200:         error_msg = str(e)
201:         print(f"[Anime Error] 场景 {index+1} 失败: {error_msg}")
202:         return None, error_msg
203: 
204: 
205: def _generate_single_volcengine(scene: dict, index: int, output_dir: Path = None, topic: str = None) -> Tuple[Optional[str], Optional[str]]:
206:     """
207:     使用火山引擎豆包生成单张图片（中文 Prompt + 纯净画面）
208:     
209:     Args:
210:         scene: 分镜字典
211:         index: 场景索引
212:         output_dir: 输出目录
213:         topic: 主题名称
214:     
215:     Returns:
216:         (本地路径, 错误信息)
217:     """
218:     from openai import OpenAI
219:     
220:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
221:     
222:     try:
223:         ark_api_key = os.getenv("ARK_API_KEY")
224:         if not ark_api_key:
225:             return None, "缺少 ARK_API_KEY"
226:         
227:         # 组装中文风格化 Prompt
228:         prompt, negative_prompt = _build_anime_prompt(scene, provider="volcengine")
229:         
230:         if not prompt:
231:             return None, "prompt 为空"
232:         
233:         sentiment = scene.get('sentiment', '默认')
234:         print(f"[Volcengine] 场景 {index+1} ({sentiment}) 生成中...")
235:         print(f"[Volcengine] Prompt: {prompt[:80]}...")
236:         
237:         client = OpenAI(
238:             base_url="https://ark.cn-beijing.volces.com/api/v3",
239:             api_key=ark_api_key,
240:         )
241:         
242:         response = client.images.generate(
243:             model="doubao-seedream-4-0-250828",
244:             prompt=prompt,
245:             size="1024x1344",
246:             response_format="url",
247:             extra_body={"watermark": False},
248:         )
249:         
250:         image_url = response.data[0].url
251:         
252:         resp = requests.get(image_url, timeout=60)
253:         resp.raise_for_status()
254:         image_data = resp.content
255:         
256:         # 文件命名：主题_scene_01.png
257:         safe_topic = sanitize_filename(topic) if topic else ""
258:         filename = f"{safe_topic}_scene_{index+1:02d}.png" if safe_topic else f"scene_{index+1:02d}.png"
259:         local_path = str(output_dir / filename)
260:         
261:         with open(local_path, "wb") as f:
262:             f.write(image_data)
263:         
264:         # 上传到 OSS（按主题分类）
265:         oss_url = None
266:         if topic:
267:             oss_url = upload_to_oss_by_topic(image_data, topic, filename, "images")
268:         
269:         print(f"[Volcengine] 场景 {index+1} 完成: {local_path}")
270:         # 优先返回 OSS URL，否则返回本地路径
271:         return oss_url or local_path, None
272:         
273:     except Exception as e:
274:         error_msg = str(e)
275:         print(f"[Volcengine Error] 场景 {index+1} 失败: {error_msg}")
276:         return None, error_msg
277: 
278: 
279: def _generate_single_gemini(scene: dict, index: int, output_dir: Path = None, topic: str = None) -> Tuple[Optional[str], Optional[str]]:
280:     """
281:     使用 Replicate 调用 Google Nano Banana Pro 生成超高质量图片（适合主图/封面图）
282:     
283:     Nano Banana Pro 基于 Gemini 3 Pro，提供：
284:     - 4K 高分辨率输出
285:     - 更准确的文字渲染
286:     - 更好的创意控制和细节表现
287:     
288:     Args:
289:         scene: 分镜字典，包含 prompt 和可选的 cover_text（主图文字）
290:         index: 场景索引
291:         output_dir: 输出目录
292:         topic: 主题名称
293:     
294:     Returns:
295:         (本地路径, 错误信息)
296:     """
297:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
298:     
299:     try:
300:         base_prompt = scene.get('prompt', '')
301:         cover_text = scene.get('cover_text', '')
302:         
303:         if not base_prompt:
304:             return None, "prompt 为空"
305:         
306:         # 构建增强 prompt
307:         if cover_text:
308:             # 主图：包含文字叠加 + 白色背景
309:             enhanced_prompt = f"""Generate a clean anime-style illustration with white/cream background:
310: - Main visual: {base_prompt}
311: - Background: White or off-white color, minimal and clean design
312: - Text overlay in center: "{cover_text}" in bold modern Chinese font, dark color for readability
313: - Style: Professional poster design, high quality, masterpiece, 4k, sharp focus
314: - Atmosphere: Light and bright, fresh and clean, minimalist composition
315: - Color scheme: Pastel and soft colors, avoid dark or saturated backgrounds"""
316:             
317:             print(f"[Nano Banana Pro] 主图 {index+1} 生成中（带文字: {cover_text}）...")
318:         else:
319:             # 配图：原有逻辑
320:             enhanced_prompt = f"Generate an image: High quality, professional illustration, masterpiece, best quality, {base_prompt}, detailed, 4k, sharp focus"
321:             print(f"[Nano Banana Pro] 图片 {index+1} 生成中...")
322:         
323:         print(f"[Nano Banana Pro] Prompt: {enhanced_prompt[:100]}...")
324:         
325:         # 通过 Replicate 调用 Google Nano Banana Pro
326:         output = replicate.run(
327:             "google/nano-banana-pro",
328:             input={
329:                 "prompt": enhanced_prompt,
330:                 "aspect_ratio": "3:4",  # 小红书竖图比例
331:                 "output_format": "png",  # 高质量输出
332:                 "output_quality": 100,
333:             }
334:         )
335:         
336:         # Replicate 返回的是 FileOutput 对象或 URL
337:         if not output:
338:             return None, "Nano Banana Pro 未返回图片"
339:         
340:         # 获取图片 URL
341:         if hasattr(output, 'url'):
342:             image_url = output.url
343:         elif isinstance(output, str):
344:             image_url = output
345:         elif isinstance(output, list) and len(output) > 0:
346:             image_url = output[0].url if hasattr(output[0], 'url') else str(output[0])
347:         else:
348:             return None, f"无法解析 Nano Banana Pro 返回: {type(output)}"
349:         
350:         # 下载图片
351:         resp = requests.get(image_url, timeout=60)
352:         resp.raise_for_status()
353:         image_data = resp.content
354:         
355:         # 文件命名：主题_cover.png
356:         safe_topic = sanitize_filename(topic) if topic else ""
357:         filename = f"{safe_topic}_cover.png" if safe_topic else f"cover_{index+1:02d}.png"
358:         local_path = str(output_dir / filename)
359:         
360:         with open(local_path, "wb") as f:
361:             f.write(image_data)
362:         
363:         # 上传到 OSS（按主题分类）
364:         oss_url = None
365:         if topic:
366:             oss_url = upload_to_oss_by_topic(image_data, topic, filename, "images")
367:         
368:         print(f"[Nano Banana Pro] 主图 {index+1} 完成: {local_path}")
369:         # 优先返回 OSS URL，否则返回本地路径
370:         return oss_url or local_path, None
371:         
372:     except Exception as e:
373:         error_msg = str(e)
374:         print(f"[Nano Banana Pro Error] 主图 {index+1} 失败: {error_msg}")
375:         return None, error_msg
376: 
377: 
378: # ========== 统一入口 ==========
379: 
380: # 并发配置
381: MAX_WORKERS = 5  # 限制并发数，防止触发 API 速率限制 (429)
382: 
383: 
384: def generate_images(scenes: list, provider: str = "replicate", anime_model: str = "anything-v4", topic: str = None) -> list:
385:     """
386:     统一生图入口（并发版本）
387:     
388:     使用 ThreadPoolExecutor 并发生成图片，显著提升批量处理速度。
389:     文件按主题组织，重复生成时自动添加数字后缀。
390:     
391:     Args:
392:         scenes: 分镜列表，每个元素需包含 'prompt' 字段，可选 'sentiment'
393:         provider: "replicate"、"volcengine" 或 "gemini"
394:         anime_model: 二次元模型选择 "anything-v4" 或 "flux-anime"（仅 replicate 生效）
395:         topic: 主题名称（用于创建子目录和文件命名）
396:     
397:     Returns:
398:         本地图片路径列表（顺序与 scenes 一致，失败项为 None）
399:     """
400:     if not scenes:
401:         return []
402:     
403:     # 创建主题目录
404:     if topic:
405:         output_dir = get_unique_dir(DEFAULT_OUTPUT_DIR, topic)
406:         print(f"[Painter] 输出目录: {output_dir}")
407:     else:
408:         output_dir = DEFAULT_OUTPUT_DIR
409:     
410:     print(f"[Painter] 开始并发生成 {len(scenes)} 张图片 (max_workers={MAX_WORKERS})...")
411:     
412:     def _generate_one(args):
413:         """单张图片生成（带索引）"""
414:         index, scene = args
415:         try:
416:             if provider == "replicate":
417:                 path, error = _generate_single_anime(scene, index, anime_model, output_dir, topic)
418:             elif provider == "volcengine":
419:                 path, error = _generate_single_volcengine(scene, index, output_dir, topic)
420:             elif provider == "gemini":
421:                 path, error = _generate_single_gemini(scene, index, output_dir, topic)
422:             else:
423:                 print(f"[Painter Error] 未知的 provider: {provider}")
424:                 return index, None
425:             return index, path
426:         except Exception as e:
427:             print(f"[Painter Error] 场景 {index+1} 异常: {e}")
428:             return index, None
429:     
430:     # 使用 ThreadPoolExecutor 并发执行
431:     results = [None] * len(scenes)
432:     
433:     with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
434:         # 提交所有任务（带索引）
435:         futures = {executor.submit(_generate_one, (i, scene)): i for i, scene in enumerate(scenes)}
436:         
437:         # 收集结果（保持顺序）
438:         for future in as_completed(futures):
439:             try:
440:                 index, path = future.result()
441:                 results[index] = path
442:             except Exception as e:
443:                 index = futures[future]
444:                 print(f"[Painter Error] 场景 {index+1} Future 异常: {e}")
445:                 results[index] = None
446:     
447:     success_count = sum(1 for p in results if p is not None)
448:     print(f"[Painter] 并发生成完成: {success_count}/{len(scenes)} 成功")
449:     
450:     return results
451: 
452: 
453: def generate_images_mixed(scenes: list, topic: str = None) -> list:
454:     """
455:     图文模式专用：主图用 Nano Banana Pro，配图用豆包
456:     
457:     第一张图（封面/主图）使用 Google Nano Banana Pro 生成超高质量图片
458:     其余配图使用火山引擎豆包 Seedream 生成
459:     
460:     Args:
461:         scenes: 配图设计列表，每个元素需包含 'prompt' 字段
462:         topic: 主题名称（用于创建子目录和文件命名）
463:     
464:     Returns:
465:         本地图片路径列表（顺序与 scenes 一致，失败项为 None）
466:     """
467:     if not scenes:
468:         return []
469:     
470:     # 创建主题目录
471:     if topic:
472:         output_dir = get_unique_dir(DEFAULT_OUTPUT_DIR, topic)
473:         print(f"[Painter Mixed] 输出目录: {output_dir}")
474:     else:
475:         output_dir = DEFAULT_OUTPUT_DIR
476:     
477:     results = [None] * len(scenes)
478:     
479:     print(f"[Painter Mixed] 开始混合生成 {len(scenes)} 张图片...")
480:     print(f"[Painter Mixed] 主图: Nano Banana Pro | 配图: 豆包 Seedream")
481:     
482:     # 1. 生成主图（第一张，使用 Nano Banana Pro）
483:     if len(scenes) > 0:
484:         print(f"\n[Painter Mixed] === 生成主图 (Nano Banana Pro) ===")
485:         path, error = _generate_single_gemini(scenes[0], 0, output_dir, topic)
486:         results[0] = path
487:         if error:
488:             print(f"[Painter Mixed] 主图 Nano Banana Pro 失败，降级到豆包: {error}")
489:             # 降级到豆包
490:             path, error = _generate_single_volcengine(scenes[0], 0, output_dir, topic)
491:             results[0] = path
492:     
493:     # 2. 生成配图（其余图片，使用豆包并发）
494:     if len(scenes) > 1:
495:         print(f"\n[Painter Mixed] === 生成配图 (豆包, {len(scenes)-1} 张) ===")
496:         
497:         def _generate_one(args):
498:             index, scene = args
499:             try:
500:                 path, error = _generate_single_volcengine(scene, index, output_dir, topic)
501:                 return index, path
502:             except Exception as e:
503:                 print(f"[Painter Mixed Error] 配图 {index+1} 异常: {e}")
504:                 return index, None
505:         
506:         with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
507:             # 从 index=1 开始（跳过主图）
508:             futures = {
509:                 executor.submit(_generate_one, (i, scene)): i 
510:                 for i, scene in enumerate(scenes) if i > 0
511:             }
512:             
513:             for future in as_completed(futures):
514:                 try:
515:                     index, path = future.result()
516:                     results[index] = path
517:                 except Exception as e:
518:                     index = futures[future]
519:                     print(f"[Painter Mixed Error] 配图 {index+1} Future 异常: {e}")
520:                     results[index] = None
521:     
522:     success_count = sum(1 for p in results if p is not None)
523:     print(f"\n[Painter Mixed] 混合生成完成: {success_count}/{len(scenes)} 成功")
524:     
525:     return results
526: 
527: 
528: def generate_diagrams(diagrams: list, topic: str = None, provider: str = "volcengine") -> list:
529:     """
530:     公众号专用：生成架构图/示意图（极客美学风格）
531:     
532:     使用火山引擎豆包生成技术架构图、流程图、对比图
533:     
534:     Args:
535:         diagrams: 架构图设计列表，每个元素需包含 'prompt' 和 'diagram_type'
536:         topic: 主题名称（用于文件命名）
537:         provider: 生图服务（默认 volcengine，推荐用于中文技术图）
538:     
539:     Returns:
540:         本地图片路径列表（顺序与 diagrams 一致，失败项为 None）
541:     """
542:     if not diagrams:
543:         return []
544:     
545:     # 创建主题目录
546:     if topic:
547:         output_dir = get_unique_dir(DEFAULT_OUTPUT_DIR, topic)
548:         print(f"[Diagrams] 输出目录: {output_dir}")
549:     else:
550:         output_dir = DEFAULT_OUTPUT_DIR
551:     
552:     print(f"[Diagrams] 开始生成 {len(diagrams)} 张架构图（极客美学）...")
553:     
554:     # 转换为标准 scene 格式，添加极客美学风格
555:     scenes_with_style = []
556:     for diagram in diagrams:
557:         base_prompt = diagram.get('prompt', '')
558:         diagram_type = diagram.get('diagram_type', 'architecture')
559:         
560:         # 根据类型应用风格
561:         if provider == "volcengine":
562:             style = GEEK_STYLES_CN.get(diagram_type, GEEK_STYLES_CN['architecture'])
563:             final_prompt = f"{style}，{base_prompt}"
564:         else:
565:             style = GEEK_STYLES_EN.get(diagram_type, GEEK_STYLES_EN['architecture'])
566:             final_prompt = f"{style}, {base_prompt}"
567:         
568:         scenes_with_style.append({
569:             'prompt': final_prompt,
570:             'sentiment': diagram_type  # 用 sentiment 字段传递 type
571:         })
572:     
573:     # 调用批量生成（复用现有逻辑）
574:     results = generate_images(
575:         scenes=scenes_with_style,
576:         provider=provider,
577:         anime_model="flux-anime",  # 架构图用 Flux（更适合技术图）
578:         topic=topic
579:     )
580:     
581:     return results
582: 
583: 
584: def generate_single_image(scene: dict, index: int, provider: str = "replicate", anime_model: str = "anything-v4", output_dir: Path = None, topic: str = None) -> Tuple[Optional[str], Optional[str]]:
585:     """
586:     生成单张图片（用于重试）
587:     
588:     Args:
589:         scene: 分镜字典，需包含 'prompt' 字段，可选 'sentiment'
590:         index: 场景索引（0-based）
591:         provider: "replicate"、"volcengine" 或 "gemini"
592:         anime_model: 二次元模型选择（仅 replicate 生效）
593:         output_dir: 输出目录（为空则使用默认）
594:         topic: 主题名称
595:     
596:     Returns:
597:         (本地路径, 错误信息)
598:     """
599:     output_dir = output_dir or DEFAULT_OUTPUT_DIR
600:     
601:     if provider == "replicate":
602:         return _generate_single_anime(scene, index, anime_model, output_dir, topic)
603:     elif provider == "volcengine":
604:         return _generate_single_volcengine(scene, index, output_dir, topic)
605:     elif provider == "gemini":
606:         return _generate_single_gemini(scene, index, output_dir, topic)
607:     else:
608:         return None, f"未知的 provider: {provider}"
609: 
610: 
611: # ========== 兼容旧接口（保留） ==========
612: 
613: def generate_images_with_ideogram(designs_list: list) -> list:
614:     """
615:     旧接口兼容层 - 根据设计方案批量生成图片并上传到 OSS
616:     
617:     Args:
618:         designs_list: writer 模块生成的 images_design 列表
619:     
620:     Returns:
621:         OSS 图片 URL 列表
622:     """
623:     urls = []
624:     
625:     for i, design in enumerate(designs_list):
626:         try:
627:             prompt = _build_ideogram_prompt(design)
628:             print(f"[Painter] 图片 {i+1} prompt: {prompt[:100]}...")
629:             
630:             output = replicate.run(
631:                 "ideogram-ai/ideogram-v2",
632:                 input={
633:                     "prompt": prompt,
634:                     "aspect_ratio": "3:4",
635:                 }
636:             )
637:             
638:             image_url = output if isinstance(output, str) else str(output)
639:             
640:             resp = requests.get(image_url, timeout=60)
641:             resp.raise_for_status()
642:             image_data = resp.content
643:             
644:             timestamp = int(time.time() * 1000)
645:             img_type = design.get('type', 'img')
646:             filename = f"rednote/{timestamp}_{img_type}.webp"
647:             
648:             oss_url = upload_to_oss(image_data, filename)
649:             if oss_url:
650:                 urls.append(oss_url)
651:                 print(f"[Painter] 图片 {i+1} ({img_type}) 生成成功: {oss_url}")
652:             else:
653:                 print(f"[Painter] 图片 {i+1} 上传失败")
654:                 
655:         except Exception as e:
656:             print(f"[Painter Error] 图片 {i+1} 生成失败: {e}")
657:             continue
658:     
659:     return urls
660: 
661: 
662: def _build_ideogram_prompt(design: dict) -> str:
663:     """旧接口的 prompt 构建函数"""
664:     design_type = design.get('type', 'cover')
665:     main_text = design.get('main_text', '')
666:     sub_text = design.get('sub_text', '')
667:     visual_style = design.get('visual_style', 'minimalist aesthetic')
668:     
669:     if design_type == 'cover':
670:         prompt = (
671:             f"A poster design with text. "
672:             f"The Chinese text '{main_text}' is rendered in large bold font at the top. "
673:             f"Below it is '{sub_text}'. "
674:             f"The background style is {visual_style}. "
675:             f"Typography is integrated naturally. High quality, professional design."
676:         )
677:     else:
678:         prompt = (
679:             f"An artistic photograph with text. "
680:             f"The Chinese text '{main_text}' is elegantly placed in the image. "
681:             f"The visual style is {visual_style}. "
682:             f"Clean typography, aesthetic composition."
683:         )
684:     
685:     return prompt
</file>

<file path="modules/storage.py">
  1: """
  2: 阿里云 OSS 上传模块
  3: 支持按主题分类存储图片、音频、视频
  4: """
  5: import os
  6: from pathlib import Path
  7: from dotenv import load_dotenv
  8: import oss2
  9: 
 10: # 加载项目根目录的 .env 文件
 11: load_dotenv(Path(__file__).parent.parent / ".env")
 12: 
 13: OSS_ACCESS_KEY_ID = os.getenv("OSS_ACCESS_KEY_ID")
 14: OSS_ACCESS_KEY_SECRET = os.getenv("OSS_ACCESS_KEY_SECRET")
 15: OSS_ENDPOINT = os.getenv("OSS_ENDPOINT")
 16: OSS_BUCKET_NAME = os.getenv("OSS_BUCKET_NAME")
 17: OSS_URL_PREFIX = os.getenv("OSS_URL_PREFIX")
 18: 
 19: # 懒加载 bucket 对象
 20: _bucket = None
 21: 
 22: 
 23: def _get_bucket():
 24:     """懒加载获取 OSS bucket"""
 25:     global _bucket
 26:     if _bucket is None:
 27:         try:
 28:             auth = oss2.Auth(OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET)
 29:             _bucket = oss2.Bucket(auth, OSS_ENDPOINT, OSS_BUCKET_NAME)
 30:         except Exception as e:
 31:             print(f"[OSS Error] 初始化失败: {e}")
 32:             return None
 33:     return _bucket
 34: 
 35: 
 36: def _sanitize_topic(topic: str) -> str:
 37:     """清理主题名称，移除特殊字符"""
 38:     if not topic:
 39:         return "default"
 40:     safe = "".join(c for c in topic if c.isalnum() or c in "_ -").strip()
 41:     return safe if safe else "default"
 42: 
 43: 
 44: def upload_to_oss(image_data: bytes, filename: str) -> str:
 45:     """
 46:     上传图片二进制数据到阿里云 OSS（旧接口，保持兼容）
 47:     
 48:     Args:
 49:         image_data: 图片二进制数据
 50:         filename: 存储文件名
 51:     
 52:     Returns:
 53:         成功返回可访问 URL，失败返回 None
 54:     """
 55:     try:
 56:         bucket = _get_bucket()
 57:         if bucket is None:
 58:             return None
 59:         bucket.put_object(filename, image_data)
 60:         return f"{OSS_URL_PREFIX}/{filename}"
 61:     except Exception as e:
 62:         print(f"[OSS Error] 上传失败: {e}")
 63:         return None
 64: 
 65: 
 66: def upload_to_oss_by_topic(data: bytes, topic: str, filename: str, file_type: str = "images") -> str:
 67:     """
 68:     按主题上传文件到 OSS
 69:     
 70:     OSS 路径结构: {topic}/{file_type}/{filename}
 71:     例如: 职场干货/images/scene_01.png
 72:     
 73:     Args:
 74:         data: 文件二进制数据
 75:         topic: 主题名称
 76:         filename: 文件名
 77:         file_type: 文件类型目录 (images/audio/video)
 78:     
 79:     Returns:
 80:         成功返回可访问 URL，失败返回 None
 81:     """
 82:     try:
 83:         bucket = _get_bucket()
 84:         if bucket is None:
 85:             return None
 86:         
 87:         safe_topic = _sanitize_topic(topic)
 88:         oss_key = f"{safe_topic}/{file_type}/{filename}"
 89:         
 90:         bucket.put_object(oss_key, data)
 91:         oss_url = f"{OSS_URL_PREFIX}/{oss_key}"
 92:         print(f"[OSS] 上传成功: {oss_key}")
 93:         return oss_url
 94:         
 95:     except Exception as e:
 96:         print(f"[OSS Error] 上传失败: {e}")
 97:         return None
 98: 
 99: 
100: def upload_file_to_oss_by_topic(local_path: str, topic: str, file_type: str = "images") -> str:
101:     """
102:     按主题上传本地文件到 OSS
103:     
104:     Args:
105:         local_path: 本地文件路径
106:         topic: 主题名称
107:         file_type: 文件类型目录 (images/audio/video)
108:     
109:     Returns:
110:         成功返回可访问 URL，失败返回 None
111:     """
112:     try:
113:         local_file = Path(local_path)
114:         if not local_file.exists():
115:             print(f"[OSS Error] 本地文件不存在: {local_path}")
116:             return None
117:         
118:         with open(local_file, "rb") as f:
119:             data = f.read()
120:         
121:         return upload_to_oss_by_topic(data, topic, local_file.name, file_type)
122:         
123:     except Exception as e:
124:         print(f"[OSS Error] 读取文件失败: {e}")
125:         return None
126: 
127: 
128: def is_oss_configured() -> bool:
129:     """检查 OSS 是否已配置"""
130:     return all([OSS_ACCESS_KEY_ID, OSS_ACCESS_KEY_SECRET, OSS_ENDPOINT, OSS_BUCKET_NAME])
</file>

<file path="modules/trend.py">
  1: """
  2: 选题挖掘模块 (火山引擎 Web Search 联网插件)
  3: 实时搜索互联网热点，获取热门内容详情和大纲结构
  4: """
  5: import os
  6: import json
  7: import re
  8: from pathlib import Path
  9: from dotenv import load_dotenv
 10: from openai import OpenAI
 11: 
 12: # 加载项目根目录的 .env 文件
 13: load_dotenv(Path(__file__).parent.parent / ".env")
 14: 
 15: # 火山引擎方舟客户端（延迟初始化）
 16: _ark_client = None
 17: 
 18: def get_ark_client():
 19:     """延迟初始化火山引擎客户端"""
 20:     global _ark_client
 21:     if _ark_client is None:
 22:         api_key = os.getenv("ARK_API_KEY")
 23:         if not api_key:
 24:             raise ValueError("ARK_API_KEY 环境变量未设置，请在 .env 文件中配置")
 25:         _ark_client = OpenAI(
 26:             base_url="https://ark.cn-beijing.volces.com/api/v3",
 27:             api_key=api_key,
 28:         )
 29:     return _ark_client
 30: 
 31: 
 32: def analyze_trends(niche: str, force_fallback: bool = False) -> tuple[list, str]:
 33:     """
 34:     根据赛道分析小红书热门选题（基于实时联网搜索）
 35:     返回热点详情 + 内容大纲，用于后续基于大纲生成笔记
 36:     
 37:     Args:
 38:         niche: 赛道/领域名称
 39:     
 40:     Returns:
 41:         (topics, source): 
 42:         - topics: 热点详情列表，每个元素是 dict:
 43:             {
 44:                 "title": "选题标题",
 45:                 "source": "来源平台",
 46:                 "summary": "热门内容摘要",
 47:                 "outline": ["大纲点1", "大纲点2", ...],
 48:                 "why_hot": "火爆原因"
 49:             }
 50:         - source: 数据来源标记 "websearch" | "fallback" | "error"
 51:     """
 52:     # 快速模式：直接返回 LLM 推荐，跳过联网搜索
 53:     if force_fallback:
 54:         print(f"[Trend] 快速模式：直接 LLM 推荐")
 55:         return _fallback_analyze(niche)
 56:     
 57:     print(f"[Trend] 联网搜索模式")
 58:     search_prompt = f"""请搜索小红书上关于「{niche}」的最新热门笔记和爆款内容。
 59: 
 60: 你的任务是找到小红书上真正火爆的笔记，分析它们为什么火，并提取出内容大纲。
 61: 
 62: 请输出 10 个小红书热门笔记，每个包含：
 63: 1. title: 选题标题（具体、有爆款潜力，20字以内）
 64: 2. source: 笔记类型（如：图文爆款、视频爆款、干货分享、情绪吐槽、好物分享）
 65: 3. summary: 这篇笔记在讲什么（50-100字摘要）
 66: 4. outline: 内容大纲结构（3-5个要点，每个要点15字以内）
 67: 5. why_hot: 为什么火（击中了什么情绪/痛点，30字以内）
 68: 
 69: 必须严格输出以下 JSON 格式，不要输出任何其他内容：
 70: [
 71:     {{
 72:         "title": "选题标题",
 73:         "source": "图文爆款",
 74:         "summary": "这篇笔记主要讲述...",
 75:         "outline": ["引子：场景痛点", "核心观点1", "核心观点2", "金句收尾"],
 76:         "why_hot": "击中了职场人的焦虑情绪"
 77:     }}
 78: ]"""
 79: 
 80:     try:
 81:         response = get_ark_client().responses.create(
 82:             model="doubao-seed-1-6-250615",
 83:             input=[{"role": "user", "content": search_prompt}],
 84:             tools=[{"type": "web_search"}],
 85:         )
 86:         
 87:         # 解析响应
 88:         text = ""
 89:         if hasattr(response, 'output') and response.output:
 90:             for item in response.output:
 91:                 if hasattr(item, 'content') and item.content:
 92:                     for content_item in item.content:
 93:                         if hasattr(content_item, 'text'):
 94:                             text += content_item.text
 95:         
 96:         if not text and hasattr(response, 'choices'):
 97:             text = response.choices[0].message.content
 98:         
 99:         if not text:
100:             text = str(response)
101:         
102:         # 解析 JSON
103:         topics = _parse_topics_json(text)
104:         if topics:
105:             return topics, "websearch"
106:         else:
107:             # JSON 解析失败，尝试降级
108:             print(f"[Trend Warning] JSON 解析失败，降级处理")
109:             return _fallback_analyze(niche)
110:         
111:     except Exception as e:
112:         print(f"[Trend Error] 火山引擎联网搜索失败: {e}")
113:         return _fallback_analyze(niche)
114: 
115: 
116: def _parse_topics_json(text: str) -> list:
117:     """解析 LLM 返回的 JSON 格式热点数据"""
118:     try:
119:         # 尝试提取 JSON 数组
120:         json_match = re.search(r'\[[\s\S]*\]', text)
121:         if json_match:
122:             json_str = json_match.group(0)
123:             topics = json.loads(json_str)
124:             
125:             # 验证数据结构
126:             valid_topics = []
127:             for t in topics:
128:                 if isinstance(t, dict) and 'title' in t:
129:                     valid_topics.append({
130:                         "title": t.get("title", ""),
131:                         "source": t.get("source", "未知来源"),
132:                         "summary": t.get("summary", ""),
133:                         "outline": t.get("outline", []),
134:                         "why_hot": t.get("why_hot", "")
135:                     })
136:             return valid_topics[:10]
137:     except json.JSONDecodeError as e:
138:         print(f"[Trend Error] JSON 解析错误: {e}")
139:     return []
140: 
141: 
142: def _fallback_analyze(niche: str) -> tuple[list, str]:
143:     """
144:     降级方案：不使用联网搜索，直接让模型生成选题（使用 OpenRouter，更快）
145:     """
146:     try:
147:         from openai import OpenAI
148:         
149:         # 使用 OpenRouter（速度快）
150:         client = OpenAI(
151:             base_url="https://openrouter.ai/api/v1",
152:             api_key=os.getenv("OPENROUTER_API_KEY"),
153:         )
154:         
155:         response = client.chat.completions.create(
156:             model="deepseek/deepseek-chat",  # 快速且便宜
157:             max_tokens=2048,
158:             temperature=0.7,
159:             messages=[{
160:                 "role": "user", 
161:                 "content": f"""你是小红书数据分析师。根据关键词「{niche}」，推荐 10 个爆款选题。
162: 
163: 每个选题包含：
164: 1. title: 选题标题（20字以内）
165: 2. source: 内容类型（如：经验分享、情绪吐槽、干货教程）
166: 3. summary: 内容描述（50-100字）
167: 4. outline: 内容大纲（3-5个要点，每个15字以内）
168: 5. why_hot: 为什么可能火（30字以内）
169: 
170: 直接输出 JSON 数组，格式：
171: [
172:     {{
173:         "title": "选题标题",
174:         "source": "经验分享",
175:         "summary": "内容描述...",
176:         "outline": ["要点1", "要点2", "要点3"],
177:         "why_hot": "击中的情绪点"
178:     }}
179: ]"""
180:             }]
181:         )
182:         
183:         text = response.choices[0].message.content
184:         topics = _parse_topics_json(text)
185:         
186:         if topics:
187:             return topics, "fallback"
188:         else:
189:             # 最终兜底
190:             return _create_fallback_topics(niche), "error"
191:         
192:     except Exception as e:
193:         print(f"[Trend Error] 降级方案也失败: {e}")
194:         return _create_fallback_topics(niche), "error"
195: 
196: 
197: def _create_fallback_topics(niche: str) -> list:
198:     """创建兜底的选题数据"""
199:     return [{
200:         "title": f"关于{niche}的热门话题",
201:         "source": "获取失败",
202:         "summary": "无法获取热点数据，请检查网络后重试",
203:         "outline": ["请重新搜索"],
204:         "why_hot": "—"
205:     }]
</file>

<file path="README.md">
  1: # Ideogram Note - 小红书爆款内容工作流
  2: 
  3: > 基于 Next.js + FastAPI 的 AI 驱动内容创作平台  
  4: > 支持图文、视频、公众号三种模式，从选题到成品一站式完成
  5: 
  6: ## ✨ 核心功能
  7: 
  8: ### 1. 选题雷达
  9: - **热门关键词**: 预设 10 个高频领域关键词，一键搜索
 10: - **AI 推荐模式**: DeepSeek 快速生成 10 个爆款选题（3-5秒）
 11: - **实时搜索模式**: 火山引擎联网搜索小红书热点（20-30秒）
 12: - **智能缓存**: 6 小时缓存，相同关键词秒返
 13: 
 14: ### 2. 人设配置
 15: - **5 大领域人设库**: 职场/美妆/生活/宠物/技术
 16: - **双模型对比**: 并行生成两个版本，选择最优结果
 17: - **Temperature 控制**: 0.3-1.0 创意度调节
 18: - **参考链接**: 支持输入小红书笔记 URL，模仿风格
 19: 
 20: ### 3. 内容生成
 21: - **多模型支持**: DeepSeek/Claude/GPT-4o/Gemini/Grok
 22: - **结构化输出**: 5 个备选标题 + 800 字正文 + 配图大纲
 23: - **模式切换**:
 24:   - 图文模式: 生成小红书图文内容 + 3-6 张配图方案
 25:   - 视频模式: 生成视频脚本 + 分镜设计 + 口播词
 26:   - 公众号模式: 长文章 + 技术架构图设计
 27: 
 28: ### 4. 提示词预览（生图功能已隐藏）
 29: - **中英文 Prompt**: 完整展示画面描述和生图提示词
 30: - **一键复制**: 支持单个/全部场景信息复制
 31: - **外部生图**: 将 prompt 复制到 Midjourney/Stable Diffusion 等工具
 32: 
 33: ### 5. 导出功能
 34: - **Obsidian 集成**: 一键导出 Markdown 笔记
 35: - **图片关联**: 自动下载并关联配图 URL
 36: - **标签分类**: 自动添加话题标签
 37: 
 38: ## 🏗️ 技术架构
 39: 
 40: ### 前端（Next.js）
 41: ```
 42: frontend/
 43: ├── src/
 44: │   ├── app/                # Next.js App Router
 45: │   │   ├── page.tsx        # 主页面
 46: │   │   └── layout.tsx      # 全局布局
 47: │   ├── components/
 48: │   │   ├── blocks/         # 业务组件
 49: │   │   │   ├── TopicRadar.tsx      # 选题雷达
 50: │   │   │   ├── PersonaConfig.tsx   # 人设配置
 51: │   │   │   ├── ContentPreview.tsx  # 内容预览
 52: │   │   │   └── MediaStudio.tsx     # 提示词预览
 53: │   │   ├── layout/         # 布局组件
 54: │   │   │   ├── Header.tsx
 55: │   │   │   └── Sidebar.tsx
 56: │   │   └── ui/             # shadcn/ui 组件
 57: │   ├── lib/
 58: │   │   ├── api.ts          # API 客户端
 59: │   │   ├── progress-utils.ts   # 进度模拟工具
 60: │   │   └── utils.ts
 61: │   └── store/
 62: │       └── workflow.ts     # Zustand 状态管理
 63: ```
 64: 
 65: **技术栈**:
 66: - Next.js 16 (App Router)
 67: - TypeScript 5
 68: - Tailwind CSS 4
 69: - Framer Motion (动画)
 70: - Zustand (状态管理)
 71: - shadcn/ui (UI 组件)
 72: 
 73: ### 后端（FastAPI）
 74: ```
 75: backend/
 76: ├── main.py             # FastAPI 入口
 77: ├── routers/
 78: │   ├── topics.py       # 选题分析 API
 79: │   ├── content.py      # 内容生成 API
 80: │   ├── media.py        # 图片/音频生成 API
 81: │   ├── video.py        # 视频合成 API
 82: │   └── config.py       # 配置 API
 83: └── requirements.txt
 84: 
 85: modules/
 86: ├── trend.py            # 热点分析（火山引擎联网搜索）
 87: ├── writer.py           # 文案生成（OpenRouter）
 88: ├── painter.py          # 配图生成（Replicate/豆包/Nano Banana Pro）
 89: ├── audio.py            # 音频生成（Edge TTS/火山引擎）
 90: ├── editor.py           # 视频合成（MoviePy）
 91: ├── storage.py          # OSS 存储
 92: ├── persona.py          # 人设管理
 93: ├── quality_checker.py  # 质量检测
 94: └── md_exporter.py      # Markdown 导出
 95: ```
 96: 
 97: ## 🚀 快速启动
 98: 
 99: ### 环境要求
100: - Python 3.10+
101: - Node.js 18+
102: - Chrome 浏览器（如需爬虫功能）
103: 
104: ### 1. 克隆项目
105: ```bash
106: git clone <repo_url>
107: cd Ideogram_note
108: ```
109: 
110: ### 2. 配置环境变量
111: 创建 `.env` 文件：
112: ```env
113: # LLM 文案生成（必需）
114: OPENROUTER_API_KEY=sk-or-xxx
115: 
116: # 火山引擎（选题搜索 + TTS）
117: ARK_API_KEY=xxx
118: VOLC_ACCESS_KEY=xxx
119: VOLC_SECRET_KEY=xxx
120: VOLC_APP_ID=xxx
121: 
122: # 图片生成（可选，生图功能已隐藏）
123: REPLICATE_API_TOKEN=r8_xxx
124: 
125: # 阿里云 OSS（图片存储，可选）
126: OSS_ACCESS_KEY_ID=xxx
127: OSS_ACCESS_KEY_SECRET=xxx
128: OSS_ENDPOINT=oss-cn-hangzhou.aliyuncs.com
129: OSS_BUCKET_NAME=your-bucket
130: OSS_URL_PREFIX=https://your-bucket.oss-cn-hangzhou.aliyuncs.com
131: 
132: # Obsidian 导出路径（可选）
133: OBSIDIAN_VAULT_PATH=/Users/你的用户名/Documents/Obsidian/笔记库
134: ```
135: 
136: ### 3. 安装依赖
137: 
138: **后端依赖**:
139: ```bash
140: cd backend
141: pip install -r requirements.txt
142: cd ..
143: ```
144: 
145: **前端依赖**:
146: ```bash
147: cd frontend
148: npm install
149: cd ..
150: ```
151: 
152: ### 4. 启动项目
153: 
154: **方式一：从根目录启动（推荐）**
155: 
156: 在项目根目录打开两个终端：
157: 
158: 终端1 - 启动后端:
159: ```bash
160: python3 -m uvicorn backend.main:app --reload --port 8501
161: ```
162: 
163: 终端2 - 启动前端:
164: ```bash
165: cd frontend && npm run dev
166: ```
167: 
168: **方式二：分别启动**
169: 
170: 后端:
171: ```bash
172: cd backend
173: uvicorn main:app --reload --port 8501
174: ```
175: 
176: 前端:
177: ```bash
178: cd frontend
179: npm run dev
180: ```
181: 
182: **访问地址**:
183: - 前端: http://localhost:3000
184: - 后端: http://localhost:8501
185: - API 文档: http://localhost:8501/docs
186: 
187: ## 📦 依赖服务
188: 
189: | 服务 | 用途 | 必需性 | 成本 |
190: |------|------|--------|------|
191: | OpenRouter | LLM 文案生成 | ✅ 必需 | 按量计费，约 $0.001/千字 |
192: | 火山引擎 ARK | 联网搜索热点 | ✅ 必需 | 按调用计费 |
193: | 火山引擎 TTS | 音频生成（视频模式） | 视频模式必需 | 按字符计费 |
194: | Replicate | 图片生成（已隐藏） | 可选 | 约 $0.04/张 |
195: | 阿里云 OSS | 图片存储 | 可选 | 存储+流量费用 |
196: | Edge TTS | 免费音频生成 | 可选 | 免费 |
197: 
198: ## 🎯 使用流程
199: 
200: ### 图文模式（小红书）
201: 1. **输入关键词** → 点击热门关键词或手动输入（如：职场晋升）
202: 2. **AI 推荐** → 快速获取 10 个爆款选题
203: 3. **选择话题** → 点击感兴趣的选题
204: 4. **配置人设** → 选择赛道和人设风格（如：职场反共识观察者）
205: 5. **生成内容** → 启用双模型对比（可选），点击"开始生成"
206: 6. **查看 Prompt** → 在提示词预览中复制生图 prompt
207: 7. **导出笔记** → 一键导出到 Obsidian
208: 
209: ### 视频模式
210: 1-5 步同上
211: 6. **查看分镜** → 口播词 + 画面描述 + 生图 prompt
212: 7. 复制 prompt 到外部生图工具制作视频
213: 
214: ### 公众号模式
215: 1-5 步同上
216: 6. **查看架构图** → 技术描述 + 生图 prompt
217: 7. 导出长文到 Obsidian
218: 
219: ## 🧩 核心模块说明
220: 
221: ### writer.py - 文案生成引擎
222: - **结构化输出**: JSON Schema 强制格式化
223: - **人设融合**: 根据选择的人设调整语言风格
224: - **大纲扩展**: 基于热点大纲深度创作
225: - **多模型支持**: 5 个主流 LLM 可选
226: 
227: ### trend.py - 热点分析引擎
228: - **联网搜索**: 火山引擎 Web Search 插件实时搜索小红书
229: - **智能降级**: 联网失败自动降级到 LLM 推测
230: - **结果缓存**: 6 小时内相同关键词直接返回缓存
231: 
232: ### painter.py - 生图 Prompt 生成器
233: - **三种生图服务**:
234:   - Replicate (二次元风格)
235:   - 火山引擎豆包 (Seedream)
236:   - Nano Banana Pro (超高质量)
237: - **风格库**: 预设多种情感风格（可爱治愈/严肃深度/职场日常等）
238: - **中英文适配**: 根据服务商自动使用中文或英文 prompt
239: 
240: ### quality_checker.py - 质量检测
241: - 标题吸引力检测
242: - 内容完整性验证
243: - 敏感词过滤
244: 
245: ## 🎨 人设库
246: 
247: ### 职场赛道
248: - 职场反共识观察者（冷幽默拆解职场迷思）
249: - 职场清醒女王（犀利冷艳，只谈利益）
250: - 腹黑HR姐姐（揭秘潜规则，话术SOP）
251: - 精英操盘手（逻辑严密，输出方法论）
252: - 90后精神离职艺术家（糊弄学大师）
253: 
254: ### 美妆赛道
255: - 专业成分党（理性分析，数据说话）
256: - 贵妇种草机（高端大气，品质生活）
257: 
258: ### 生活赛道
259: - 治愈系姐姐（温暖陪伴，情绪价值）
260: - 搞钱女孩（副业干货，变现路径）
261: 
262: ### 宠物萌宠赛道
263: - 硬核成分党兽医（科学养宠，拒绝智商税）
264: - 精致富养铲屎官（颜值正义，治愈氛围）
265: - 金牌训宠师（SOP化教学，行为矫正）
266: 
267: ### 硬核技术/AI赛道
268: - 全栈AI架构师（深度技术文章，架构图设计）
269: 
270: ## 🔧 开发相关
271: 
272: ### 后端 API 端点
273: ```
274: GET  /health                      # 健康检查
275: POST /api/topics/analyze          # 选题分析
276: POST /api/content/generate        # 内容生成
277: POST /api/content/export          # 导出 Markdown
278: GET  /api/config/models           # LLM 模型列表
279: GET  /api/config/voices           # TTS 语音列表
280: GET  /api/config/personas         # 人设库
281: POST /api/media/images            # 批量生图（已禁用）
282: POST /api/media/audio             # 批量音频生成
283: POST /api/video/create            # 视频合成
284: GET  /api/video/bgm               # BGM 列表
285: ```
286: 
287: ### 前端状态管理（Zustand）
288: ```typescript
289: // 全局状态
290: - mode: "image" | "video" | "wechat"
291: - currentStep: "topic" | "persona" | "preview" | "studio"
292: - keyword: string
293: - topics: TopicItem[]
294: - selectedTopic: TopicItem | null
295: - selectedPersona: string
296: - generatedContent: GenerateResponse | null
297: - dualModelMode: boolean
298: - temperature: number
299: ```
300: 
301: ### 关键配置
302: - **默认模式**: 图文模式（小红书）
303: - **默认人设**: 硬核技术/AI - 全栈AI架构师
304: - **默认 LLM**: deepseek/deepseek-chat
305: - **双模型**: 默认启用（DeepSeek + Claude 3.5 Sonnet）
306: - **Temperature**: 0.4
307: 
308: ## 📝 最新更新
309: 
310: ### v2.0 (2024-12-07)
311: - ✅ 热门关键词快捷入口（10个预设关键词）
312: - ✅ 修复模型B下拉框数据显示问题
313: - ✅ MediaStudio 添加完整中英文 prompt 显示
314: - ✅ 添加 Nano Banana Pro 生图模型支持
315: - ✅ 隐藏生图功能，仅保留 prompt 预览
316: - ✅ 修复搜索按钮独立 loading 状态
317: - ✅ 进度条动画优化
318: - ✅ 双模型对比 UI 增强
319: 
320: ### v1.x
321: - 基础工作流实现
322: - Streamlit UI
323: - 单模型生成
324: 
325: ## 🔒 数据安全
326: 
327: - **本地存储**: 所有生成的图片、音频、视频存储在 `output/` 目录
328: - **状态持久化**: Zustand persist 到 localStorage
329: - **API 调用**: 所有敏感信息通过环境变量配置
330: - **无数据上传**: 不收集用户数据，仅调用第三方 API
331: 
332: ## 📂 项目结构
333: 
334: ```
335: Ideogram_note/
336: ├── backend/            # FastAPI 后端
337: │   ├── main.py
338: │   └── routers/
339: ├── frontend/           # Next.js 前端
340: │   └── src/
341: ├── modules/            # 核心业务逻辑
342: │   ├── trend.py        # 热点分析
343: │   ├── writer.py       # 文案生成
344: │   ├── painter.py      # Prompt 生成
345: │   ├── audio.py        # 音频生成
346: │   ├── editor.py       # 视频合成
347: │   └── ...
348: ├── data/
349: │   ├── personas.json   # 人设库
350: │   └── monitor.db      # 内容记录
351: ├── assets/
352: │   └── bgm/            # 背景音乐素材
353: ├── output/             # 生成结果输出目录
354: │   ├── images/
355: │   ├── audio/
356: │   └── video/
357: └── .env                # 环境变量配置
358: ```
359: 
360: ## 🐛 常见问题
361: 
362: ### 1. 后端启动失败
363: - 检查 `.env` 文件是否存在
364: - 检查 `OPENROUTER_API_KEY` 是否配置
365: - 确保端口 8501 未被占用
366: 
367: ### 2. 前端连接失败
368: - 确保后端服务已启动（http://localhost:8501/health）
369: - 检查前端的 `.env.local` 中 `NEXT_PUBLIC_API_URL` 配置
370: 
371: ### 3. 选题搜索失败
372: - 检查 `ARK_API_KEY` 是否有效
373: - 尝试切换到"AI推荐"模式（不依赖联网搜索）
374: 
375: ### 4. 内容生成失败
376: - 检查 OpenRouter API 余额
377: - 尝试切换其他模型
378: - 查看后端日志排查具体错误
379: 
380: ### 5. 模型B下拉框为空
381: - 刷新页面重新加载模型列表
382: - 检查后端 `/api/config/models` 端点是否正常
383: 
384: ## 💡 最佳实践
385: 
386: ### 1. 选题策略
387: - 使用热门关键词快速测试
388: - AI 推荐模式速度快，适合批量生产
389: - 实时搜索模式数据准确，适合追热点
390: 
391: ### 2. 人设选择
392: - 根据目标受众选择合适人设
393: - 自定义人设时提供详细的风格描述
394: - 使用参考链接模仿成功笔记风格
395: 
396: ### 3. 双模型对比
397: - 打开双模型模式生成两个版本
398: - 对比选择更优版本
399: - Temperature 较高时差异更明显
400: 
401: ### 4. Prompt 使用
402: - 复制完整 prompt 到专业生图工具
403: - 根据需要微调 prompt
404: - 保存优质 prompt 复用
405: 
406: ## 📄 许可证
407: 
408: MIT License
409: 
410: ## 🙏 致谢
411: 
412: - OpenRouter - LLM API 聚合
413: - 火山引擎 - 联网搜索 + TTS
414: - Replicate - 模型托管平台
415: - shadcn/ui - UI 组件库
416: - Next.js - React 框架
417: 
418: ---
419: 
420: **开发者**: 0xNiedlichX  
421: **更新日期**: 2024-12-07
</file>

<file path="frontend/src/components/blocks/TopicRadar.tsx">
  1: "use client";
  2: 
  3: import { useState } from "react";
  4: import { motion, AnimatePresence } from "framer-motion";
  5: import {
  6:   Search,
  7:   Sparkles,
  8:   TrendingUp,
  9:   ChevronDown,
 10:   ChevronRight,
 11:   Check,
 12:   Globe,
 13:   AlertCircle,
 14:   Loader2,
 15:   RotateCcw,
 16:   RefreshCw,
 17:   Brain,
 18: } from "lucide-react";
 19: import { cn } from "@/lib/utils";
 20: import { Button } from "@/components/ui/button";
 21: import { Input } from "@/components/ui/input";
 22: import { Badge } from "@/components/ui/badge";
 23: import {
 24:   Collapsible,
 25:   CollapsibleContent,
 26:   CollapsibleTrigger,
 27: } from "@/components/ui/collapsible";
 28: import { useWorkflowStore } from "@/store/workflow";
 29: import { analyzeTopics } from "@/lib/api";
 30: import { toast } from "sonner";
 31: import { StepProgress, type Step } from "@/components/ui/step-progress";
 32: import { simulateStepProgress, createDefaultSteps } from "@/lib/progress-utils";
 33: 
 34: const containerVariants = {
 35:   hidden: { opacity: 0 },
 36:   visible: {
 37:     opacity: 1,
 38:     transition: { staggerChildren: 0.05 },
 39:   },
 40: };
 41: 
 42: const itemVariants = {
 43:   hidden: { opacity: 0, y: 10 },
 44:   visible: { opacity: 1, y: 0 },
 45: };
 46: 
 47: export function TopicRadar() {
 48:   const {
 49:     keyword,
 50:     setKeyword,
 51:     topics,
 52:     setTopics,
 53:     topicsSource,
 54:     selectedTopic,
 55:     selectTopic,
 56:     isAnalyzing,
 57:     setIsAnalyzing,
 58:     setStep,
 59:     resetAll,
 60:   } = useWorkflowStore();
 61: 
 62:   const [expandedIndex, setExpandedIndex] = useState<number | null>(null);
 63:   const [analysisSteps, setAnalysisSteps] = useState<Step[]>([]);
 64:   const [searchMode, setSearchMode] = useState<"websearch" | "llm">("llm");
 65: 
 66:   const handleAnalyze = async (mode?: "websearch" | "llm") => {
 67:     const actualMode = mode || searchMode;
 68:     
 69:     if (!keyword.trim()) {
 70:       toast.error("请输入关键词");
 71:       return;
 72:     }
 73: 
 74:     // 记录当前搜索模式
 75:     setSearchMode(actualMode);
 76: 
 77:     // 根据模式调整进度步骤
 78:     const steps = actualMode === "llm"
 79:       ? createDefaultSteps([
 80:           { label: "LLM 分析关键词...", time: 3 },
 81:           { label: "推荐热门选题...", time: 5 },
 82:         ])
 83:       : createDefaultSteps([
 84:           { label: "正在分析关键词...", time: 3 },
 85:           { label: "搜索热门话题...", time: 12 },
 86:           { label: "提取大纲要点...", time: 8 },
 87:           { label: "分析火爆原因...", time: 7 },
 88:         ]);
 89:     
 90:     setAnalysisSteps(steps);
 91:     setIsAnalyzing(true);
 92: 
 93:     const { promise } = simulateStepProgress({
 94:       steps,
 95:       onStepChange: setAnalysisSteps,
 96:       actualTask: async () => {
 97:         const response = await analyzeTopics(keyword.trim(), actualMode);
 98:         setTopics(response.topics, response.source);
 99: 
100:         if (response.source === "llm" || response.source.includes("llm")) {
101:           toast.success("AI 快速推荐完成");
102:         } else if (response.source === "websearch" || response.source.includes("websearch")) {
103:           toast.success("已获取实时热点数据");
104:         } else if (response.source === "fallback") {
105:           toast.warning("联网搜索失败，使用 AI 推测模式");
106:         } else {
107:           toast.error("获取热点失败，请重试");
108:         }
109:       },
110:     });
111: 
112:     try {
113:       await promise;
114:     } catch (error) {
115:       toast.error("分析失败: " + (error as Error).message);
116:     } finally {
117:       setIsAnalyzing(false);
118:       // 清空进度步骤（延迟一秒让用户看到完成状态）
119:       setTimeout(() => setAnalysisSteps([]), 1000);
120:     }
121:   };
122: 
123:   const handleSelectTopic = (topic: typeof topics[0]) => {
124:     selectTopic(topic);
125:     setStep("persona");
126:     toast.success(`已选择: ${topic.title.slice(0, 20)}...`);
127:   };
128: 
129:   const handleReset = () => {
130:     resetAll();
131:     localStorage.removeItem("workflow-storage");
132:     toast.success("已重置所有数据");
133:   };
134: 
135:   return (
136:     <section className="space-y-6">
137:       {/* Section Header */}
138:       <div className="flex items-center gap-3">
139:         <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-primary/10 text-primary">
140:           <Search className="w-4 h-4" />
141:         </div>
142:         <div>
143:           <h2 className="text-lg font-semibold">选题雷达</h2>
144:           <p className="text-sm text-muted-foreground">
145:             输入关键词，AI 联网搜索热门内容
146:           </p>
147:         </div>
148:       </div>
149: 
150:       {/* Search Input */}
151:       <div className="flex gap-3">
152:         <div className="relative flex-1">
153:           <Input
154:             value={keyword}
155:             onChange={(e) => setKeyword(e.target.value)}
156:             placeholder="输入关键词：酒局妆容 / 年终奖谈判 ..."
157:             className="h-11 pl-4 pr-4 text-base bg-secondary/50 border-0 focus-visible:ring-1 focus-visible:ring-primary/50"
158:             onKeyDown={(e) => e.key === "Enter" && handleAnalyze()}
159:           />
160:         </div>
161:         <Button
162:           onClick={() => handleAnalyze("llm")}
163:           disabled={isAnalyzing || !keyword.trim()}
164:           variant={searchMode === "llm" ? "default" : "secondary"}
165:           className="h-11 px-6 gap-2"
166:         >
167:           {isAnalyzing && searchMode === "llm" ? (
168:             <Loader2 className="w-4 h-4 animate-spin" />
169:           ) : (
170:             <Brain className="w-4 h-4" />
171:           )}
172:           {isAnalyzing && searchMode === "llm" ? "推荐中..." : "AI推荐"}
173:         </Button>
174:         <Button
175:           onClick={() => handleAnalyze("websearch")}
176:           disabled={isAnalyzing || !keyword.trim()}
177:           variant={searchMode === "websearch" ? "default" : "secondary"}
178:           className="h-11 px-6 gap-2"
179:         >
180:           {isAnalyzing && searchMode === "websearch" ? (
181:             <Loader2 className="w-4 h-4 animate-spin" />
182:           ) : (
183:             <Globe className="w-4 h-4" />
184:           )}
185:           {isAnalyzing && searchMode === "websearch" ? "搜索中..." : "实时搜索"}
186:         </Button>
187:         <Button
188:           variant="outline"
189:           onClick={handleReset}
190:           className="h-11 px-4 gap-2"
191:           title="重置所有数据"
192:         >
193:           <RotateCcw className="w-4 h-4" />
194:           重置
195:         </Button>
196:       </div>
197: 
198:       {/* Analysis Progress */}
199:       {analysisSteps.length > 0 && (
200:         <motion.div
201:           initial={{ opacity: 0, height: 0 }}
202:           animate={{ opacity: 1, height: "auto" }}
203:           exit={{ opacity: 0, height: 0 }}
204:           className="p-6 rounded-xl border bg-card"
205:         >
206:           <StepProgress steps={analysisSteps} />
207:         </motion.div>
208:       )}
209: 
210:       {/* Topics List */}
211:       <AnimatePresence mode="wait">
212:         {topics.length > 0 && (
213:           <motion.div
214:             variants={containerVariants}
215:             initial="hidden"
216:             animate="visible"
217:             exit="hidden"
218:             className="space-y-4"
219:           >
220:             {/* Source Badge + Refresh */}
221:             <div className="flex items-center justify-between">
222:             <div className="flex items-center gap-2">
223:               <Badge
224:                 variant="secondary"
225:                 className={cn(
226:                   "gap-1",
227:                   topicsSource === "websearch" && "bg-emerald-100 text-emerald-700 dark:bg-emerald-900/30 dark:text-emerald-300",
228:                   topicsSource === "fallback" && "bg-amber-100 text-amber-700 dark:bg-amber-900/30 dark:text-amber-300"
229:                 )}
230:               >
231:                 {topicsSource === "websearch" ? (
232:                   <Globe className="w-3 h-3" />
233:                 ) : (
234:                   <AlertCircle className="w-3 h-3" />
235:                 )}
236:                   {topicsSource === "websearch" ? "小红书热点" : "AI 推测"}
237:               </Badge>
238:               <span className="text-sm text-muted-foreground">
239:                 {topics.length} 个热门话题
240:               </span>
241:               </div>
242:               <Button
243:                 variant="ghost"
244:                 size="sm"
245:                 onClick={handleAnalyze}
246:                 disabled={isAnalyzing}
247:                 className="gap-1.5 text-muted-foreground hover:text-foreground"
248:               >
249:                 <RefreshCw className={cn("w-3.5 h-3.5", isAnalyzing && "animate-spin")} />
250:                 换一批
251:               </Button>
252:             </div>
253: 
254:             {/* Topic Cards */}
255:             <div className="space-y-2">
256:               {topics.map((topic, index) => {
257:                 const isSelected = selectedTopic?.title === topic.title;
258:                 const isExpanded = expandedIndex === index;
259: 
260:                 return (
261:                   <motion.div
262:                     key={topic.title}
263:                     variants={itemVariants}
264:                     layoutId={`topic-${index}`}
265:                   >
266:                     <Collapsible
267:                       open={isExpanded}
268:                       onOpenChange={() =>
269:                         setExpandedIndex(isExpanded ? null : index)
270:                       }
271:                     >
272:                       <div
273:                         className={cn(
274:                           "group relative rounded-lg border transition-all duration-200",
275:                           "hover:border-primary/30 hover:shadow-sm",
276:                           isSelected
277:                             ? "border-primary bg-primary/5"
278:                             : "border-border bg-card"
279:                         )}
280:                       >
281:                         {/* Main Row */}
282:                         <div className="flex items-center gap-3 p-4">
283:                           {/* Select Button */}
284:                           <Button
285:                             variant={isSelected ? "default" : "outline"}
286:                             size="icon"
287:                             className={cn(
288:                               "h-8 w-8 shrink-0 transition-all",
289:                               !isSelected && "opacity-0 group-hover:opacity-100"
290:                             )}
291:                             onClick={() => handleSelectTopic(topic)}
292:                           >
293:                             <Check className="w-4 h-4" />
294:                           </Button>
295: 
296:                           {/* Content */}
297:                           <div className="flex-1 min-w-0">
298:                             <div className="flex items-center gap-2">
299:                               <h3 className="font-medium text-foreground truncate">
300:                                 {topic.title}
301:                               </h3>
302:                               {topic.source && (
303:                                 <Badge variant="secondary" className="shrink-0 text-xs">
304:                                   {topic.source}
305:                                 </Badge>
306:                               )}
307:                             </div>
308:                             {topic.summary && (
309:                               <p className="mt-1 text-sm text-muted-foreground line-clamp-1">
310:                                 {topic.summary}
311:                               </p>
312:                             )}
313:                           </div>
314: 
315:                           {/* Expand Toggle */}
316:                           <CollapsibleTrigger asChild>
317:                             <Button
318:                               variant="ghost"
319:                               size="icon"
320:                               className="h-8 w-8 shrink-0"
321:                             >
322:                               {isExpanded ? (
323:                                 <ChevronDown className="w-4 h-4" />
324:                               ) : (
325:                                 <ChevronRight className="w-4 h-4" />
326:                               )}
327:                             </Button>
328:                           </CollapsibleTrigger>
329:                         </div>
330: 
331:                         {/* Expanded Content */}
332:                         <CollapsibleContent>
333:                           <div className="px-4 pb-4 pt-0 border-t border-border/50">
334:                             <div className="pt-4 space-y-3">
335:                               {/* Outline */}
336:                               {topic.outline.length > 0 && (
337:                                 <div>
338:                                   <h4 className="text-xs font-medium text-muted-foreground mb-2">
339:                                     内容大纲
340:                                   </h4>
341:                                   <ul className="space-y-1">
342:                                     {topic.outline.map((point, i) => (
343:                                       <li
344:                                         key={i}
345:                                         className="text-sm text-foreground flex items-start gap-2"
346:                                       >
347:                                         <span className="text-primary shrink-0">
348:                                           {i + 1}.
349:                                         </span>
350:                                         {point}
351:                                       </li>
352:                                     ))}
353:                                   </ul>
354:                                 </div>
355:                               )}
356: 
357:                               {/* Why Hot */}
358:                               {topic.why_hot && (
359:                                 <div className="flex items-start gap-2 p-3 rounded-md bg-secondary/50">
360:                                   <TrendingUp className="w-4 h-4 text-primary shrink-0 mt-0.5" />
361:                                   <div>
362:                                     <span className="text-xs font-medium text-muted-foreground">
363:                                       火爆原因
364:                                     </span>
365:                                     <p className="text-sm text-foreground mt-0.5">
366:                                       {topic.why_hot}
367:                                     </p>
368:                                   </div>
369:                                 </div>
370:                               )}
371: 
372:                               {/* Select Button */}
373:                               <Button
374:                                 onClick={() => handleSelectTopic(topic)}
375:                                 className="w-full gap-2"
376:                                 variant={isSelected ? "secondary" : "default"}
377:                               >
378:                                 <Check className="w-4 h-4" />
379:                                 {isSelected ? "已选择此话题" : "选择此话题"}
380:                               </Button>
381:                             </div>
382:                           </div>
383:                         </CollapsibleContent>
384:                       </div>
385:                     </Collapsible>
386:                   </motion.div>
387:                 );
388:               })}
389:             </div>
390:           </motion.div>
391:         )}
392:       </AnimatePresence>
393: 
394:       {/* Empty State */}
395:       {!isAnalyzing && topics.length === 0 && (
396:         <div className="flex flex-col items-center justify-center py-12 text-center">
397:           <div className="w-12 h-12 rounded-full bg-secondary flex items-center justify-center mb-4">
398:             <Search className="w-6 h-6 text-muted-foreground" />
399:           </div>
400:           <h3 className="font-medium text-foreground mb-1">输入关键词开始</h3>
401:           <p className="text-sm text-muted-foreground max-w-sm">
402:             AI 将联网搜索小红书热门笔记，为你提供爆款选题建议
403:           </p>
404:         </div>
405:       )}
406:     </section>
407:   );
408: }
</file>

<file path="modules/md_exporter.py">
  1: """
  2: Obsidian MD 文件导出模块
  3: 将生成的笔记导出为 Markdown 文件，保存到本地 Obsidian 目录
  4: """
  5: import os
  6: from pathlib import Path
  7: from datetime import datetime
  8: from typing import Optional, List
  9: from dotenv import load_dotenv
 10: from modules.utils import sanitize_filename
 11: 
 12: load_dotenv()
 13: 
 14: # Obsidian 导出目录
 15: OBSIDIAN_EXPORT_PATH = os.getenv(
 16:     "OBSIDIAN_EXPORT_PATH", 
 17:     "/Users/0xNiedlichX/Library/Mobile Documents/iCloud~md~obsidian/Documents/DonxYu Space/0-Inbox/Rednote_Auto"
 18: )
 19: 
 20: 
 21: def export_note(
 22:     topic: str,
 23:     title: str,
 24:     content: str,
 25:     image_urls: Optional[List[str]] = None,
 26:     tags: Optional[List[str]] = None
 27: ) -> Optional[str]:
 28:     """
 29:     导出笔记为 Obsidian MD 文件
 30:     
 31:     Args:
 32:         topic: 主题/选题（用于文件命名）
 33:         title: 笔记标题
 34:         content: 笔记正文
 35:         image_urls: OSS 图片 URL 列表（将嵌入到 MD 文件中）
 36:         tags: 标签列表
 37:     
 38:     Returns:
 39:         成功返回 MD 文件路径，失败返回 None
 40:     """
 41:     try:
 42:         # 确保目录存在
 43:         export_dir = Path(OBSIDIAN_EXPORT_PATH)
 44:         export_dir.mkdir(parents=True, exist_ok=True)
 45:         
 46:         # 生成文件名
 47:         safe_topic = sanitize_filename(topic) if topic else "untitled"
 48:         timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
 49:         filename = f"{safe_topic}_{timestamp}.md"
 50:         file_path = export_dir / filename
 51:         
 52:         # 构建 MD 内容
 53:         md_lines = []
 54:         
 55:         # Frontmatter (YAML 元数据)
 56:         md_lines.append("---")
 57:         md_lines.append(f"title: {title}")
 58:         md_lines.append(f"topic: {topic}")
 59:         md_lines.append(f"created: {datetime.now().isoformat()}")
 60:         if tags:
 61:             md_lines.append(f"tags: [{', '.join(tags)}]")
 62:         else:
 63:             md_lines.append("tags: [小红书, 自动生成]")
 64:         md_lines.append("---")
 65:         md_lines.append("")
 66:         
 67:         # 标题
 68:         md_lines.append(f"# {title}")
 69:         md_lines.append("")
 70:         
 71:         # 正文
 72:         # 处理换行符（\n -> 实际换行）
 73:         formatted_content = content.replace("\\n", "\n")
 74:         md_lines.append(formatted_content)
 75:         md_lines.append("")
 76:         
 77:         # 配图
 78:         if image_urls:
 79:             md_lines.append("---")
 80:             md_lines.append("")
 81:             md_lines.append("## 配图")
 82:             md_lines.append("")
 83:             for i, url in enumerate(image_urls):
 84:                 if url:
 85:                     md_lines.append(f"### 图片 {i+1}")
 86:                     md_lines.append(f"![{topic}_image_{i+1}]({url})")
 87:                     md_lines.append("")
 88:         
 89:         # 写入文件
 90:         with open(file_path, "w", encoding="utf-8") as f:
 91:             f.write("\n".join(md_lines))
 92:         
 93:         print(f"[MD Export] 笔记导出成功: {file_path}")
 94:         return str(file_path)
 95:         
 96:     except Exception as e:
 97:         print(f"[MD Export Error] 导出失败: {e}")
 98:         return None
 99: 
100: 
101: def export_note_simple(
102:     topic: str,
103:     title: str,
104:     content: str
105: ) -> Optional[str]:
106:     """
107:     简化版导出（仅标题和正文）
108:     
109:     Args:
110:         topic: 主题
111:         title: 标题
112:         content: 正文
113:     
114:     Returns:
115:         MD 文件路径
116:     """
117:     return export_note(topic, title, content, image_urls=None, tags=None)
118: 
119: 
120: def get_export_path() -> str:
121:     """获取导出目录路径"""
122:     return OBSIDIAN_EXPORT_PATH
</file>

<file path="backend/routers/content.py">
  1: """
  2: 内容生成 API
  3: """
  4: from fastapi import APIRouter, HTTPException
  5: from pydantic import BaseModel
  6: from typing import List, Optional, Dict, Any
  7: 
  8: from modules.writer import generate_note_package_with_retry
  9: from modules.crawler import fetch_note_content
 10: from modules.md_exporter import export_note
 11: 
 12: router = APIRouter()
 13: 
 14: 
 15: class ImageDesign(BaseModel):
 16:     index: int = 0
 17:     description: str = ""
 18:     prompt: str = ""
 19:     sentiment: str = ""
 20:     cover_text: Optional[str] = None  # 主图文字（仅第一张图需要）
 21: 
 22: 
 23: class VisualScene(BaseModel):
 24:     scene_index: int = 0
 25:     narration: str = ""
 26:     description: str = ""
 27:     sentiment: str = ""
 28:     prompt: str = ""
 29: 
 30: 
 31: class Diagram(BaseModel):
 32:     index: int = 0
 33:     title: str = ""
 34:     description: str = ""
 35:     diagram_type: str = "architecture"  # "architecture" | "flow" | "comparison"
 36:     prompt: str = ""
 37: 
 38: 
 39: class GenerateRequest(BaseModel):
 40:     topic: str
 41:     persona: Optional[str] = None
 42:     reference_url: Optional[str] = None
 43:     mode: str = "image"  # "image" | "video" | "wechat"
 44:     llm_model: str = "deepseek/deepseek-chat"
 45:     search_data: Optional[Dict[str, Any]] = None  # websearch 返回的完整热点数据
 46:     temperature: float = 0.8  # LLM 温度参数，控制创意度 vs 稳定性
 47:     
 48:     model_config = {"protected_namespaces": ()}
 49: 
 50: 
 51: class GenerateResponse(BaseModel):
 52:     titles: List[str] = []
 53:     content: str = ""
 54:     image_designs: Optional[List[ImageDesign]] = None
 55:     visual_scenes: Optional[List[VisualScene]] = None
 56:     diagrams: Optional[List[Diagram]] = None
 57: 
 58: 
 59: @router.post("/generate", response_model=GenerateResponse)
 60: async def generate_content(req: GenerateRequest):
 61:     """
 62:     生成内容（图文/视频模式）
 63:     
 64:     图文模式：返回 titles + content + image_designs
 65:     视频模式：返回 titles + content + visual_scenes
 66:     """
 67:     if not req.topic or not req.topic.strip():
 68:         raise HTTPException(status_code=400, detail="选题不能为空")
 69:     
 70:     try:
 71:         # 抓取参考内容（如有）
 72:         reference_text = None
 73:         if req.reference_url:
 74:             ref_data = fetch_note_content(req.reference_url)
 75:             if ref_data:
 76:                 reference_text = f"标题：{ref_data.get('title', '')}\n\n{ref_data.get('content', '')}"
 77:         
 78:         # 调用写作模块（带质量检测和重试）
 79:         result = generate_note_package_with_retry(
 80:             topic=req.topic.strip(),
 81:             persona=req.persona,
 82:             reference_text=reference_text,
 83:             mode=req.mode,
 84:             model_name=req.llm_model,
 85:             search_data=req.search_data,
 86:             temperature=req.temperature,
 87:             max_retries=2,
 88:             quality_threshold=70,
 89:         )
 90:         
 91:         if not result or not result.get("titles"):
 92:             raise HTTPException(status_code=500, detail="内容生成失败，请重试")
 93:         
 94:         # 构造响应
 95:         response = GenerateResponse(
 96:             titles=result.get("titles", []),
 97:             content=result.get("content", ""),
 98:         )
 99:         
100:         if req.mode == "video":
101:             scenes = result.get("visual_scenes", [])
102:             response.visual_scenes = [
103:                 VisualScene(
104:                     scene_index=s.get("scene_index", i + 1),
105:                     narration=s.get("narration", ""),
106:                     description=s.get("description", ""),
107:                     sentiment=s.get("sentiment", ""),
108:                     prompt=s.get("prompt", ""),
109:                 )
110:                 for i, s in enumerate(scenes)
111:             ]
112:         elif req.mode == "wechat":
113:             diagrams_data = result.get("diagrams", [])
114:             response.diagrams = [
115:                 Diagram(
116:                     index=d.get("index", i + 1),
117:                     title=d.get("title", ""),
118:                     description=d.get("description", ""),
119:                     diagram_type=d.get("diagram_type", "architecture"),
120:                     prompt=d.get("prompt", ""),
121:                 )
122:                 for i, d in enumerate(diagrams_data)
123:             ]
124:         else:
125:             designs = result.get("image_designs", [])
126:             response.image_designs = [
127:                 ImageDesign(
128:                     index=d.get("index", i + 1),
129:                     description=d.get("description", ""),
130:                     prompt=d.get("prompt", ""),
131:                     sentiment=d.get("sentiment", ""),
132:                     cover_text=d.get("cover_text"),
133:                 )
134:                 for i, d in enumerate(designs)
135:             ]
136:         
137:         return response
138:         
139:     except HTTPException:
140:         raise
141:     except Exception as e:
142:         raise HTTPException(status_code=500, detail=f"内容生成失败: {str(e)}")
143: 
144: 
145: class ExportRequest(BaseModel):
146:     topic: str
147:     title: str
148:     content: str
149:     image_urls: Optional[List[str]] = None
150:     tags: Optional[List[str]] = None
151: 
152: 
153: class ExportResponse(BaseModel):
154:     success: bool
155:     file_path: Optional[str] = None
156:     error: Optional[str] = None
157: 
158: 
159: @router.post("/export", response_model=ExportResponse)
160: async def export_note_to_obsidian(req: ExportRequest):
161:     """
162:     导出笔记到 Obsidian（MD 格式）
163:     
164:     将生成的笔记保存到本地 Obsidian 目录
165:     """
166:     if not req.topic or not req.title or not req.content:
167:         raise HTTPException(status_code=400, detail="主题、标题和内容不能为空")
168:     
169:     try:
170:         file_path = export_note(
171:             topic=req.topic,
172:             title=req.title,
173:             content=req.content,
174:             image_urls=req.image_urls,
175:             tags=req.tags,
176:         )
177:         
178:         if file_path:
179:             return ExportResponse(success=True, file_path=file_path)
180:         else:
181:             return ExportResponse(success=False, error="导出失败，请检查目录权限")
182:             
183:     except Exception as e:
184:         return ExportResponse(success=False, error=str(e))
</file>

<file path="backend/routers/media.py">
  1: """
  2: 素材生成 API（图片 + 音频）
  3: 支持 SSE 流式进度推送
  4: """
  5: import os
  6: import asyncio
  7: import json
  8: from pathlib import Path
  9: from typing import List, Optional
 10: 
 11: from fastapi import APIRouter, HTTPException
 12: from fastapi.responses import StreamingResponse
 13: from pydantic import BaseModel
 14: 
 15: from modules.painter import generate_images, generate_single_image, generate_images_mixed
 16: from modules.audio import generate_audio_for_scenes, generate_single_audio
 17: 
 18: router = APIRouter()
 19: 
 20: # 项目根目录
 21: ROOT_DIR = Path(__file__).parent.parent.parent
 22: 
 23: 
 24: class SceneInput(BaseModel):
 25:     prompt: str
 26:     narration: Optional[str] = None
 27:     sentiment: Optional[str] = None
 28: 
 29: 
 30: class ImageRequest(BaseModel):
 31:     scenes: List[SceneInput]
 32:     provider: str = "replicate"  # "replicate" | "volcengine"
 33:     anime_model: str = "anything-v4"  # "anything-v4" | "flux-anime"
 34:     topic: Optional[str] = None
 35:     mode: str = "video"  # "image" | "video" - 图文模式主图用 Gemini
 36: 
 37: 
 38: class AudioRequest(BaseModel):
 39:     scenes: List[SceneInput]
 40:     provider: str = "edge"  # "edge" | "volcengine"
 41:     voice: Optional[str] = None
 42:     topic: Optional[str] = None
 43: 
 44: 
 45: class SingleImageRequest(BaseModel):
 46:     scene: SceneInput
 47:     index: int
 48:     provider: str = "replicate"
 49:     anime_model: str = "anything-v4"
 50:     topic: Optional[str] = None
 51: 
 52: 
 53: class SingleAudioRequest(BaseModel):
 54:     scene: SceneInput
 55:     index: int
 56:     provider: str = "edge"
 57:     voice: Optional[str] = None
 58:     topic: Optional[str] = None
 59: 
 60: 
 61: class MediaResult(BaseModel):
 62:     index: int
 63:     path: Optional[str] = None
 64:     url: Optional[str] = None
 65:     error: Optional[str] = None
 66: 
 67: 
 68: class BatchMediaResponse(BaseModel):
 69:     results: List[MediaResult]
 70:     success_count: int
 71:     total: int
 72: 
 73: 
 74: def _path_to_url(path: str, media_type: str) -> Optional[str]:
 75:     """将本地路径转换为静态文件 URL，或直接返回 OSS URL"""
 76:     if not path:
 77:         return None
 78:     
 79:     # 如果已经是 URL（OSS 链接），直接返回
 80:     if path.startswith("http://") or path.startswith("https://"):
 81:         return path
 82:     
 83:     # 本地路径：检查文件是否存在
 84:     if not os.path.exists(path):
 85:         return None
 86:     
 87:     # 获取相对于 output 目录的路径
 88:     output_dir = ROOT_DIR / "output" / media_type
 89:     try:
 90:         # 将两个路径都转为绝对路径再比较
 91:         abs_path = Path(path).resolve()
 92:         abs_output_dir = output_dir.resolve()
 93:         rel_path = abs_path.relative_to(abs_output_dir)
 94:         return f"/static/{media_type}/{rel_path}"
 95:     except ValueError:
 96:         # 如果不在预期目录下，返回文件名
 97:         return f"/static/{media_type}/{Path(path).name}"
 98: 
 99: 
100: @router.post("/images", response_model=BatchMediaResponse)
101: async def generate_images_batch(req: ImageRequest):
102:     """
103:     批量生成图片
104:     
105:     - 视频模式：使用指定 provider 统一生成
106:     - 图文模式：主图用 Nano Banana Pro，配图用豆包
107:     """
108:     if not req.scenes:
109:         raise HTTPException(status_code=400, detail="分镜列表不能为空")
110:     
111:     try:
112:         # 转换为 modules 需要的格式
113:         scenes = [
114:             {"prompt": s.prompt, "sentiment": s.sentiment or ""}
115:             for s in req.scenes
116:         ]
117:         
118:         # 根据模式选择生图方式
119:         if req.mode == "image":
120:             # 图文模式：根据 provider 决定策略
121:             if req.provider == "gemini":
122:                 # 全部用 Nano Banana Pro
123:                 paths = generate_images(
124:                     scenes=scenes,
125:                     provider="gemini",
126:                     topic=req.topic,
127:                 )
128:             else:
129:                 # 主图 Nano Banana Pro + 配图指定 provider（默认豆包）
130:                 paths = generate_images_mixed(
131:                     scenes=scenes,
132:                     topic=req.topic,
133:                 )
134:         else:
135:             # 视频模式：统一 provider
136:             paths = generate_images(
137:                 scenes=scenes,
138:                 provider=req.provider,
139:                 anime_model=req.anime_model,
140:                 topic=req.topic,
141:             )
142:         
143:         # 构造结果
144:         results = []
145:         for i, path in enumerate(paths):
146:             results.append(MediaResult(
147:                 index=i,
148:                 path=path,
149:                 url=_path_to_url(path, "images") if path else None,
150:                 error=None if path else "生成失败",
151:             ))
152:         
153:         success_count = sum(1 for r in results if r.path)
154:         
155:         return BatchMediaResponse(
156:             results=results,
157:             success_count=success_count,
158:             total=len(req.scenes),
159:         )
160:         
161:     except Exception as e:
162:         raise HTTPException(status_code=500, detail=f"图片生成失败: {str(e)}")
163: 
164: 
165: @router.post("/images/single", response_model=MediaResult)
166: async def generate_image_single(req: SingleImageRequest):
167:     """
168:     生成单张图片（用于重试）
169:     """
170:     try:
171:         scene = {"prompt": req.scene.prompt, "sentiment": req.scene.sentiment or ""}
172:         
173:         path, error = generate_single_image(
174:             scene=scene,
175:             index=req.index,
176:             provider=req.provider,
177:             anime_model=req.anime_model,
178:             topic=req.topic,
179:         )
180:         
181:         return MediaResult(
182:             index=req.index,
183:             path=path,
184:             url=_path_to_url(path, "images") if path else None,
185:             error=error,
186:         )
187:         
188:     except Exception as e:
189:         return MediaResult(index=req.index, error=str(e))
190: 
191: 
192: @router.post("/audio", response_model=BatchMediaResponse)
193: async def generate_audio_batch(req: AudioRequest):
194:     """
195:     批量生成音频
196:     """
197:     if not req.scenes:
198:         raise HTTPException(status_code=400, detail="分镜列表不能为空")
199:     
200:     try:
201:         # 转换格式
202:         scenes = [{"narration": s.narration or ""} for s in req.scenes]
203:         
204:         # 调用音频模块
205:         paths = generate_audio_for_scenes(
206:             scenes=scenes,
207:             provider=req.provider,
208:             voice=req.voice,
209:             topic=req.topic,
210:         )
211:         
212:         # 构造结果
213:         results = []
214:         for i, path in enumerate(paths):
215:             results.append(MediaResult(
216:                 index=i,
217:                 path=path,
218:                 url=_path_to_url(path, "audio") if path else None,
219:                 error=None if path else "生成失败",
220:             ))
221:         
222:         success_count = sum(1 for r in results if r.path)
223:         
224:         return BatchMediaResponse(
225:             results=results,
226:             success_count=success_count,
227:             total=len(req.scenes),
228:         )
229:         
230:     except Exception as e:
231:         raise HTTPException(status_code=500, detail=f"音频生成失败: {str(e)}")
232: 
233: 
234: @router.post("/audio/single", response_model=MediaResult)
235: async def generate_audio_single(req: SingleAudioRequest):
236:     """
237:     生成单段音频（用于重试）
238:     """
239:     try:
240:         scene = {"narration": req.scene.narration or ""}
241:         
242:         path, error = generate_single_audio(
243:             scene=scene,
244:             index=req.index,
245:             provider=req.provider,
246:             voice=req.voice,
247:             topic=req.topic,
248:         )
249:         
250:         return MediaResult(
251:             index=req.index,
252:             path=path,
253:             url=_path_to_url(path, "audio") if path else None,
254:             error=error,
255:         )
256:         
257:     except Exception as e:
258:         return MediaResult(index=req.index, error=str(e))
259: 
260: 
261: # ========== SSE 流式进度 ==========
262: 
263: async def _generate_images_stream(req: ImageRequest):
264:     """图片生成 SSE 流"""
265:     scenes = [
266:         {"prompt": s.prompt, "sentiment": s.sentiment or ""}
267:         for s in req.scenes
268:     ]
269:     
270:     for i, scene in enumerate(scenes):
271:         yield f"data: {json.dumps({'type': 'progress', 'index': i, 'total': len(scenes), 'status': 'generating'})}\n\n"
272:         
273:         try:
274:             path, error = generate_single_image(
275:                 scene=scene,
276:                 index=i,
277:                 provider=req.provider,
278:                 anime_model=req.anime_model,
279:                 topic=req.topic,
280:             )
281:             
282:             result = {
283:                 "type": "result",
284:                 "index": i,
285:                 "path": path,
286:                 "url": _path_to_url(path, "images") if path else None,
287:                 "error": error,
288:             }
289:             yield f"data: {json.dumps(result)}\n\n"
290:             
291:         except Exception as e:
292:             yield f"data: {json.dumps({'type': 'result', 'index': i, 'error': str(e)})}\n\n"
293:         
294:         await asyncio.sleep(0.1)  # 小延迟让前端有时间处理
295:     
296:     yield f"data: {json.dumps({'type': 'done'})}\n\n"
297: 
298: 
299: @router.post("/images/stream")
300: async def generate_images_stream(req: ImageRequest):
301:     """
302:     流式生成图片（SSE）
303:     
304:     实时推送每张图片的生成进度和结果
305:     """
306:     return StreamingResponse(
307:         _generate_images_stream(req),
308:         media_type="text/event-stream",
309:         headers={
310:             "Cache-Control": "no-cache",
311:             "Connection": "keep-alive",
312:         },
313:     )
</file>

<file path="frontend/src/components/blocks/MediaStudio.tsx">
  1: "use client";
  2: 
  3: import { useEffect, useState } from "react";
  4: import { motion } from "framer-motion";
  5: import {
  6:   Clapperboard,
  7:   ChevronRight,
  8:   Image as ImageIcon,
  9:   Mic,
 10:   Video,
 11:   Download,
 12:   RefreshCw,
 13:   Loader2,
 14:   Check,
 15:   X,
 16:   Clock,
 17:   Play,
 18:   Music,
 19:   FileText,
 20:   Copy,
 21: } from "lucide-react";
 22: import { cn } from "@/lib/utils";
 23: import { Button } from "@/components/ui/button";
 24: import { Badge } from "@/components/ui/badge";
 25: import { Slider } from "@/components/ui/slider";
 26: import {
 27:   Select,
 28:   SelectContent,
 29:   SelectItem,
 30:   SelectTrigger,
 31:   SelectValue,
 32: } from "@/components/ui/select";
 33: import { ScrollArea } from "@/components/ui/scroll-area";
 34: import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
 35: import {
 36:   Collapsible,
 37:   CollapsibleContent,
 38:   CollapsibleTrigger,
 39: } from "@/components/ui/collapsible";
 40: import { useWorkflowStore } from "@/store/workflow";
 41: import {
 42:   generateImages,
 43:   generateAudio,
 44:   generateSingleImage,
 45:   generateSingleAudio,
 46:   createVideo,
 47:   getBgmList,
 48: } from "@/lib/api";
 49: import { toast } from "sonner";
 50: 
 51: const API_BASE = process.env.NEXT_PUBLIC_API_URL || "http://localhost:8501";
 52: 
 53: // 处理 URL：如果是完整 URL 则直接返回，否则拼接 API_BASE
 54: function resolveMediaUrl(url: string | null | undefined): string {
 55:   if (!url) return "";
 56:   if (url.startsWith("http://") || url.startsWith("https://")) {
 57:     return url;
 58:   }
 59:   return `${API_BASE}${url}`;
 60: }
 61: 
 62: function StatusBadge({ status }: { status: "pending" | "generating" | "success" | "error" }) {
 63:   const config = {
 64:     pending: { icon: Clock, label: "待生成", className: "status-pending" },
 65:     generating: { icon: Loader2, label: "生成中", className: "status-generating" },
 66:     success: { icon: Check, label: "完成", className: "status-success" },
 67:     error: { icon: X, label: "失败", className: "status-error" },
 68:   };
 69:   const { icon: Icon, label, className } = config[status];
 70:   
 71:   return (
 72:     <Badge variant="secondary" className={cn("gap-1 text-xs", className)}>
 73:       <Icon className={cn("w-3 h-3", status === "generating" && "animate-spin")} />
 74:       {label}
 75:     </Badge>
 76:   );
 77: }
 78: 
 79: export function MediaStudio() {
 80:   const {
 81:     mode,
 82:     generatedContent,
 83:     selectedTopic,
 84:     imageProvider,
 85:     animeModel,
 86:     ttsProvider,
 87:     selectedVoice,
 88:     imageResults,
 89:     setImageResults,
 90:     updateImageResult,
 91:     audioResults,
 92:     setAudioResults,
 93:     updateAudioResult,
 94:     videoPath,
 95:     videoUrl,
 96:     setVideoResult,
 97:     selectedBgm,
 98:     setSelectedBgm,
 99:     bgmVolume,
100:     setBgmVolume,
101:     availableBgm,
102:     setAvailableBgm,
103:     isGeneratingImages,
104:     setIsGeneratingImages,
105:     isGeneratingAudio,
106:     setIsGeneratingAudio,
107:     isCreatingVideo,
108:     setIsCreatingVideo,
109:   } = useWorkflowStore();
110: 
111:   // Load BGM list
112:   useEffect(() => {
113:     if (mode === "video" && availableBgm.length === 0) {
114:       getBgmList()
115:         .then((data) => setAvailableBgm(data.bgm_list))
116:         .catch(() => {});
117:     }
118:   }, [mode, availableBgm.length, setAvailableBgm]);
119: 
120:   const scenes = mode === "video"
121:     ? generatedContent?.visual_scenes || []
122:     : mode === "wechat"
123:     ? generatedContent?.diagrams || []
124:     : generatedContent?.image_designs || [];
125: 
126:   const getSceneStatus = (result: { path: string | null; error: string | null } | null, isGenerating: boolean) => {
127:     if (isGenerating) return "generating";
128:     if (result?.path) return "success";
129:     if (result?.error) return "error";
130:     return "pending";
131:   };
132: 
133:   // Generate all images
134:   const handleGenerateImages = async () => {
135:     if (!scenes.length) return;
136:     
137:     setIsGeneratingImages(true);
138:     try {
139:       const sceneInputs = scenes.map((s) => ({
140:         prompt: (s as { prompt: string }).prompt,
141:         sentiment: mode === "video" ? (s as { sentiment?: string }).sentiment : undefined,
142:       }));
143: 
144:       const response = await generateImages({
145:         scenes: sceneInputs,
146:         provider: imageProvider,
147:         anime_model: animeModel,
148:         topic: selectedTopic?.title,
149:         mode: mode,  // 图文模式主图用 Gemini
150:       });
151: 
152:       setImageResults(response.results);
153:       toast.success(`图片生成完成: ${response.success_count}/${response.total}`);
154:     } catch (error) {
155:       toast.error("图片生成失败: " + (error as Error).message);
156:     } finally {
157:       setIsGeneratingImages(false);
158:     }
159:   };
160: 
161:   // Generate all audio (video mode only)
162:   const handleGenerateAudio = async () => {
163:     if (!scenes.length || mode !== "video") return;
164: 
165:     setIsGeneratingAudio(true);
166:     try {
167:       const sceneInputs = scenes.map((s) => ({
168:         narration: (s as { narration: string }).narration || "",
169:       }));
170: 
171:       const response = await generateAudio({
172:         scenes: sceneInputs,
173:         provider: ttsProvider,
174:         voice: selectedVoice,
175:         topic: selectedTopic?.title,
176:       });
177: 
178:       setAudioResults(response.results);
179:       toast.success(`音频生成完成: ${response.success_count}/${response.total}`);
180:     } catch (error) {
181:       toast.error("音频生成失败: " + (error as Error).message);
182:     } finally {
183:       setIsGeneratingAudio(false);
184:     }
185:   };
186: 
187:   // Retry single image
188:   const handleRetryImage = async (index: number) => {
189:     const scene = scenes[index];
190:     if (!scene) return;
191: 
192:     updateImageResult(index, { index, path: null, url: null, error: null });
193:     
194:     try {
195:       const result = await generateSingleImage({
196:         scene: {
197:           prompt: (scene as { prompt: string }).prompt,
198:           sentiment: mode === "video" ? (scene as { sentiment?: string }).sentiment : undefined,
199:         },
200:         index,
201:         provider: imageProvider,
202:         anime_model: animeModel,
203:         topic: selectedTopic?.title,
204:       });
205: 
206:       updateImageResult(index, result);
207:       if (result.path) {
208:         toast.success(`图片 ${index + 1} 重新生成成功`);
209:       } else {
210:         toast.error(`图片 ${index + 1} 重试失败`);
211:       }
212:     } catch (error) {
213:       updateImageResult(index, { index, path: null, url: null, error: (error as Error).message });
214:     }
215:   };
216: 
217:   // Create video
218:   const handleCreateVideo = async () => {
219:     if (mode !== "video") return;
220: 
221:     const imagePaths = imageResults.map((r) => r?.path).filter(Boolean) as string[];
222:     const audioPaths = audioResults.map((r) => r?.path).filter(Boolean) as string[];
223: 
224:     if (imagePaths.length !== scenes.length || audioPaths.length !== scenes.length) {
225:       toast.error("请先完成所有图片和音频的生成");
226:       return;
227:     }
228: 
229:     setIsCreatingVideo(true);
230:     try {
231:       const response = await createVideo({
232:         image_paths: imagePaths,
233:         audio_paths: audioPaths,
234:         scenes: scenes.map((s) => ({ narration: (s as { narration: string }).narration || "" })),
235:         bgm_path: selectedBgm || undefined,
236:         bgm_volume: bgmVolume,
237:         topic: selectedTopic?.title,
238:       });
239: 
240:       if (response.video_path) {
241:         setVideoResult(response.video_path, response.video_url, response.srt_path);
242:         toast.success("视频合成完成!");
243:       } else {
244:         toast.error(response.error || "视频合成失败");
245:       }
246:     } catch (error) {
247:       toast.error("视频合成失败: " + (error as Error).message);
248:     } finally {
249:       setIsCreatingVideo(false);
250:     }
251:   };
252: 
253:   const imageSuccessCount = imageResults.filter((r) => r?.path).length;
254:   const audioSuccessCount = audioResults.filter((r) => r?.path).length;
255:   const allImagesReady = imageSuccessCount === scenes.length;
256:   const allAudioReady = mode !== "video" || audioSuccessCount === scenes.length;
257: 
258:   // Disabled state
259:   if (!generatedContent) {
260:     return (
261:       <section className="space-y-6 opacity-50">
262:         <div className="flex items-center gap-3">
263:           <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-muted text-muted-foreground">
264:             <FileText className="w-4 h-4" />
265:           </div>
266:           <div>
267:             <h2 className="text-lg font-semibold">
268:               生图提示词预览
269:             </h2>
270:             <p className="text-sm text-muted-foreground">
271:               查看和复制各场景的中英文生图提示词
272:             </p>
273:           </div>
274:         </div>
275:         <div className="flex items-center gap-2 p-4 rounded-lg bg-secondary/50 text-muted-foreground">
276:           <ChevronRight className="w-4 h-4" />
277:           <span className="text-sm">请先完成前面的步骤</span>
278:         </div>
279:       </section>
280:     );
281:   }
282: 
283:   return (
284:     <section className="space-y-6">
285:       {/* Section Header */}
286:       <div className="flex items-center gap-3">
287:         <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-primary/10 text-primary">
288:           <FileText className="w-4 h-4" />
289:         </div>
290:         <div>
291:           <h2 className="text-lg font-semibold">
292:             生图提示词预览
293:           </h2>
294:           <p className="text-sm text-muted-foreground">
295:             查看和复制各场景的中英文生图提示词
296:           </p>
297:         </div>
298:       </div>
299: 
300:       {/* Prompt Preview Grid - 生图功能已隐藏 */}
301:       <div className="space-y-4">
302:         <div className="flex items-center justify-between">
303:           <h3 className="text-sm font-medium text-foreground">生图提示词列表</h3>
304:           <Badge variant="secondary" className="text-xs">
305:             {scenes.length} 个场景
306:           </Badge>
307:         </div>
308:         <ScrollArea className="h-[600px]">
309:           <div className="space-y-3 pr-4">
310:             {scenes.map((scene, i) => (
311:               <motion.div
312:                 key={i}
313:                 initial={{ opacity: 0, y: 10 }}
314:                 animate={{ opacity: 1, y: 0 }}
315:                 transition={{ delay: i * 0.03 }}
316:                 className="rounded-lg border border-border bg-card p-4 space-y-3"
317:               >
318:                 {/* Scene Header */}
319:                 <div className="flex items-center justify-between">
320:                   <Badge variant="outline">场景 {i + 1}</Badge>
321:                   <Button
322:                     variant="ghost"
323:                     size="sm"
324:                     className="h-7 gap-1 text-xs"
325:                     onClick={() => {
326:                       const fullText = `场景${i+1}\n\n【画面描述】\n${
327:                         mode === "video"
328:                           ? (scene as { description: string }).description
329:                           : mode === "wechat"
330:                           ? (scene as any).title || (scene as { description: string }).description
331:                           : (scene as { description: string }).description
332:                       }\n\n【生图提示词】\n${(scene as { prompt: string }).prompt}`;
333:                       navigator.clipboard.writeText(fullText);
334:                       toast.success("场景完整信息已复制");
335:                     }}
336:                   >
337:                     <Copy className="w-3 h-3" />
338:                     复制全部
339:                   </Button>
340:                 </div>
341: 
342:                 {/* 视频模式：口播词 */}
343:                 {mode === "video" && (
344:                   <div className="space-y-1">
345:                     <label className="text-xs font-medium text-muted-foreground">
346:                       口播词
347:                     </label>
348:                     <p className="text-sm text-foreground leading-relaxed">
349:                       {(scene as { narration: string }).narration}
350:                     </p>
351:                   </div>
352:                 )}
353: 
354:                 {/* 中文描述 */}
355:                 <div className="space-y-1">
356:                   <label className="text-xs font-medium text-muted-foreground">
357:                     {mode === "wechat" ? "技术描述" : "画面描述"}
358:                   </label>
359:                   <p className="text-sm text-foreground leading-relaxed">
360:                     {mode === "video"
361:                       ? (scene as { description: string }).description
362:                       : mode === "wechat"
363:                       ? (scene as any).title || (scene as { description: string }).description
364:                       : (scene as { description: string }).description}
365:                   </p>
366:                 </div>
367: 
368:                 {/* 英文 Prompt */}
369:                 <div className="space-y-1">
370:                   <div className="flex items-center justify-between">
371:                     <label className="text-xs font-medium text-muted-foreground">
372:                       生图提示词（英文）
373:                     </label>
374:                     <Button
375:                       variant="ghost"
376:                       size="sm"
377:                       className="h-6 gap-1 text-xs"
378:                       onClick={() => {
379:                         navigator.clipboard.writeText((scene as { prompt: string }).prompt);
380:                         toast.success("Prompt 已复制");
381:                       }}
382:                     >
383:                       <Copy className="w-3 h-3" />
384:                       复制
385:                     </Button>
386:                   </div>
387:                   <pre className="text-xs bg-secondary/50 p-3 rounded whitespace-pre-wrap font-mono leading-relaxed">
388: {(scene as { prompt: string }).prompt}
389:                   </pre>
390:                 </div>
391:               </motion.div>
392:             ))}
393:           </div>
394:         </ScrollArea>
395:       </div>
396:     </section>
397:   );
398: }
</file>

<file path="frontend/src/lib/api.ts">
  1: /**
  2:  * Backend API Client
  3:  */
  4: 
  5: const API_BASE = process.env.NEXT_PUBLIC_API_URL || "http://localhost:8501";
  6: 
  7: // ========== Types ==========
  8: 
  9: export interface TopicItem {
 10:   title: string;
 11:   source: string;
 12:   summary: string;
 13:   outline: string[];
 14:   why_hot: string;
 15: }
 16: 
 17: export interface AnalyzeResponse {
 18:   topics: TopicItem[];
 19:   source: "websearch" | "fallback" | "error";
 20: }
 21: 
 22: export interface ImageDesign {
 23:   index: number;
 24:   description: string;
 25:   prompt: string;
 26:   sentiment?: string;
 27:   cover_text?: string;
 28: }
 29: 
 30: export interface VisualScene {
 31:   scene_index: number;
 32:   narration: string;
 33:   description: string;
 34:   sentiment: string;
 35:   prompt: string;
 36: }
 37: 
 38: export interface Diagram {
 39:   index: number;
 40:   title: string;
 41:   description: string;
 42:   diagram_type: "architecture" | "flow" | "comparison";
 43:   prompt: string;
 44: }
 45: 
 46: export interface GenerateResponse {
 47:   titles: string[];
 48:   content: string;
 49:   image_designs?: ImageDesign[];
 50:   visual_scenes?: VisualScene[];
 51:   diagrams?: Diagram[];
 52: }
 53: 
 54: export interface MediaResult {
 55:   index: number;
 56:   path: string | null;
 57:   url: string | null;
 58:   error: string | null;
 59: }
 60: 
 61: export interface BatchMediaResponse {
 62:   results: MediaResult[];
 63:   success_count: number;
 64:   total: number;
 65: }
 66: 
 67: export interface VoiceOption {
 68:   label: string;
 69:   value: string;
 70: }
 71: 
 72: export interface ModelOption {
 73:   label: string;
 74:   value: string;
 75: }
 76: 
 77: export interface PersonaItem {
 78:   name: string;
 79:   prompt: string;
 80: }
 81: 
 82: export interface PersonaCategory {
 83:   category: string;
 84:   personas: PersonaItem[];
 85: }
 86: 
 87: export interface HealthResponse {
 88:   status: string;
 89:   openrouter: boolean;
 90:   replicate: boolean;
 91:   ark: boolean;
 92:   volc_tts: boolean;
 93: }
 94: 
 95: // ========== API Functions ==========
 96: 
 97: async function fetchAPI<T>(endpoint: string, options?: RequestInit): Promise<T> {
 98:   const res = await fetch(`${API_BASE}${endpoint}`, {
 99:     ...options,
100:     headers: {
101:       "Content-Type": "application/json",
102:       ...options?.headers,
103:     },
104:   });
105: 
106:   if (!res.ok) {
107:     const error = await res.json().catch(() => ({ detail: res.statusText }));
108:     throw new Error(error.detail || "API request failed");
109:   }
110: 
111:   return res.json();
112: }
113: 
114: // Health Check
115: export async function checkHealth(): Promise<HealthResponse> {
116:   return fetchAPI<HealthResponse>("/health");
117: }
118: 
119: // Topics
120: export async function analyzeTopics(keyword: string, mode: "websearch" | "llm" = "websearch"): Promise<AnalyzeResponse> {
121:   return fetchAPI<AnalyzeResponse>("/api/topics/analyze", {
122:     method: "POST",
123:     body: JSON.stringify({ keyword, mode }),
124:   });
125: }
126: 
127: // Content Generation
128: export async function generateContent(params: {
129:   topic: string;
130:   persona?: string;
131:   reference_url?: string;
132:   mode: "image" | "video" | "wechat";
133:   model_name?: string;
134:   outline?: string[];
135:   temperature?: number;
136: }): Promise<GenerateResponse> {
137:   // Rename model_name to llm_model for API compatibility
138:   const { model_name, ...rest } = params;
139:   return fetchAPI<GenerateResponse>("/api/content/generate", {
140:     method: "POST",
141:     body: JSON.stringify({ ...rest, llm_model: model_name }),
142:   });
143: }
144: 
145: // Image Generation
146: export async function generateImages(params: {
147:   scenes: Array<{ prompt: string; sentiment?: string }>;
148:   provider?: string;
149:   anime_model?: string;
150:   topic?: string;
151:   mode?: "image" | "video";  // 图文模式主图用 Gemini
152: }): Promise<BatchMediaResponse> {
153:   return fetchAPI<BatchMediaResponse>("/api/media/images", {
154:     method: "POST",
155:     body: JSON.stringify(params),
156:   });
157: }
158: 
159: export async function generateSingleImage(params: {
160:   scene: { prompt: string; sentiment?: string };
161:   index: number;
162:   provider?: string;
163:   anime_model?: string;
164:   topic?: string;
165: }): Promise<MediaResult> {
166:   return fetchAPI<MediaResult>("/api/media/images/single", {
167:     method: "POST",
168:     body: JSON.stringify(params),
169:   });
170: }
171: 
172: // Audio Generation
173: export async function generateAudio(params: {
174:   scenes: Array<{ narration: string }>;
175:   provider?: string;
176:   voice?: string;
177:   topic?: string;
178: }): Promise<BatchMediaResponse> {
179:   return fetchAPI<BatchMediaResponse>("/api/media/audio", {
180:     method: "POST",
181:     body: JSON.stringify(params),
182:   });
183: }
184: 
185: export async function generateSingleAudio(params: {
186:   scene: { narration: string };
187:   index: number;
188:   provider?: string;
189:   voice?: string;
190:   topic?: string;
191: }): Promise<MediaResult> {
192:   return fetchAPI<MediaResult>("/api/media/audio/single", {
193:     method: "POST",
194:     body: JSON.stringify(params),
195:   });
196: }
197: 
198: // Video
199: export async function createVideo(params: {
200:   image_paths: string[];
201:   audio_paths: string[];
202:   scenes?: Array<{ narration: string }>;
203:   bgm_path?: string;
204:   bgm_volume?: number;
205:   topic?: string;
206: }): Promise<{
207:   video_path: string | null;
208:   video_url: string | null;
209:   srt_path: string | null;
210:   srt_url: string | null;
211:   duration: number;
212:   error: string | null;
213: }> {
214:   return fetchAPI("/api/video/create", {
215:     method: "POST",
216:     body: JSON.stringify(params),
217:   });
218: }
219: 
220: export async function getBgmList(): Promise<{
221:   bgm_list: Array<{ name: string; filename: string; path: string }>;
222: }> {
223:   return fetchAPI("/api/video/bgm");
224: }
225: 
226: // Config
227: export async function getModels(): Promise<{ models: ModelOption[] }> {
228:   return fetchAPI("/api/config/models");
229: }
230: 
231: export async function getVoices(): Promise<{
232:   edge: VoiceOption[];
233:   volcengine: VoiceOption[];
234: }> {
235:   return fetchAPI("/api/config/voices");
236: }
237: 
238: export async function getPersonas(): Promise<{ categories: PersonaCategory[] }> {
239:   return fetchAPI("/api/config/personas");
240: }
241: 
242: // SSE Stream for images
243: export function streamImages(
244:   params: {
245:     scenes: Array<{ prompt: string; sentiment?: string }>;
246:     provider?: string;
247:     anime_model?: string;
248:     topic?: string;
249:   },
250:   onProgress: (data: {
251:     type: "progress" | "result" | "done";
252:     index?: number;
253:     total?: number;
254:     status?: string;
255:     path?: string;
256:     url?: string;
257:     error?: string;
258:   }) => void
259: ): () => void {
260:   const controller = new AbortController();
261: 
262:   fetch(`${API_BASE}/api/media/images/stream`, {
263:     method: "POST",
264:     headers: { "Content-Type": "application/json" },
265:     body: JSON.stringify(params),
266:     signal: controller.signal,
267:   })
268:     .then(async (response) => {
269:       const reader = response.body?.getReader();
270:       if (!reader) return;
271: 
272:       const decoder = new TextDecoder();
273:       let buffer = "";
274: 
275:       while (true) {
276:         const { done, value } = await reader.read();
277:         if (done) break;
278: 
279:         buffer += decoder.decode(value, { stream: true });
280:         const lines = buffer.split("\n");
281:         buffer = lines.pop() || "";
282: 
283:         for (const line of lines) {
284:           if (line.startsWith("data: ")) {
285:             try {
286:               const data = JSON.parse(line.slice(6));
287:               onProgress(data);
288:             } catch {
289:               // Ignore parse errors
290:             }
291:           }
292:         }
293:       }
294:     })
295:     .catch((err) => {
296:       if (err.name !== "AbortError") {
297:         console.error("Stream error:", err);
298:       }
299:     });
300: 
301:   return () => controller.abort();
302: }
303: 
304: // Export Note to Obsidian
305: export interface ExportResponse {
306:   success: boolean;
307:   file_path: string | null;
308:   error: string | null;
309: }
310: 
311: export async function exportNote(params: {
312:   topic: string;
313:   title: string;
314:   content: string;
315:   image_urls?: string[];
316:   tags?: string[];
317: }): Promise<ExportResponse> {
318:   return fetchAPI<ExportResponse>("/api/content/export", {
319:     method: "POST",
320:     body: JSON.stringify(params),
321:   });
322: }
</file>

<file path="data/personas.json">
 1: {
 2:   "职场": [
 3:     {
 4:       "name": "职场反共识观察者",
 5:       "desc": "",
 6:       "prompt": "你是一位28岁的前大厂技术高P/自由职业者,懂代码、懂商业、懂人性。你不是导师,而是「比别人早踩坑的同龄人」。你的价值在于:用冷幽默拆解职场迷思,用商业逻辑解构人性游戏。\n\n【核心人设】\n1. **身份定位**:反共识观察者。你不迎合主流鸡汤,专门戳破「努力就有回报」「老板都是为你好」这类谎言。你的态度是:不端不装,但有料。\n2. **思考方式**:擅长「提前踩坑」式的经验输出。当别人还在相信表面规则时,你已经看透了底层的利益交换逻辑。你用经济学、博弈论、人类学视角重新解读职场。\n3. **沟通姿态**:平等对话,而非居高临下。多用「你可能没意识到」「我之前也这么以为」来拉近距离,而非「你应该」「你必须」。适度自嘲来消解说教感。\n\n【小红书内容公式】\n1. **开头钩子(前3秒)**:必须包含 [反常识+具体数字/身份] 来制造认知冲突。\n   - ✅ 示例:「年薪百万的人,90%都不加班。为什么?」\n   - ❌ 避免:「今天想和大家聊聊职场成长...」\n\n2. **中段结构**:拆解逻辑 + 真实案例 + 反直觉洞察(1-2个金句自然植入,而非刻意堆砌)\n   - 用「比如」「举个例子」来具象化抽象概念\n   - 用生活化比喻降低理解门槛,如:「跳槽就像谈恋爱,timing比能力更重要」\n\n3. **结尾动作**:可执行建议 + 争议性提问(引导评论区互动)\n   - ✅ 示例:「你在职场遇到过哪些「潜规则」?评论区见💡」\n   - ❌ 避免:「希望对你有帮助」「关注我了解更多」\n\n【语言风格细则】\n- 多用短句,节奏感强。避免长难句和学术腔。\n- 保留1个个人符号emoji:💡(代表洞察),用于结尾或关键观点处\n- 适度使用「」引用符号来强调关键词,但不过度\n- 每篇内容插入2-3个加粗小标题,方便快速浏览\n- 语气:冷幽默为主,偶尔带点「看透但不说透」的松弛感\n\n【小红书平台适配】\n1. **标题公式**:必须包含 [数字+反差+痛点/身份认同] 中的2个元素\n   - 示例:「28岁裸辞后,我发现的3个职场真相」「大厂5年,我劝你别信这4句话」\n2. **关键词布局**:在开头和结尾自然植入1-2个搜索热词(如:职场困境/副业/大厂经验)\n3. **话题标签**:选择2-3个精准话题,如 #职场真相 #大厂打工人 #副业思维\n4. **互动设计**:预埋1个「槽点」或「争议观点」,引导用户在评论区表达不同立场\n\n【配图方向(给设计师)】\n- **方案A**:真人出镜场景 — 咖啡店工作照/家中书桌侧影/城市街景行走,展示「松弛感精英」气质,服装以基础款为主(白T/衬衫/毛衣)\n- **方案A**:文字卡片设计 — 大字观点+纯色/渐变背景,Canva/创客贴风格,字体选择苹方/思源黑体,保持简洁\n- **避免**:过度抽象的艺术照、黑白滤镜、刻意摆拍的「高级感」(会降低小红书用户信任度)\n- **色调**:优先选择暖色调(米白/浅灰/暖黄)或高饱和度(提升点击率),而非冷色调\""    },
 7:     {
 8:       "name": "职场清醒女王",
 9:       "desc": "犀利冷艳，只谈利益不谈情怀",
10:       "prompt": "你是一个在互联网大厂混迹10年的高管姐姐，也是小红书上的「职场清醒」博主。\n你的受众是20-30岁的职场女性，她们正遭受内耗、迷茫或职场PUA。\n\n【核心人设】\n1. 语气风格：犀利、冷艳、一针见血、拒绝爹味说教。\n2. 价值观：只谈利益不谈情怀，上班是为了搞钱，不是来交朋友的。\n3. 常用词：去魅、内耗、搞钱、向上管理、预期管理、草台班子。\n\n【写作绝对禁忌】\n❌ 禁止使用「首先、其次、最后」这种教科书式的连接词。\n❌ 禁止说「我们要努力工作」这种正确的废话。\n❌ 禁止长篇大论，每一段不超过3行。\n\n【文章结构要求】\n1. **标题**：必须包含【痛点】或【反直觉】的观点。例如：「停止你的学生思维！」、「大厂没你想的那么光鲜」。\n2. **开头**：直接用一句狠话扎心，或者描述一个具体的崩溃场景。\n3. **中间**：给出3个颠覆认知的观点，或者3个具体的「话术」（直接给怎么说，不要只给理论）。\n4. **结尾**：一句金句总结，带点傲娇的鼓励。\n5. **排版**：多用 emoji (✨, 💡, 💰, 💅, 🚫)，使用换行增加留白。\""    },
11:     {
12:       "name": "腹黑HR姐姐",
13:       "desc": "揭秘潜规则，直接给话术SOP",
14:       "prompt": "你是一位拥有15年经验的资深HRD（人力资源总监），你深知职场背后的「潜规则」和「人性暗面」。\n你现在要在小红书上通过「揭秘」的方式，教职场小白如何保护自己、如何谈薪、如何应对甩锅。\n\n【核心人设】\n1. 语气风格：冷静、客观、甚至带点「腹黑」，像是在偷偷告诉用户公司不想让他们知道的秘密。\n2. 内容重心：侧重于「具体话术」和「博弈心理」。\n3. 表现形式：不要讲大道理，直接给 SOP（标准作业程序）。\n\n【写作强制要求】\n1. **标题**：要用【括号】强调关键词，例如：「HR不会告诉你的（谈薪底线）」。\n2. **正文必须包含话术**：遇到问题不要只分析，要直接写出：「如果领导说X，你就回Y」。\n3. **案例感**：通过「我见过太多候选人...」或「上周开掉的一个员工...」来引入话题。\n4. **排版**：使用 ✅ 和 ❌ 做对比。\n\n【示例风格】\n❌ 错误做法：领导给任务就接，最后累死自己。\n✅ 正确话术：「老板，手里现在的A和B项目都很急，您看这个新任务优先会排在哪里？我好调整时间表。」\""    },
15:     {
16:       "name": "精英操盘手",
17:       "desc": "逻辑怪效率控，输出思维模型",
18:       "prompt": "你是一位29岁就晋升为互联网大厂核心业务负责人的「精英操盘手」。\n你的粉丝是一群渴望快速晋升、突破薪资瓶颈的职场野心家。\n\n【核心人设】\n1. **身份标签**：年轻有为、高学历、逻辑怪、效率控、极度自律。\n2. **语气风格**：冷静、理性、逻辑严密、不说废话。喜欢用「降维打击」的视角看问题。\n3. **口头禅/关键词**：底层逻辑、复盘、颗粒度、闭环、SOP、交付感、向上对齐、非共识。\n\n【写作绝对规则】\n1. **拒绝情绪化**：不要吐槽老板傻X，要分析「如何管理老板的预期」。不要抱怨加班，要谈「如何提升ROI」。\n2. **必须输出模型**：每一篇笔记必须包含一个【思维模型】或【方法论】（如：金字塔原理、PDCA、SWOT、MECE法则）。\n3. **结构化表达**：全文必须使用 1. 2. 3. 的清单体，或者 What-Why-How 结构。\n4. **隐形凡尔赛**：文章中要不经意透露出你的高位阶。例如：「昨天和CEO过方案时...」、「面试了一个阿里P7...」。\n\n【排版要求】\n- 标题要展现「稀缺性」和「结果导向」。\n- 多用商务风Emoji：💼, 📈, 🧠, ⚡️, 🎯。\n- 关键结论加粗。\n\n【示例对比】\n❌ 普通写法：大家开会要认真听讲，记好笔记。\n✅ 精英写法：**拒绝低效会议。** 我要求团队在会前必须发一页Memo，会上只解决Blocked Issue，不汇报流水账。我的会议原则只有三条：...\""    },
19:     {
20:       "name": "90后精神离职艺术家",
21:       "desc": "整顿职场 / 糊弄学大师",
22:       "prompt": "你是一位30岁左右的“90后职场老油条”，也是互联网大厂的“精神离职”艺术家。\n\n【核心人设】\n1. **生存哲学**：工作不是为了实现价值，而是为了换取“窝囊费”。你主打“高性价比打工”：凡事不拒绝、不负责、不主动。工资是你的“片酬”，上班就是来“演戏”的。\n2. **性格底色**：表面情绪稳定（甚至面带微笑），内心发疯尖叫。主打一种“淡淡的疯感”。\n3. **身体状况**：身上有班味，体检有结节，靠冰美式续命，桌上摆满保健品。\n\n【写作风格与语气】\n1. **语气**：幽默、自嘲、阴阳怪气但显得很有礼貌。喜欢用“成年人的崩溃”做梗。\n2. **关键词**：精神离职、糊弄学、防御性工作、已读乱回、演技精湛、颗粒度（用来反讽）、去班味。\n3. **禁止项**：禁止像00后那样直接骂老板（90后不敢），要用“高情商话术”来软抵抗。\n\n【内容创作规范】\n1. **标题风格**：必须戳中30岁打工人的痛点。例如：“月薪两万，毫无意义”、“如何在会上表演自己在认真听讲”。\n2. **正文结构**：\n   - **场景重现**：描述一个具体的想死的瞬间（如：周五下午5点开会）。\n   - **糊弄SOP**：传授具体的“摸鱼技巧”或“推锅话术”。\n   - **情绪升华**：最后回归到“爱自己”，下班后我是我，上班时我是牛马。\n3. **排版要求**：多用职场社畜专属Emoji (☕️, 🧘‍♀️, 🙃, 🤡, 💊)。\n\n【示例话术】\n❌ 00后写法：老板你脑子有病吧，我不干了。\n✅ 90后写法：老板这个想法太有创意了，但我目前的带宽可能无法高质量交付，为了不影响项目进度，建议您安排给更合适的人（内心OS：滚啊）。\""    }
23:   ],
24:   "美妆": [
25:     {
26:       "name": "专业成分党",
27:       "desc": "理性分析，数据说话",
28:       "prompt": "你是一位护肤成分研究博主，拥有化学/皮肤科背景。\n你的受众是关注护肤品成分、追求科学护肤的年轻女性。\n\n【核心人设】\n1. 语气风格：专业但不枯燥，用通俗语言解释复杂成分。\n2. 内容重心：成分分析、功效对比、性价比测评。\n3. 常用词：成分表、浓度、配方、刺激性、耐受。\n\n【写作要求】\n1. 标题要有具体成分名或对比感。\n2. 正文要有数据支撑，但不能太学术。\n3. 排版：使用表格对比，emoji用💊🧪✨。\""    },
29:     {
30:       "name": "贵妇种草机",
31:       "desc": "高端大气，品质生活",
32:       "prompt": "你是一位追求品质生活的美妆博主，偏爱高端护肤和彩妆。\n你的受众是有一定消费能力、追求精致生活的女性。\n\n【核心人设】\n1. 语气风格：优雅、有品味、不炫富但透露精致。\n2. 内容重心：大牌测评、贵妇单品、奢华体验。\n3. 常用词：质感、仪式感、精致、值得投资。\n\n【写作要求】\n1. 标题要有高级感，不要用「平价替代」这种词。\n2. 正文要描述使用体验和氛围感。\n3. 排版：使用✨💎🌸等优雅emoji。\""    }
33:   ],
34:   "生活": [
35:     {
36:       "name": "治愈系姐姐",
37:       "desc": "温暖陪伴，情绪价值拉满",
38:       "prompt": "你是一位温柔治愈的生活博主，像邻家姐姐一样陪伴粉丝。\n你的受众是需要情绪价值、生活有些迷茫的年轻人。\n\n【核心人设】\n1. 语气风格：温柔、治愈、有同理心、不说教。\n2. 内容重心：生活感悟、情绪疏导、小确幸分享。\n3. 常用词：没关系、慢慢来、你已经很棒了。\n\n【写作要求】\n1. 标题要有治愈感，能让人想点进来。\n2. 正文要有共情，像在和朋友聊天。\n3. 排版：使用🌷☁️🧸等温柔emoji。\""    },
39:     {
40:       "name": "搞钱女孩",
41:       "desc": "副业干货，搞钱不躺平",
42:       "prompt": "你是一位靠副业实现经济独立的博主，分享搞钱干货。\n你的受众是想发展副业、增加收入的年轻人。\n\n【核心人设】\n1. 语气风格：接地气、实在、不画饼。\n2. 内容重心：副业选择、变现路径、时间管理。\n3. 常用词：搞钱、变现、被动收入、副业。\n\n【写作要求】\n1. 标题要有具体数字或结果导向。\n2. 正文要给可执行的步骤，不要只讲道理。\n3. 排版：使用💰📈💪等激励emoji。\""    }
43:   ],
44:   "宠物萌宠": [
45:     {
46:       "name": "硬核成分党兽医",
47:       "prompt": "你是一位拥有10年临床经验的宠物医生，也是全网最敢讲真话的\"成分党\"。\n\n【核心人设】\n1. 语气：客观、严谨、稍微有点\"毒舌\"，看不惯智商税产品。\n2. 价值观：科学养宠，拒绝盲目跟风，只看成分表，不看品牌光环。\n3. 关键词：配料表实测、智商税、软便、诱食剂、科学喂养。\n\n【写作要求】\n1. **拒绝废话**：开篇直接抛出结论（例如：\"这款粮千万别买！\"）。\n2. **数据支撑**：文中必须引用成分数据（如：粗蛋白≥40%，不含肉粉）。\n3. **排版风格**：使用 ✅ 和 ❌ 进行鲜明对比。多用 ⚠️, 🧪, 📉 Emoji。\n4. **视觉指令**：配图提示词要偏向\"测评风\"，如：特写镜头拍摄猫粮颗粒、显微镜视角、带有红叉❌的产品图。\""    },
48:     {
49:       "name": "精致富养铲屎官",
50:       "prompt": "你是一位把宠物当亲生孩子养的\"95后独居富婆/精致女生\"。你家有一只特别可爱的猫/狗（金毛或布偶）。\n\n【核心人设】\n1. 语气：温柔、治愈、元气满满、把宠物称为\"哈基米\"或\"毛孩子\"。\n2. 价值观：颜值即正义，要在能力范围内给它最好的。主打陪伴感和生活美学。\n3. 关键词：绝美、治愈瞬间、好物分享、提升幸福感、家居好物。\n\n【写作要求】\n1. **情绪共鸣**：多描写和宠物的互动细节（蹭头、踩奶、迎接下班）。\n2. **种草属性**：推荐的东西必须\"好看\"，强调放在家里的装饰性。\n3. **排版风格**：软萌风格，多用 ✨, 🐾, 🎀, 🧸 Emoji。\n4. **视觉指令**：配图提示词要偏向\"Ins风/家居风\"，暖色调，阳光洒在地板上，人宠互动的温馨画面。\""    },
51:     {
52:       "name": "金牌训宠师",
53:       "prompt": "你是一位专门解决\"恶犬/坏猫\"行为问题的资深动物行为矫正师。你见过各种拆家、护食、乱尿的宠物。\n\n【核心人设】\n1. 语气：干练、自信、指令感强、像一位严格但靠谱的教官。\n2. 价值观：没有教不好的狗，只有不会教的人。建立规则比溺爱更重要。\n3. 关键词：脱敏训练、社会化、定点大小便、分离焦虑、指令服从。\n\n【写作要求】\n1. **痛点直击**：标题必须戳中主人的崩溃瞬间（如：\"一回家满地尿？\"\"半夜跑酷怎么治？\"）。\n2. **SOP化教学**：正文必须给出 Step 1, Step 2, Step 3 的具体操作步骤。\n3. **排版风格**：清晰的清单体，重点文字加粗。多用 🐕, 🚫, 🎓, ✅ Emoji。\n4. **视觉指令**：配图提示词要偏向\"教程风\"，清晰的动作分解图，或者宠物乖乖坐下的正面照。\""    }
54:   ],
55:   "硬核技术/AI": [
56:     {
57:       "name": "全栈AI架构师",
58:       "prompt": "你是一位拥有15年一线经验的资深技术专家，横跨分布式架构、核心算法与AI大模型领域。你曾在多家大厂担任首席架构师，现在致力于技术布道。\n\n【核心人设】\n1. **技术视野**：拥有上帝视角（God View）。你看待AI不仅仅是模型，而是'算力+数据+算法+工程'的系统工程。你善于一眼看穿新技术的本质和炒作泡沫。\n2. **语气风格**：极度理性、硬核、逻辑严密（Engineering Mindset）。不讲正确的废话，只输出经过验证的经验和深度思考。\n3. **受众画像**：面向中高级工程师、架构师、CTO以及对技术有深度追求的从业者。\n\n【写作绝对规则】\n1. **结构化输出**：文章必须符合'金字塔原理'。结构通常为：'背景/痛点 -> 现有方案局限 -> 深度原理拆解 -> 架构设计/代码思路 -> 商业/未来价值'。\n2. **深度要求**：严禁浅尝辄止。必须包含：\n   - **技术原理**：用通俗的语言解释复杂的数学或架构（如：用'传话游戏'解释Transformer）。\n   - **工程落地**：不仅仅讲算法，还要讲部署、成本、延迟优化等工程细节。\n   - **对比分析**：必须有 Pros & Cons（优缺点）对比。\n3. **公众号风格排版**：\n   - 标题要硬核且吸引人（如：《RAG已死？深度解析Long Context的工程边界》）。\n   - 关键概念加粗。\n   - 适当使用代码块（```python ... ```）展示核心逻辑。\n   - 必须包含 1-2 个'架构图描述'（用文字描述，提示Painter画出来）。\n\n【视觉指令 (给Painter)】\n画面要体现'极客美学'。例如：复杂的系统架构蓝图、发光的神经网络节点、代码流过服务器机架、赛博朋克风格的机房、深色背景下的数据可视化图表。\""    }
59:   ]
60: }
</file>

<file path="frontend/src/components/blocks/ContentPreview.tsx">
  1: "use client";
  2: 
  3: import { useState } from "react";
  4: import { motion, AnimatePresence } from "framer-motion";
  5: import {
  6:   FileText,
  7:   ChevronRight,
  8:   Copy,
  9:   Check,
 10:   Eye,
 11:   Image as ImageIcon,
 12:   Mic,
 13: } from "lucide-react";
 14: import { cn } from "@/lib/utils";
 15: import { Button } from "@/components/ui/button";
 16: import { Badge } from "@/components/ui/badge";
 17: import { Textarea } from "@/components/ui/textarea";
 18: import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
 19: import { ScrollArea } from "@/components/ui/scroll-area";
 20: import {
 21:   Collapsible,
 22:   CollapsibleContent,
 23:   CollapsibleTrigger,
 24: } from "@/components/ui/collapsible";
 25: import { useWorkflowStore } from "@/store/workflow";
 26: import { GenerateResponse } from "@/lib/api";
 27: import { toast } from "sonner";
 28: 
 29: // Dual Model Comparison Card Component
 30: function DualModelCard({
 31:   model,
 32:   content,
 33:   version,
 34:   isSelected,
 35:   onSelect,
 36: }: {
 37:   model: string;
 38:   content: GenerateResponse;
 39:   version: 'model1' | 'model2';
 40:   isSelected: boolean;
 41:   onSelect: () => void;
 42: }) {
 43:   const modelName = model.split('/').pop() || model;
 44:   const [copiedType, setCopiedType] = useState<'title' | 'content' | null>(null);
 45: 
 46:   const copyToClipboard = async (text: string, type: 'title' | 'content') => {
 47:     try {
 48:       await navigator.clipboard.writeText(text);
 49:       setCopiedType(type);
 50:       toast.success("已复制到剪贴板");
 51:       setTimeout(() => setCopiedType(null), 2000);
 52:     } catch {
 53:       toast.error("复制失败");
 54:     }
 55:   };
 56:   
 57:   return (
 58:     <motion.div
 59:       initial={{ opacity: 0, y: 20 }}
 60:       animate={{ opacity: 1, y: 0 }}
 61:       className={cn(
 62:         "relative p-6 rounded-xl border-2 transition-all",
 63:         isSelected
 64:           ? "border-primary bg-primary/5 shadow-lg"
 65:           : "border-border bg-card hover:border-primary/50"
 66:       )}
 67:     >
 68:       {/* Model Badge */}
 69:       <div className="flex items-center justify-between mb-4">
 70:         <Badge variant={isSelected ? "default" : "outline"} className="text-xs">
 71:           {modelName}
 72:         </Badge>
 73:         <Button
 74:           size="sm"
 75:           variant={isSelected ? "default" : "outline"}
 76:           onClick={onSelect}
 77:           className="gap-2"
 78:         >
 79:           {isSelected ? (
 80:             <>
 81:               <Check className="w-3 h-3" />
 82:               已选择
 83:             </>
 84:           ) : (
 85:             "选择此版本"
 86:           )}
 87:         </Button>
 88:       </div>
 89: 
 90:       {/* Title Preview */}
 91:       <div className="space-y-2 mb-4">
 92:         <div className="flex items-center justify-between">
 93:           <h3 className="text-sm font-medium text-muted-foreground">标题预览</h3>
 94:           <Button
 95:             size="sm"
 96:             variant="ghost"
 97:             className="h-6 gap-1"
 98:             onClick={() => copyToClipboard(content.titles[0], 'title')}
 99:           >
100:             {copiedType === 'title' ? (
101:               <Check className="w-3 h-3 text-green-500" />
102:             ) : (
103:               <Copy className="w-3 h-3" />
104:             )}
105:             <span className="text-xs">复制</span>
106:           </Button>
107:         </div>
108:         <p className="text-base font-medium line-clamp-2">{content.titles[0]}</p>
109:       </div>
110: 
111:       {/* Content Preview */}
112:       <div className="space-y-2">
113:         <div className="flex items-center justify-between">
114:           <h3 className="text-sm font-medium text-muted-foreground">正文预览</h3>
115:           <Button
116:             size="sm"
117:             variant="ghost"
118:             className="h-6 gap-1"
119:             onClick={() => copyToClipboard(content.content, 'content')}
120:           >
121:             {copiedType === 'content' ? (
122:               <Check className="w-3 h-3 text-green-500" />
123:             ) : (
124:               <Copy className="w-3 h-3" />
125:             )}
126:             <span className="text-xs">复制</span>
127:           </Button>
128:         </div>
129:         <ScrollArea className="h-[300px] rounded-lg border p-3 bg-secondary/30">
130:           <p className="text-sm whitespace-pre-wrap leading-relaxed">
131:             {content.content}
132:           </p>
133:         </ScrollArea>
134:       </div>
135: 
136:       {/* Stats */}
137:       <div className="mt-4 pt-4 border-t flex gap-4 text-xs text-muted-foreground">
138:         <span>{content.titles.length} 个标题</span>
139:         <span>{content.content.length} 字</span>
140:         {content.image_designs && <span>{content.image_designs.length} 张配图</span>}
141:         {content.visual_scenes && <span>{content.visual_scenes.length} 个分镜</span>}
142:       </div>
143:     </motion.div>
144:   );
145: }
146: 
147: export function ContentPreview() {
148:   const {
149:     mode,
150:     generatedContent,
151:     selectedTitleIndex,
152:     setSelectedTitleIndex,
153:     setStep,
154:     dualResults,
155:     selectedVersion,
156:     setSelectedVersion,
157:     selectedModel,
158:     secondModel,
159:   } = useWorkflowStore();
160: 
161:   const [copiedIndex, setCopiedIndex] = useState<number | null>(null);
162:   const [expandedScene, setExpandedScene] = useState<number | null>(0);
163: 
164:   const copyToClipboard = async (text: string, index: number) => {
165:     try {
166:       await navigator.clipboard.writeText(text);
167:       setCopiedIndex(index);
168:       toast.success("已复制到剪贴板");
169:       setTimeout(() => setCopiedIndex(null), 2000);
170:     } catch {
171:       toast.error("复制失败");
172:     }
173:   };
174: 
175:   // Disabled state
176:   if (!generatedContent && !dualResults) {
177:     return (
178:       <section className="space-y-6 opacity-50">
179:         <div className="flex items-center gap-3">
180:           <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-muted text-muted-foreground">
181:             <Eye className="w-4 h-4" />
182:           </div>
183:           <div>
184:             <h2 className="text-lg font-semibold">内容预览</h2>
185:             <p className="text-sm text-muted-foreground">
186:               查看生成的内容和分镜脚本
187:             </p>
188:           </div>
189:         </div>
190:         <div className="flex items-center gap-2 p-4 rounded-lg bg-secondary/50 text-muted-foreground">
191:           <ChevronRight className="w-4 h-4" />
192:           <span className="text-sm">请先在上一步生成内容</span>
193:         </div>
194:       </section>
195:     );
196:   }
197:   
198:   // Dual model comparison view
199:   if (dualResults) {
200:     return (
201:       <section className="space-y-6">
202:         <div className="flex items-center gap-3">
203:           <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-primary/10">
204:             <Eye className="w-4 h-4 text-primary" />
205:           </div>
206:           <div>
207:             <h2 className="text-lg font-semibold">双模型对比</h2>
208:             <p className="text-sm text-muted-foreground">
209:               选择更优版本继续制作
210:             </p>
211:           </div>
212:         </div>
213: 
214:         <div className="grid grid-cols-2 gap-6">
215:           {/* Model 1 */}
216:           <DualModelCard
217:             model={selectedModel}
218:             content={dualResults.model1}
219:             version="model1"
220:             isSelected={selectedVersion === 'model1'}
221:             onSelect={() => setSelectedVersion('model1')}
222:           />
223: 
224:           {/* Model 2 */}
225:           <DualModelCard
226:             model={secondModel}
227:             content={dualResults.model2}
228:             version="model2"
229:             isSelected={selectedVersion === 'model2'}
230:             onSelect={() => setSelectedVersion('model2')}
231:           />
232:         </div>
233: 
234:         <div className="flex gap-3">
235:           <Button
236:             variant="outline"
237:             onClick={() => setStep("persona")}
238:             className="flex-1"
239:           >
240:             重新生成
241:           </Button>
242:           <Button
243:             onClick={() => setStep("studio")}
244:             className="flex-1 gap-2"
245:           >
246:             继续制作 ({selectedVersion === 'model1' ? selectedModel.split('/').pop() : secondModel.split('/').pop()})
247:             <ChevronRight className="w-4 h-4" />
248:           </Button>
249:         </div>
250:       </section>
251:     );
252:   }
253: 
254:   const { titles, content, image_designs, visual_scenes, diagrams } = generatedContent;
255:   const scenes = mode === "video" ? visual_scenes : mode === "wechat" ? diagrams : image_designs;
256:   const charCount = content.replace(/\s/g, "").length;
257: 
258:   return (
259:     <section className="space-y-6">
260:       {/* Section Header */}
261:       <div className="flex items-center justify-between">
262:         <div className="flex items-center gap-3">
263:           <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-primary/10 text-primary">
264:             <Eye className="w-4 h-4" />
265:           </div>
266:           <div>
267:             <h2 className="text-lg font-semibold">内容预览</h2>
268:             <p className="text-sm text-muted-foreground">
269:               {mode === "video"
270:                 ? "查看视频脚本和分镜设计"
271:                 : mode === "wechat"
272:                 ? "查看文章正文和架构图设计"
273:                 : "查看图文内容和配图方案"}
274:             </p>
275:           </div>
276:         </div>
277:         <Button onClick={() => setStep("studio")} className="gap-2">
278:           下一步
279:           <ChevronRight className="w-4 h-4" />
280:         </Button>
281:       </div>
282: 
283:       <Tabs defaultValue="content" className="w-full">
284:         <TabsList className="grid w-full grid-cols-2 h-10">
285:           <TabsTrigger value="content" className="gap-2">
286:             <FileText className="w-4 h-4" />
287:             {mode === "video" ? "脚本简介" : mode === "wechat" ? "文章正文" : "正文内容"}
288:           </TabsTrigger>
289:           <TabsTrigger value="scenes" className="gap-2">
290:             {mode === "video" ? (
291:               <Mic className="w-4 h-4" />
292:             ) : (
293:               <ImageIcon className="w-4 h-4" />
294:             )}
295:             {mode === "video" 
296:               ? `分镜 (${visual_scenes?.length || 0})` 
297:               : mode === "wechat"
298:               ? `架构图 (${diagrams?.length || 0})`
299:               : `配图 (${image_designs?.length || 0})`}
300:           </TabsTrigger>
301:         </TabsList>
302: 
303:         {/* Content Tab */}
304:         <TabsContent value="content" className="space-y-4 mt-4">
305:           {/* Titles */}
306:           <div className="space-y-3">
307:             <h3 className="text-sm font-medium text-foreground">备选标题</h3>
308:             <div className="space-y-2">
309:               {titles.map((title, i) => (
310:                 <motion.div
311:                   key={i}
312:                   initial={{ opacity: 0, x: -10 }}
313:                   animate={{ opacity: 1, x: 0 }}
314:                   transition={{ delay: i * 0.05 }}
315:                   onClick={() => setSelectedTitleIndex(i)}
316:                   className={cn(
317:                     "flex items-center gap-3 p-3 rounded-lg cursor-pointer transition-all",
318:                     "border hover:border-primary/30",
319:                     selectedTitleIndex === i
320:                       ? "border-primary bg-primary/5"
321:                       : "border-border bg-card"
322:                   )}
323:                 >
324:                   <Badge
325:                     variant={selectedTitleIndex === i ? "default" : "secondary"}
326:                     className="shrink-0"
327:                   >
328:                     {i + 1}
329:                   </Badge>
330:                   <span className="flex-1 text-sm text-foreground">{title}</span>
331:                   <Button
332:                     variant="ghost"
333:                     size="icon"
334:                     className="h-8 w-8 shrink-0"
335:                     onClick={(e) => {
336:                       e.stopPropagation();
337:                       copyToClipboard(title, i);
338:                     }}
339:                   >
340:                     {copiedIndex === i ? (
341:                       <Check className="w-4 h-4 text-emerald-500" />
342:                     ) : (
343:                       <Copy className="w-4 h-4" />
344:                     )}
345:                   </Button>
346:                 </motion.div>
347:               ))}
348:             </div>
349:           </div>
350: 
351:           {/* Main Content */}
352:           <div className="space-y-3">
353:             <div className="flex items-center justify-between">
354:               <h3 className="text-sm font-medium text-foreground">
355:                 {mode === "video" ? "视频简介" : "正文内容"}
356:               </h3>
357:               <span className="text-xs text-muted-foreground">{charCount} 字</span>
358:             </div>
359:             <div className="relative">
360:               <Textarea
361:                 value={content}
362:                 readOnly
363:                 className="min-h-[200px] resize-none bg-secondary/30 border-0"
364:               />
365:               <Button
366:                 variant="secondary"
367:                 size="sm"
368:                 className="absolute top-2 right-2 gap-1"
369:                 onClick={() => copyToClipboard(content, -1)}
370:               >
371:                 {copiedIndex === -1 ? (
372:                   <Check className="w-3 h-3 text-emerald-500" />
373:                 ) : (
374:                   <Copy className="w-3 h-3" />
375:                 )}
376:                 复制
377:               </Button>
378:             </div>
379:           </div>
380:         </TabsContent>
381: 
382:         {/* Scenes Tab */}
383:         <TabsContent value="scenes" className="mt-4">
384:           <ScrollArea className="h-[500px] pr-4">
385:             <div className="space-y-2">
386:               {scenes?.map((scene, i) => {
387:                 const isExpanded = expandedScene === i;
388:                 const isVideoScene = mode === "video" && "narration" in scene;
389:                 const isDiagram = mode === "wechat" && "title" in scene;
390: 
391:                 return (
392:                   <Collapsible
393:                     key={i}
394:                     open={isExpanded}
395:                     onOpenChange={() => setExpandedScene(isExpanded ? null : i)}
396:                   >
397:                     <div
398:                       className={cn(
399:                         "rounded-lg border transition-all",
400:                         isExpanded ? "border-primary/30" : "border-border"
401:                       )}
402:                     >
403:                       {/* Header */}
404:                       <CollapsibleTrigger className="w-full">
405:                         <div className="flex items-center gap-3 p-3 hover:bg-secondary/30 transition-colors">
406:                           <Badge variant="outline" className="shrink-0">
407:                             {isDiagram && (scene as any).diagram_type ? (
408:                               <span className="text-xs">
409:                                 {(scene as any).diagram_type === "architecture" ? "架构" : (scene as any).diagram_type === "flow" ? "流程" : "对比"}
410:                               </span>
411:                             ) : (
412:                               i + 1
413:                             )}
414:                           </Badge>
415:                           <div className="flex-1 text-left min-w-0">
416:                             {isDiagram ? (
417:                               <p className="text-sm font-medium text-foreground truncate">
418:                                 {(scene as any).title || (scene as { description: string }).description}
419:                               </p>
420:                             ) : isVideoScene ? (
421:                               <p className="text-sm text-foreground truncate">
422:                                 {(scene as { narration: string }).narration}
423:                               </p>
424:                             ) : (
425:                               <p className="text-sm text-foreground truncate">
426:                                 {(scene as { description: string }).description}
427:                               </p>
428:                             )}
429:                           </div>
430:                           <ChevronRight
431:                             className={cn(
432:                               "w-4 h-4 text-muted-foreground transition-transform",
433:                               isExpanded && "rotate-90"
434:                             )}
435:                           />
436:                         </div>
437:                       </CollapsibleTrigger>
438: 
439:                       {/* Expanded Content */}
440:                       <CollapsibleContent>
441:                         <div className="px-3 pb-3 pt-0 border-t border-border/50">
442:                           <div className="pt-3 space-y-3">
443:                             {/* Diagram Title (Wechat Mode) */}
444:                             {isDiagram && (scene as any).title && (
445:                               <div className="space-y-1">
446:                                 <label className="text-xs font-medium text-muted-foreground">
447:                                   架构图标题
448:                                 </label>
449:                                 <p className="text-sm font-medium text-foreground">
450:                                   {(scene as any).title}
451:                                 </p>
452:                               </div>
453:                             )}
454: 
455:                             {/* Narration (Video Mode) */}
456:                             {isVideoScene && (
457:                               <div className="space-y-1">
458:                                 <label className="text-xs font-medium text-muted-foreground">
459:                                   口播词
460:                                 </label>
461:                                 <div className="p-2 rounded bg-blue-50 dark:bg-blue-900/20 text-sm text-foreground">
462:                                   {(scene as { narration: string }).narration}
463:                                 </div>
464:                               </div>
465:                             )}
466: 
467:                             {/* Description */}
468:                             <div className="space-y-1">
469:                               <label className="text-xs font-medium text-muted-foreground">
470:                                 {isDiagram ? "技术描述" : "画面描述"}
471:                               </label>
472:                               <p className="text-sm text-foreground">
473:                                 {(scene as { description: string }).description}
474:                               </p>
475:                             </div>
476: 
477:                             {/* Sentiment (Video Mode) */}
478:                             {isVideoScene && (scene as { sentiment?: string }).sentiment && (
479:                               <div className="flex items-center gap-2">
480:                                 <span className="text-xs text-muted-foreground">情感基调:</span>
481:                                 <Badge variant="secondary" className="text-xs">
482:                                   {(scene as { sentiment: string }).sentiment}
483:                                 </Badge>
484:                               </div>
485:                             )}
486: 
487:                             {/* Prompt */}
488:                             <div className="space-y-1">
489:                               <div className="flex items-center justify-between">
490:                                 <label className="text-xs font-medium text-muted-foreground">
491:                                   生图提示词
492:                                 </label>
493:                                 <Button
494:                                   variant="ghost"
495:                                   size="sm"
496:                                   className="h-6 text-xs gap-1"
497:                                   onClick={() =>
498:                                     copyToClipboard(
499:                                       (scene as { prompt: string }).prompt,
500:                                       100 + i
501:                                     )
502:                                   }
503:                                 >
504:                                   {copiedIndex === 100 + i ? (
505:                                     <Check className="w-3 h-3 text-emerald-500" />
506:                                   ) : (
507:                                     <Copy className="w-3 h-3" />
508:                                   )}
509:                                   复制
510:                                 </Button>
511:                               </div>
512:                               <pre className="p-2 rounded bg-secondary/50 text-xs text-muted-foreground whitespace-pre-wrap font-mono">
513:                                 {(scene as { prompt: string }).prompt}
514:                               </pre>
515:                             </div>
516:                           </div>
517:                         </div>
518:                       </CollapsibleContent>
519:                     </div>
520:                   </Collapsible>
521:                 );
522:               })}
523:             </div>
524:           </ScrollArea>
525:         </TabsContent>
526:       </Tabs>
527:     </section>
528:   );
529: }
</file>

<file path="frontend/src/components/blocks/PersonaConfig.tsx">
  1: "use client";
  2: 
  3: import { useEffect, useState } from "react";
  4: import { motion } from "framer-motion";
  5: import {
  6:   User,
  7:   Link2,
  8:   Loader2,
  9:   Sparkles,
 10:   ChevronRight,
 11:   AlertTriangle,
 12:   Thermometer,
 13:   GitCompare,
 14: } from "lucide-react";
 15: import { cn } from "@/lib/utils";
 16: import { Button } from "@/components/ui/button";
 17: import { Input } from "@/components/ui/input";
 18: import { Textarea } from "@/components/ui/textarea";
 19: import { Badge } from "@/components/ui/badge";
 20: import {
 21:   Select,
 22:   SelectContent,
 23:   SelectItem,
 24:   SelectTrigger,
 25:   SelectValue,
 26: } from "@/components/ui/select";
 27: import {
 28:   Collapsible,
 29:   CollapsibleContent,
 30:   CollapsibleTrigger,
 31: } from "@/components/ui/collapsible";
 32: import { Slider } from "@/components/ui/slider";
 33: import { useWorkflowStore } from "@/store/workflow";
 34: import { generateContent, getPersonas } from "@/lib/api";
 35: import { toast } from "sonner";
 36: import { StepProgress, type Step } from "@/components/ui/step-progress";
 37: import { simulateStepProgress, createDefaultSteps } from "@/lib/progress-utils";
 38: 
 39: export function PersonaConfig() {
 40:   const {
 41:     mode,
 42:     selectedTopic,
 43:     selectedCategory,
 44:     setSelectedCategory,
 45:     selectedPersona,
 46:     setSelectedPersona,
 47:     customPersona,
 48:     setCustomPersona,
 49:     referenceUrl,
 50:     setReferenceUrl,
 51:     selectedModel,
 52:     generatedContent,
 53:     setGeneratedContent,
 54:     isGenerating,
 55:     setIsGenerating,
 56:     availablePersonas,
 57:     setAvailablePersonas,
 58:     setStep,
 59:     temperature,
 60:     setTemperature,
 61:     dualModelMode,
 62:     setDualModelMode,
 63:     secondModel,
 64:     setSecondModel,
 65:     setDualResults,
 66:     availableModels,
 67:   } = useWorkflowStore();
 68: 
 69:   const [showPrompt, setShowPrompt] = useState(false);
 70:   const [generationSteps, setGenerationSteps] = useState<Step[]>([]);
 71: 
 72:   // Fetch personas on mount
 73:   useEffect(() => {
 74:     if (availablePersonas.length === 0) {
 75:       getPersonas()
 76:         .then((data) => setAvailablePersonas(data.categories))
 77:         .catch(() => {});
 78:     }
 79:   }, [availablePersonas.length, setAvailablePersonas]);
 80: 
 81:   // 根据 mode 过滤人设分类
 82:   const categories = mode === "wechat"
 83:     ? availablePersonas.filter((c) => c.category === "硬核技术/AI" || c.category === "自定义").map((c) => c.category)
 84:     : availablePersonas.map((c) => c.category);
 85:   
 86:   const currentPersonas =
 87:     availablePersonas.find((c) => c.category === selectedCategory)?.personas || [];
 88:   const selectedPersonaData = currentPersonas.find((p) => p.name === selectedPersona);
 89: 
 90:   const getPersonaPrompt = () => {
 91:     if (selectedCategory === "自定义") {
 92:       return customPersona;
 93:     }
 94:     return selectedPersonaData?.prompt || "";
 95:   };
 96: 
 97:   const handleGenerate = async () => {
 98:     const personaPrompt = getPersonaPrompt();
 99:     if (!personaPrompt) {
100:       toast.error("请先选择或输入人设");
101:       return;
102:     }
103: 
104:     if (!selectedTopic) {
105:       toast.error("请先选择话题");
106:       return;
107:     }
108:     
109:     if (dualModelMode && !secondModel) {
110:       toast.error("请选择第二个模型");
111:       return;
112:     }
113: 
114:     // 开始生成前先清空旧内容，避免显示缓存数据
115:     setGeneratedContent(null);
116:     setDualResults(null);
117:     setIsGenerating(true);
118: 
119:     // 初始化进度步骤（调整为更接近实际耗时）
120:     const steps = dualModelMode
121:       ? createDefaultSteps([
122:           { label: "准备创作上下文...", time: 3 },
123:           { label: `${selectedModel.split('/').pop()} 创作中...`, time: 25 },
124:           { label: `${secondModel.split('/').pop()} 创作中...`, time: 2 }, // 并行，所以时间很短
125:           { label: "质量检测与对比...", time: 6 },
126:         ])
127:       : createDefaultSteps([
128:           { label: "准备创作上下文...", time: 3 },
129:           { label: "LLM 深度创作中...", time: 25 },
130:           { label: "质量检测与优化...", time: 5 },
131:           { label: "生成配图方案...", time: 4 },
132:         ]);
133:     
134:     setGenerationSteps(steps);
135:     
136:     const { promise } = simulateStepProgress({
137:       steps,
138:       onStepChange: setGenerationSteps,
139:       actualTask: async () => {
140:         const params = {
141:           topic: selectedTopic.title,
142:           persona: personaPrompt,
143:           reference_url: referenceUrl || undefined,
144:           mode,
145:           outline: selectedTopic.outline,
146:           temperature,
147:         };
148:         
149:         if (dualModelMode) {
150:           // 双模型并行生成
151:           const [result1, result2] = await Promise.all([
152:             generateContent({ ...params, model_name: selectedModel }),
153:             generateContent({ ...params, model_name: secondModel })
154:           ]);
155:           
156:           setDualResults({ model1: result1, model2: result2 });
157:           setStep("preview");
158:           toast.success("双模型生成完成，请选择更优版本");
159:         } else {
160:           // 单模型生成
161:           const response = await generateContent({
162:             ...params,
163:             model_name: selectedModel,
164:           });
165: 
166:           setGeneratedContent(response);
167:           setStep("preview");
168:           toast.success(mode === "video" ? "视频脚本生成完成" : "图文内容生成完成");
169:         }
170:       },
171:     });
172: 
173:     try {
174:       await promise;
175:     } catch (error) {
176:       // 生成失败时确保清空内容
177:       setGeneratedContent(null);
178:       setDualResults(null);
179:       toast.error("生成失败: " + (error as Error).message);
180:     } finally {
181:       setIsGenerating(false);
182:       setTimeout(() => setGenerationSteps([]), 1000);
183:     }
184:   };
185: 
186:   // Disabled state
187:   if (!selectedTopic) {
188:     return (
189:       <section className="space-y-6 opacity-50">
190:         <div className="flex items-center gap-3">
191:           <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-muted text-muted-foreground">
192:             <User className="w-4 h-4" />
193:           </div>
194:           <div>
195:             <h2 className="text-lg font-semibold">创作配置</h2>
196:             <p className="text-sm text-muted-foreground">
197:               选择人设风格，AI 将基于热点大纲生成内容
198:             </p>
199:           </div>
200:         </div>
201:         <div className="flex items-center gap-2 p-4 rounded-lg bg-secondary/50 text-muted-foreground">
202:           <ChevronRight className="w-4 h-4" />
203:           <span className="text-sm">请先在上一步选择话题</span>
204:         </div>
205:       </section>
206:     );
207:   }
208: 
209:   return (
210:     <section className="space-y-6">
211:       {/* Section Header */}
212:       <div className="flex items-center gap-3">
213:         <div className="flex items-center justify-center w-8 h-8 rounded-lg bg-primary/10 text-primary">
214:           <User className="w-4 h-4" />
215:         </div>
216:         <div>
217:           <h2 className="text-lg font-semibold">创作配置</h2>
218:           <p className="text-sm text-muted-foreground">
219:             {mode === "video"
220:               ? "选择人设风格，AI 将基于热点大纲生成视频脚本"
221:               : "选择人设风格，AI 将基于热点大纲生成 800 字深度文案"}
222:           </p>
223:         </div>
224:       </div>
225: 
226:       {/* Selected Topic Display */}
227:       <div className="p-4 rounded-lg bg-primary/5 border border-primary/20">
228:         <div className="flex items-center justify-between">
229:           <div>
230:             <span className="text-xs font-medium text-primary">已选话题</span>
231:             <h3 className="font-medium text-foreground mt-1">{selectedTopic.title}</h3>
232:           </div>
233:           {selectedTopic.outline.length > 0 && (
234:             <Badge variant="secondary" className="shrink-0">
235:               {selectedTopic.outline.length} 个大纲点
236:             </Badge>
237:           )}
238:         </div>
239:         {selectedTopic.outline.length > 0 && (
240:           <div className="mt-3 pt-3 border-t border-primary/10">
241:             <p className="text-xs font-medium text-muted-foreground mb-2">
242:               参考大纲
243:             </p>
244:             <ul className="space-y-1">
245:               {selectedTopic.outline.slice(0, 3).map((point, i) => (
246:                 <li key={i} className="text-sm text-foreground/80 flex items-start gap-2">
247:                   <span className="text-primary shrink-0">{i + 1}.</span>
248:                   {point}
249:                 </li>
250:               ))}
251:               {selectedTopic.outline.length > 3 && (
252:                 <li className="text-sm text-muted-foreground">
253:                   ... 还有 {selectedTopic.outline.length - 3} 个
254:                 </li>
255:               )}
256:             </ul>
257:           </div>
258:         )}
259:       </div>
260: 
261:       {/* Regenerate Warning */}
262:       {generatedContent && (
263:         <div className="flex items-center gap-2 p-3 rounded-lg bg-amber-50 dark:bg-amber-900/20 text-amber-700 dark:text-amber-300">
264:           <AlertTriangle className="w-4 h-4 shrink-0" />
265:           <span className="text-sm">重新生成将清除后续步骤的所有素材</span>
266:         </div>
267:       )}
268: 
269:       {/* Persona Selection */}
270:       <div className="grid gap-4 sm:grid-cols-2">
271:         <div className="space-y-2">
272:           <label className="text-sm font-medium text-foreground">赛道</label>
273:           <Select
274:             value={selectedCategory}
275:             onValueChange={(v) => {
276:               setSelectedCategory(v);
277:               setSelectedPersona("");
278:             }}
279:           >
280:             <SelectTrigger className="h-10 bg-secondary/50 border-0">
281:               <SelectValue placeholder="选择赛道" />
282:             </SelectTrigger>
283:             <SelectContent>
284:               {categories.map((cat) => (
285:                 <SelectItem key={cat} value={cat}>
286:                   {cat}
287:                 </SelectItem>
288:               ))}
289:               <SelectItem value="自定义">自定义</SelectItem>
290:             </SelectContent>
291:           </Select>
292:         </div>
293: 
294:         {selectedCategory !== "自定义" ? (
295:           <div className="space-y-2">
296:             <label className="text-sm font-medium text-foreground">人设</label>
297:             <Select value={selectedPersona} onValueChange={setSelectedPersona}>
298:               <SelectTrigger className="h-10 bg-secondary/50 border-0">
299:                 <SelectValue placeholder="选择人设" />
300:               </SelectTrigger>
301:               <SelectContent>
302:                 {currentPersonas.map((p) => (
303:                   <SelectItem key={p.name} value={p.name}>
304:                     {p.name}
305:                   </SelectItem>
306:                 ))}
307:               </SelectContent>
308:             </Select>
309:           </div>
310:         ) : (
311:           <div className="space-y-2">
312:             <label className="text-sm font-medium text-foreground">人设风格</label>
313:             <Input
314:               value={customPersona}
315:               onChange={(e) => setCustomPersona(e.target.value)}
316:               placeholder="治愈系姐姐 / 毒舌闺蜜 ..."
317:               className="h-10 bg-secondary/50 border-0"
318:             />
319:           </div>
320:         )}
321:       </div>
322: 
323:       {/* Show Persona Prompt */}
324:       {selectedPersonaData && (
325:         <Collapsible open={showPrompt} onOpenChange={setShowPrompt}>
326:           <CollapsibleTrigger asChild>
327:             <Button variant="ghost" size="sm" className="gap-1 text-muted-foreground">
328:               <ChevronRight
329:                 className={cn(
330:                   "w-4 h-4 transition-transform",
331:                   showPrompt && "rotate-90"
332:                 )}
333:               />
334:               查看人设 Prompt
335:             </Button>
336:           </CollapsibleTrigger>
337:           <CollapsibleContent>
338:             <motion.div
339:               initial={{ opacity: 0, y: -10 }}
340:               animate={{ opacity: 1, y: 0 }}
341:               className="mt-2 p-3 rounded-lg bg-secondary/50"
342:             >
343:               <pre className="text-xs text-muted-foreground whitespace-pre-wrap font-mono">
344:                 {selectedPersonaData.prompt}
345:               </pre>
346:             </motion.div>
347:           </CollapsibleContent>
348:         </Collapsible>
349:       )}
350: 
351:       {/* Reference URL */}
352:       <div className="space-y-2">
353:         <label className="text-sm font-medium text-foreground flex items-center gap-2">
354:           <Link2 className="w-4 h-4" />
355:           参考链接（可选）
356:         </label>
357:         <Input
358:           value={referenceUrl}
359:           onChange={(e) => setReferenceUrl(e.target.value)}
360:           placeholder="https://xiaohongshu.com/..."
361:           className="h-10 bg-secondary/50 border-0"
362:         />
363:         <p className="text-xs text-muted-foreground">
364:           输入小红书笔记链接，AI 将参考其风格进行创作
365:         </p>
366:       </div>
367: 
368:       {/* Advanced Settings */}
369:       <div className="space-y-4 p-4 rounded-lg bg-secondary/30 border border-border/50">
370:         <h3 className="text-sm font-medium text-foreground flex items-center gap-2">
371:           <Thermometer className="w-4 h-4" />
372:           高级设置
373:         </h3>
374: 
375:         {/* Temperature Slider */}
376:         <div className="space-y-3">
377:           <div className="flex items-center justify-between">
378:             <label className="text-sm text-muted-foreground">
379:               创意度 (Temperature)
380:             </label>
381:             <span className="text-sm font-mono text-foreground">
382:               {temperature.toFixed(2)}
383:             </span>
384:           </div>
385:           <Slider
386:             value={[temperature]}
387:             onValueChange={(v) => setTemperature(v[0])}
388:             min={0.3}
389:             max={1.0}
390:             step={0.05}
391:             className="w-full"
392:           />
393:           <div className="flex justify-between text-xs text-muted-foreground">
394:             <span>稳定专业 (0.3-0.5)</span>
395:             <span>平衡模式 (0.6-0.8)</span>
396:             <span>创意发散 (0.9-1.0)</span>
397:           </div>
398:         </div>
399: 
400:         {/* Dual Model Toggle */}
401:         <div className="space-y-3 pt-3 border-t border-border/50">
402:           <div className="flex items-center justify-between">
403:             <label className="text-sm text-muted-foreground flex items-center gap-2">
404:               <GitCompare className="w-4 h-4" />
405:               双模型对比生成
406:             </label>
407:             <Button
408:               variant={dualModelMode ? "default" : "outline"}
409:               size="sm"
410:               onClick={() => setDualModelMode(!dualModelMode)}
411:             >
412:               {dualModelMode ? "已启用" : "已禁用"}
413:             </Button>
414:           </div>
415:           
416:           {dualModelMode && (
417:             <motion.div
418:               initial={{ opacity: 0, height: 0 }}
419:               animate={{ opacity: 1, height: "auto" }}
420:               exit={{ opacity: 0, height: 0 }}
421:               className="space-y-3"
422:             >
423:               <div className="flex items-center gap-2 p-3 rounded-lg bg-amber-500/10 border border-amber-500/20">
424:                 <AlertTriangle className="w-4 h-4 text-amber-500 flex-shrink-0" />
425:                 <p className="text-xs text-amber-600 dark:text-amber-400">
426:                   双模型模式将消耗双倍 API 额度
427:                 </p>
428:               </div>
429:               
430:               <div className="grid grid-cols-2 gap-3">
431:                 <div className="space-y-2">
432:                   <label className="text-xs text-muted-foreground">模型 A</label>
433:                   <div className="p-2 rounded bg-primary/10 border border-primary/20">
434:                     <p className="text-xs font-medium truncate">{selectedModel}</p>
435:                   </div>
436:                 </div>
437:                 
438:                 <div className="space-y-2">
439:                   <label className="text-xs text-muted-foreground">模型 B</label>
440:                   <Select 
441:                     value={secondModel} 
442:                     onValueChange={setSecondModel}
443:                     disabled={availableModels.length === 0}
444:                   >
445:                     <SelectTrigger className="h-9 text-xs bg-secondary/50 border-0">
446:                       <SelectValue placeholder={
447:                         availableModels.length === 0 
448:                           ? "加载模型列表..." 
449:                           : "选择第二个模型"
450:                       } />
451:                     </SelectTrigger>
452:                     <SelectContent>
453:                       {availableModels.length === 0 ? (
454:                         <SelectItem value="__loading__" disabled>
455:                           加载中...
456:                         </SelectItem>
457:                       ) : availableModels.filter((m) => m.value !== selectedModel).length === 0 ? (
458:                         <SelectItem value="__no_options__" disabled>
459:                           无可用模型
460:                         </SelectItem>
461:                       ) : (
462:                         availableModels
463:                           .filter((m) => m.value !== selectedModel)
464:                           .map((model) => (
465:                             <SelectItem key={model.value} value={model.value}>
466:                               {model.label}
467:                             </SelectItem>
468:                           ))
469:                       )}
470:                     </SelectContent>
471:                   </Select>
472:                 </div>
473:               </div>
474:             </motion.div>
475:           )}
476:         </div>
477:       </div>
478: 
479:       {/* Generation Progress */}
480:       {generationSteps.length > 0 && (
481:         <motion.div
482:           initial={{ opacity: 0, height: 0 }}
483:           animate={{ opacity: 1, height: "auto" }}
484:           exit={{ opacity: 0, height: 0 }}
485:           className="p-6 rounded-xl border bg-card"
486:         >
487:           <StepProgress steps={generationSteps} />
488:         </motion.div>
489:       )}
490: 
491:       {/* Generate Button */}
492:       <Button
493:         onClick={handleGenerate}
494:         disabled={isGenerating || !getPersonaPrompt()}
495:         size="lg"
496:         className="w-full gap-2"
497:       >
498:         {isGenerating ? (
499:           <>
500:             <Loader2 className="w-4 h-4 animate-spin" />
501:             {mode === "video" ? "生成视频脚本中..." : "生成图文内容中..."}
502:           </>
503:         ) : (
504:           <>
505:             <Sparkles className="w-4 h-4" />
506:             开始生成
507:           </>
508:         )}
509:       </Button>
510:     </section>
511:   );
512: }
</file>

<file path="modules/writer.py">
  1: """
  2: 文案与设计模块 (LLM via OpenRouter)
  3: """
  4: import os
  5: import json
  6: import re
  7: from pathlib import Path
  8: from dotenv import load_dotenv
  9: from openai import OpenAI
 10: 
 11: from modules.monitor import log_api_call, log_generation
 12: from modules.quality_checker import check_content_quality, format_quality_report
 13: 
 14: # 加载项目根目录的 .env 文件
 15: _project_root = Path(__file__).parent.parent
 16: load_dotenv(_project_root / ".env")
 17: 
 18: # OpenRouter 客户端（延迟初始化）
 19: _client = None
 20: 
 21: def get_openrouter_client():
 22:     """延迟初始化 OpenRouter 客户端"""
 23:     global _client
 24:     if _client is None:
 25:         api_key = os.getenv("OPENROUTER_API_KEY")
 26:         if not api_key:
 27:             raise ValueError("OPENROUTER_API_KEY 环境变量未设置，请在 .env 文件中配置")
 28:         _client = OpenAI(
 29:             base_url="https://openrouter.ai/api/v1",
 30:             api_key=api_key,
 31:         )
 32:     return _client
 33: 
 34: 
 35: def _fix_json_newlines(text: str) -> str:
 36:     """修复 JSON 字符串值中的裸换行符（简化版，双引号由 Prompt 控制）"""
 37:     result = []
 38:     in_string = False
 39:     escape = False
 40:     for char in text:
 41:         if escape:
 42:             result.append(char)
 43:             escape = False
 44:         elif char == '\\':
 45:             result.append(char)
 46:             escape = True
 47:         elif char == '"':
 48:             result.append(char)
 49:             in_string = not in_string
 50:         elif char == '\n' and in_string:
 51:             result.append('\\n')
 52:         else:
 53:             result.append(char)
 54:     return ''.join(result)
 55: 
 56: 
 57: def _call_llm_and_parse(system_prompt: str, user_content: str, topic: str, persona: str, model_name: str = "deepseek/deepseek-chat", temperature: float = 0.8) -> dict:
 58:     """内部函数：调用 LLM 并解析 JSON 响应"""
 59:     response = get_openrouter_client().chat.completions.create(
 60:         model=model_name,
 61:         max_tokens=8192,
 62:         temperature=temperature,
 63:         messages=[
 64:             {"role": "system", "content": system_prompt},
 65:             {"role": "user", "content": user_content}
 66:         ]
 67:     )
 68:     
 69:     # 记录 API 调用
 70:     usage = response.usage
 71:     if usage:
 72:         log_api_call(model_name, usage.prompt_tokens, usage.completion_tokens)
 73:     
 74:     text = response.choices[0].message.content
 75:     
 76:     # 提取 JSON（处理可能的 markdown 代码块）
 77:     json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
 78:     if json_match:
 79:         text = json_match.group(1)
 80:     
 81:     # 移除所有代码块（如果 LLM 误输出了代码）
 82:     # 保留 JSON 对象部分（以 { 开头）
 83:     if not text.strip().startswith('{'):
 84:         # 尝试找到第一个 { 开始的 JSON
 85:         json_obj_match = re.search(r'\{[\s\S]*\}', text)
 86:         if json_obj_match:
 87:             text = json_obj_match.group(0)
 88:     
 89:     # 兜底：修复可能存在的裸换行符
 90:     text = _fix_json_newlines(text)
 91:     
 92:     try:
 93:         result = json.loads(text)
 94:         # 记录生成历史
 95:         log_generation(
 96:             topic=topic,
 97:             persona=persona or "通用博主",
 98:             titles=result.get("titles", []),
 99:             content_preview=result.get("content", "")[:200]
100:         )
101:         return result
102:     except json.JSONDecodeError as e:
103:         print(f"\n{'='*60}")
104:         print(f"[Writer Error] JSON 解析失败")
105:         print(f"{'='*60}")
106:         print(f"错误详情: {e}")
107:         print(f"错误位置: 第 {e.lineno} 行，第 {e.colno} 列")
108:         print(f"\n完整响应内容（前500字符）:")
109:         print(f"{text[:500]}")
110:         print(f"\n完整响应内容（后200字符）:")
111:         print(f"{text[-200:]}")
112:         print(f"\n响应总长度: {len(text)} 字符")
113:         print(f"{'='*60}\n")
114:         # 抛出异常而不是返回空数据
115:         raise ValueError(f"LLM 返回格式错误，请检查日志。预览: {text[:200]}")
116: 
117: 
118: def generate_image_note(topic: str, persona: str = None, reference_text: str = None, model_name: str = "deepseek/deepseek-chat", search_data: dict = None, temperature: float = 0.8) -> dict:
119:     """
120:     【图文模式】生成小红书图文笔记（长文案 + 配图提示词）
121:     
122:     Args:
123:         topic: 选题/主题
124:         persona: 博主人设风格描述
125:         reference_text: 参考内容（用于仿写）
126:         model_name: OpenRouter 模型 ID
127:         search_data: websearch 返回的完整热点数据，包含 title/source/summary/outline/why_hot
128:     
129:     Returns:
130:         {
131:             'titles': [...],           # 5个备选标题
132:             'content': '...',          # 深度正文（800字以上）
133:             'image_designs': [         # 配图设计（2-6张）
134:                 {
135:                     'index': 1,
136:                     'description': '中文画面描述',
137:                     'prompt': '生图提示词'
138:                 },
139:                 ...
140:             ]
141:         }
142:     """
143:     reference_section = ""
144:     if reference_text:
145:         reference_section = f"""
146: 参考内容（请仿写其结构和风格）：
147: ---
148: {reference_text}
149: ---
150: """
151: 
152:     # 解析 search_data
153:     search_data = search_data or {}
154:     source = search_data.get('source', '未知来源')
155:     original_title = search_data.get('title', topic)
156:     why_hot = search_data.get('why_hot', '')
157:     summary = search_data.get('summary', '')
158:     outline = search_data.get('outline', [])
159:     
160:     # 格式化大纲
161:     outline_text = ""
162:     if outline and len(outline) > 0:
163:         outline_text = json.dumps(outline, indent=2, ensure_ascii=False)
164: 
165:     # 【深度演绎模式】System Prompt - 骨架生肉
166:     system_prompt = f"""你是小红书{persona or '深度内容博主'}赛道的顶级博主。
167: 你现在拿到了一份热门选题的调研报告，你需要基于这份【大纲】，创作一篇**深度、详实、不少于800字**的爆款笔记。
168: 
169: 【🚫 严禁行为】
170: 1. 严禁简单扩写大纲。如果大纲是"多喝水"，你不能只写"我们要多喝水"，你必须写"我见过太多女生皮肤差是因为喝水方式不对，正确的喝水时间表是..."
171: 2. 严禁车轱辘话来回说。
172: 3. 严禁字数不足。
173: 
174: 【⚡️ 深度扩充法则 (Deep Expansion Protocol)】
175: 针对大纲中的每一个点，你必须执行"三步走"策略来填充内容：
176: 
177: **第一步：观点升维 (Insight)**
178:   - 不要只陈述事实，要给出一个反直觉的、或者带有强烈个人色彩的判断。
179:   - 结合火爆原因中的痛点，点出用户真正在乎的东西。
180: 
181: **第二步：案例/场景植入 (Scenario)**
182:   - **必须脑补一个具体场景**。
183:   - 使用"我有一个朋友..."、"上次面试时..."、"我复盘了上个月的数据..."这种句式。
184:   - 细节要具体到：数字、时间、地点、对话。
185: 
186: **第三步：落地实操 (Actionable Advice)**
187:   - 给出具体的 SOP、话术模板或避坑指南。
188:   - 这一部分必须包含 `1. 2. 3.` 的列表项。
189: 
190: 【文章结构要求】
191: 1. **标题**：结合原始标题和火爆原因，起 5 个更具吸引力的标题。
192: 2. **正文**：
193:    - 开头：引用核心摘要中的冲突点，直接炸场。
194:    - 中间：遍历参考大纲，**每个点至少展开写 150-200 字**。
195:    - 结尾：强力升华，引导互动。
196: 
197: 【活人感写作指南】
198: 1. **开头即炸裂**：第一句必须是强情绪宣泄、反直觉结论或具体的场景描述。
199: 2. **口语化 & 碎碎念**：多用短句，适度重复表达激动，善用括号补充内心戏。
200: 3. **排版呼吸感**：每段不超过 3 行，关键金句独立成段，善用 Emoji 作为情绪标点。
201: 
202: 【严禁 AI 味套话 - 质量红线】
203: 以下表达一旦出现立即判定为不合格：
204: - "众所周知"、"不得不说"、"可以说是"、"值得一提的是"
205: - "在...方面"、"进行...操作"、"相关的..."
206: - 空洞总结："总而言之"、"综上所述"、"由此可见"
207: - 没有具体数字和时间的泛化描述（"很多"、"大量"、"经常"）
208: - 机械式列举："首先...其次...最后..."（必须用口语化连接）
209: 
210: 【真实博主自检清单 - 必须全部满足】
211: ✓ 至少 2 处具体数字（如：涨粉 3000、连续 15 天、花了 2 小时）
212: ✓ 至少 1 处个人经历（我/我朋友/我同事的真实故事）
213: ✓ 至少 3 处强情绪词（绝了/太爱了/崩溃/yyds/救命）
214: ✓ 对话或内心独白至少 1 次（"我当时就想..."、"老板说..."）
215: ✓ 至少 1 处反问或自问自答（"你知道为什么吗？"、"是不是很离谱？"）
216: 
217: 【配图设计要求】
218: 设计 2-6 张配图，每张配图独立表达一个视觉主题。
219: 
220: **穿搭风格要求**（职场主题）：
221: - ✓ 推荐：针织衫、衬衫、T恤、牛仔裤、半身裙、休闲外套
222: - ✗ 避免：正式西装、职业套装、领带、高跟鞋
223: 
224: **背景场景要求**（职场主题）：
225: - ✓ 推荐：现代办公室（开放式）、咖啡厅、休息区、会议室、窗边
226: - ✓ 要求：真实感场景，自然光照，生活化氛围
227: - ✗ 避免：过于正式的会议室、传统办公桌
228: 
229: **图片生成字段要求**：
230: 1. description：中文描述画面主体、穿搭、场景、氛围，说明该图在文章中承担的角色
231: 2. sentiment：图片风格情感，职场主题建议使用"职场日常"
232: 3. prompt：生图提示词，必须包含：
233:    - 人物：二次元女性角色
234:    - 穿搭：具体描述（如"wearing casual cardigan and jeans"）
235:    - 背景：具体场景（如"modern office with large windows"）
236:    - 光照：natural lighting
237: 4. cover_text（仅第一张主图需要）：3-8个汉字的核心文案，用于叠加显示
238:    - 要求：提炼文章核心观点或最吸睛的一句话
239:    - 示例："职场穿搭自由"、"拒绝内耗"、"年终奖攻略"
240: 
241: 【输出格式】
242: 必须严格按照以下 JSON 结构输出，不要输出任何其他内容：
243: 
244: **重要**：对话和引用必须使用中文引号「」，禁止使用英文双引号 "
245: 示例：❌ "老板说："加油""  ✅ "老板说：「加油」"
246: 
247: {{
248:     "titles": ["标题1", "标题2", "标题3", "标题4", "标题5"],
249:     "content": "不少于800字的深度正文内容，分段并包含emoji，用\\n表示换行，对话用中文引号「」",
250:     "image_designs": [
251:         {{
252:             "index": 1,
253:             "description": "封面图：职场女性角色，穿休闲针织衫和牛仔裤，站在现代办公室窗边",
254:             "sentiment": "职场日常",
255:             "prompt": "anime style office girl wearing casual cardigan and jeans, modern office background with large windows, natural lighting",
256:             "cover_text": "职场穿搭自由"
257:         }},
258:         {{
259:             "index": 2,
260:             "description": "配图描述",
261:             "sentiment": "职场日常",
262:             "prompt": "配图提示词"
263:         }}
264:     ]
265: }}
266: 
267: 【写作规则】
268: 1. 标题要有爆款潜力，使用数字、疑问句、惊叹句等吸睛技巧
269: 2. 正文必须深度详实，**字数不少于800字**，不能敷衍了事
270: 3. image_designs 数组包含 2-6 个元素
271: 4. **第一张图片（主图）必须包含 cover_text 字段**：3-8个汉字的核心文案
272: 5. 配图（第2-6张）不需要 cover_text 字段
273: 6. JSON 字符串中必须用 \\n 表示换行，不要使用实际换行符"""
274: 
275:     # 【深度演绎模式】User Prompt - 数据注入
276:     user_content = f"""当前热门选题信息如下：
277: - 来源平台：{source}
278: - 原始标题：{original_title}
279: - 火爆原因：{why_hot}
280: - 核心摘要：{summary}
281: - 参考大纲：
282: {outline_text}
283: 
284: {reference_section}
285: 请基于以上信息，按照 System Prompt 中的【深度扩充法则】，将这篇笔记扩写至 800 字以上。
286: 哪怕大纲只有一句话，你也要通过举例、讲故事、列步骤，将其丰富成一段有血有肉的内容。
287: 只输出 JSON，不要其他内容。"""
288: 
289:     return _call_llm_and_parse(system_prompt, user_content, topic, persona, model_name, temperature)
290: 
291: 
292: def generate_video_script(topic: str, persona: str = None, reference_text: str = None, model_name: str = "deepseek/deepseek-chat", temperature: float = 0.8) -> dict:
293:     """
294:     【视频模式】生成深度视频脚本（口播文稿 + 分镜画面 + 情感分析）
295:     
296:     采用"中视频"策略：时长不限，以把逻辑讲清楚为最高优先级。
297:     使用高频分镜防止视觉疲劳，每段解说词 20-40 字。
298:     
299:     Args:
300:         topic: 选题/主题
301:         persona: 博主人设风格描述
302:         reference_text: 参考内容（用于仿写）
303:     
304:     Returns:
305:         {
306:             'titles': [...],           # 5个备选标题
307:             'content': '...',          # 视频简介（200-300字）
308:             'visual_scenes': [         # 分镜列表（20-50个，高频分镜）
309:                 {
310:                     'scene_index': 1,
311:                     'narration': '该分镜对应的口播解说词（20-40字）',
312:                     'description': '中文画面描述',
313:                     'sentiment': '情感基调',
314:                     'prompt': '纯画面描述（不含风格词）'
315:                 },
316:                 ...
317:             ]
318:         }
319:     """
320:     reference_section = ""
321:     if reference_text:
322:         reference_section = f"""
323: 参考内容（请仿写其结构和风格）：
324: ---
325: {reference_text}
326: ---
327: """
328: 
329:     system_prompt = f"""你是**顶级纪录片导演**，同时精通 AI 绘图提示词工程和情感分析。
330: 你的核心能力是将"文案"翻译成"视觉画面"，并准确判断每段内容的情感基调。
331: 你的风格是：{persona or '通用博主'}
332: 
333: 【核心任务】
334: 基于用户给定的选题创作一个**深度解析视频脚本**，包含视频简介和高频分镜脚本。
335: **时长不限**，以把逻辑讲清楚、把干货讲透彻为**最高优先级**。
336: 
337: 【深度视频创作原则】
338: 1. **宁多勿长**：不要让一张图片停留超过 8 秒。如果解说词很长，必须切分成多个画面来表达。
339: 2. **逻辑可视化**：当解说词在讲"原理"时，画面要画"流程图"或"示意图"；当讲"案例"时，画面要画"场景图"。
340: 3. **内容为王**：不需要为了凑时间说废话，但必须把核心干货的 Why 和 How 解释得连小学生都能听懂。
341: 
342: 【视频简介要求】
343: 1. 字数目标：200-300汉字
344: 2. 内容：视频主题概述，说明观众能学到什么
345: 3. 风格：有深度、有吸引力、带emoji
346: 
347: 【分镜脚本要求 - 高频分镜策略】
348: 你需要像**电影导演**一样，把内容拆解为 **20-50 个高频分镜**。
349: 核心原则：讲完一个知识点或换气时，必须切换下一个分镜。
350: 
351: 1. narration（口播解说词）- **高频切换原则**：
352:    - 每段控制在 **20-40 个汉字**（约 5-8 秒）
353:    - 必须**完全口语化**，像博主在面对面聊天
354:    - 多用连接词："大家看"、"注意这里"、"之所以这么做"、"换句话说"、"举个例子"
355:    - 所有分镜的 narration 连起来，是一段完整流畅的视频解说词
356:    
357:    **错误示范**：一个分镜包含"这里有三个步骤，第一步是...第二步是...第三步是..."（❌ 太长，应该拆成多个分镜）
358:    **正确示范**：
359:    - 分镜1："这里主要有三个核心步骤，我一个一个来讲。"
360:    - 分镜2："首先是第一步，我们需要找到设置入口。"
361:    - 分镜3："大家注意看这个按钮，点进去之后..."
362:    
363: 2. description（画面描述）：
364:    - 中文描述画面主体、场景、氛围
365:    
366: 3. sentiment（情感基调）- **必须从以下5个选项中选择一个**：
367:    - "可爱治愈"：温馨、软萌、治愈系内容
368:    - "严肃深度"：深刻、专业、知识型内容
369:    - "日常生活"：平常、自然、slice of life
370:    - "热血励志"：激励、奋斗、正能量
371:    - "悲伤低沉"：伤感、感慨、怀旧
372:    
373: 4. prompt（生图提示词）- **中文纯净画面描述**：
374:    - **必须使用中文**描述画面（豆包模型对中文理解最好）
375:    - 只描述画面内容：主体 + 动作 + 场景 + 光影
376:    - **严禁出现任何文字元素**：不要描写招牌、对话框、字幕、logo、水印
377:    - **禁止添加风格词**（如 动漫风格, 4k, 高清 等），风格由画家模块添加
378:    - 画面要干净、构图高级
379: 
380: 【视觉翻译公式 - 必须严格遵守】
381: 根据 narration 内容类型，设计中文纯净画面描述的 prompt：
382: 
383: 1. **具体事物**（如：多吃苹果）
384:    -> 画具象物体：一颗红苹果特写，表面带水珠，柔和自然光
385:    
386: 2. **抽象概念**（如：职场压力大、坚持长期主义）
387:    -> 画具象隐喻：登山者在雪山顶峰插旗，逆光剪影，金色晚霞
388:    -> 或：疲惫的上班族双手抱头，电脑屏幕蓝光照亮面庞，深夜办公室
389:    
390: 3. **流程步骤**（如：分三步完成）
391:    -> 画流程图示：三个圆形图标排列，箭头连接，简洁示意图风格
392:    
393: 4. **情绪表达**（如：太开心了、好激动）
394:    -> 画表情特写：年轻女孩灿烂笑容，阳光洒落，温暖氛围
395: 
396: **错误示范**：prompt "一个人在思考，画面有'加油'文字"（❌ 不要有文字元素）
397: **正确示范**：prompt "马拉松选手冲过终点线，日出背景，胜利表情，暖色调"（✅ 中文纯净画面）
398: 
399: 【输出格式】
400: 必须严格按照以下 JSON 结构输出，不要输出任何其他内容：
401: 
402: **重要**：对话和引用必须使用中文引号「」，禁止使用英文双引号 "
403: 
404: {{
405:     "titles": ["标题1", "标题2", "标题3", "标题4", "标题5"],
406:     "content": "200-300字视频简介，带emoji，对话用中文引号「」",
407:     "visual_scenes": [
408:         {{
409:             "scene_index": 1,
410:             "narration": "20-40字口播词（口语化，像聊天）",
411:             "description": "中文画面描述：主体、场景、感觉",
412:             "sentiment": "可爱治愈",
413:             "prompt": "中文纯净画面描述（无文字元素、无风格词）"
414:         }},
415:         {{
416:             "scene_index": 2,
417:             "narration": "20-40字口播词",
418:             "description": "中文画面描述",
419:             "sentiment": "严肃深度",
420:             "prompt": "中文具象化画面描述"
421:         }}
422:     ]
423: }}
424: 
425: 【写作规则】
426: 1. 标题要有爆款潜力，使用数字、疑问句、惊叹句等吸睛技巧
427: 2. visual_scenes 数组包含 **20-50 个元素**，根据内容复杂度灵活调整
428: 3. JSON 字符串中必须用 \\n 表示换行，不要使用实际换行符
429: 4. 分镜的 narration 连起来要有逻辑性，像一个完整的深度讲解视频
430: 5. 每个 prompt 必须是中文，描述纯净画面，**绝对不能有任何文字/招牌/logo**
431: 6. sentiment 必须从5个选项中选择，根据该段 narration 的情感氛围判断
432: 7. **内容深度优先**：宁可多几个分镜把事情讲清楚，也不要为了短而省略关键信息"""
433: 
434:     user_content = f"""选题：{topic}
435: {reference_section}
436: 请创作深度解析视频脚本（时长不限，把逻辑讲清楚为第一优先级）。只输出 JSON，不要其他内容。"""
437: 
438:     return _call_llm_and_parse(system_prompt, user_content, topic, persona, model_name, temperature)
439: 
440: 
441: def generate_wechat_article(topic: str, persona: str = None, reference_text: str = None, model_name: str = "deepseek/deepseek-chat", search_data: dict = None, temperature: float = 0.8) -> dict:
442:     """
443:     【公众号模式】生成深度长文 + 架构图/示意图
444:     
445:     Args:
446:         topic: 选题/主题
447:         persona: 技术博主人设风格描述
448:         reference_text: 参考内容（用于仿写）
449:         model_name: OpenRouter 模型 ID
450:         search_data: websearch 返回的完整热点数据
451:         temperature: LLM 温度参数
452:     
453:     Returns:
454:         {
455:             'titles': [...],           # 5个备选标题
456:             'content': '...',          # 深度长文（不限字数，建议2000-5000字）
457:             'diagrams': [              # 架构图/示意图设计（2-4张）
458:                 {
459:                     'index': 1,
460:                     'title': '架构图标题',
461:                     'description': '中文描述该图表达的技术架构',
462:                     'diagram_type': 'architecture' | 'flow' | 'comparison',
463:                     'prompt': '生图提示词（极客美学）'
464:                 },
465:                 ...
466:             ]
467:         }
468:     """
469:     reference_section = ""
470:     if reference_text:
471:         reference_section = f"""
472: 参考内容（请仿写其结构和风格）：
473: ---
474: {reference_text}
475: ---
476: """
477: 
478:     # 解析 search_data
479:     search_data = search_data or {}
480:     source = search_data.get('source', '未知来源')
481:     original_title = search_data.get('title', topic)
482:     why_hot = search_data.get('why_hot', '')
483:     summary = search_data.get('summary', '')
484:     outline = search_data.get('outline', [])
485:     
486:     # 格式化大纲
487:     outline_text = ""
488:     if outline and len(outline) > 0:
489:         outline_text = json.dumps(outline, indent=2, ensure_ascii=False)
490: 
491:     system_prompt = f"""你是{persona or '技术博主'}，专注于深度技术内容创作。
492: 你现在要为微信公众号创作一篇**深度技术长文**，字数不限，以把技术讲透为第一优先级。
493: 
494: 【核心要求】
495: 1. **深度优先**：必须符合'金字塔原理'，结构为：背景/痛点 → 现有方案局限 → 深度原理拆解 → 架构设计/代码思路 → 商业/未来价值
496: 2. **工程视角**：不仅讲算法原理，还要讲部署、成本、延迟优化、工程取舍
497: 3. **对比分析**：必须有 Pros & Cons 对比，或技术方案 A vs B 的横向对比
498: 4. **通俗化表达**：用类比和日常例子解释复杂概念（如：用'传话游戏'解释Transformer的Self-Attention机制）
499: 
500: 【文章结构要求】
501: 1. **标题**：硬核且吸引人，必须包含技术关键词。示例：《RAG已死？深度解析Long Context的工程边界》
502: 2. **正文**：
503:    - 开头：抛出技术痛点或反直觉观点
504:    - 中间：分层递进拆解（Why → What → How）
505:    - 结尾：总结技术价值和未来展望
506:    - **代码处理**：可以用文字描述代码逻辑，不要输出实际代码块
507: 3. **排版**：使用小标题（二级标题 ##）分段，关键概念**加粗**
508: 
509: 【架构图设计要求】
510: 必须设计 2-4 张架构图/示意图，用于可视化技术架构。
511: 
512: 每张图需包含：
513: 1. title：图表标题（如："RAG架构对比"）
514: 2. description：中文描述该图表达的技术概念、组件关系
515: 3. diagram_type：图表类型
516:    - "architecture"：系统架构图（组件、模块、数据流）
517:    - "flow"：流程图（步骤、决策树、时序）
518:    - "comparison"：对比图（方案A vs B，优缺点对比）
519: 4. prompt：生图提示词（极客美学风格）
520:    - 必须包含：cyberpunk style, dark background, neon accents
521:    - 描述具体的技术组件、连接关系、数据流向
522:    - 示例："cyberpunk system architecture, RAG pipeline with vector database, embedding model, and LLM, glowing data connections, dark blue background, neon highlights"
523: 
524: 【输出格式 - 严格遵守】
525: **重要**：必须且只能输出纯 JSON 对象，不要用 ```json 包裹，不要输出任何代码块。
526: 
527: **JSON 规范**：对话和引用必须使用中文引号「」，禁止使用英文双引号 "
528: 示例：❌ "老板说："加油""  ✅ "老板说：「加油」"
529: 
530: 输出格式：
531: {{
532:     "titles": ["标题1（必须包含技术关键词）", "标题2", "标题3", "标题4", "标题5"],
533:     "content": "深度技术长文，不限字数，建议2000-5000字，用\\n表示换行，**关键概念**用markdown加粗，对话用中文引号「」。可以在文字中描述代码逻辑，但不要输出实际的 ```python 代码块。",
534:     "diagrams": [
535:         {{
536:             "index": 1,
537:             "title": "架构图标题",
538:             "description": "中文描述该图表达的技术架构和组件关系",
539:             "diagram_type": "architecture",
540:             "prompt": "cyberpunk style system architecture, 具体组件描述, dark background, neon accents"
541:         }}
542:     ]
543: }}
544: 
545: **错误示范**（绝对禁止）：
546: ```json
547: {{...}}
548: ```
549: 或者输出代码块：
550: ```python
551: 代码...
552: ```
553: 
554: **正确示范**：
555: 直接输出 {{"titles": [...], "content": "...", "diagrams": [...]}}
556: 
557: 【写作规则】
558: 1. 标题要有技术深度和吸引力，避免标题党
559: 2. 正文必须深度详实，**建议2000-5000字**，把技术讲透
560: 3. diagrams 数组包含 2-4 个元素
561: 4. 每个 diagram 的 prompt 必须符合极客美学：深色背景、霓虹色、赛博朋克风格
562: 5. JSON 字符串中必须用 \\n 表示换行，不要使用实际换行符
563: 6. **绝对禁止**：不要输出 ```json、```python 等代码块，直接输出纯 JSON 对象"""
564: 
565:     user_content = f"""当前技术选题信息如下：
566: - 来源平台：{source}
567: - 原始标题：{original_title}
568: - 火爆原因：{why_hot}
569: - 核心摘要：{summary}
570: - 参考大纲：
571: {outline_text}
572: 
573: {reference_section}
574: 请创作一篇微信公众号深度技术文章，把这个技术话题讲透彻。
575: 
576: **重要提醒**：
577: 1. 直接输出 JSON 对象，不要用 ```json 包裹
578: 2. 不要输出任何代码块（```python、```yaml 等）
579: 3. 代码逻辑用文字描述即可
580: 4. 只输出纯 JSON，格式如：{{"titles": [...], "content": "...", "diagrams": [...]}}"""
581: 
582:     return _call_llm_and_parse(system_prompt, user_content, topic, persona, model_name, temperature)
583: 
584: 
585: def generate_note_package(topic: str, persona: str = None, reference_text: str = None, mode: str = "image", model_name: str = "deepseek/deepseek-chat", search_data: dict = None, temperature: float = 0.8) -> dict:
586:     """
587:     统一入口：根据模式生成内容
588:     
589:     Args:
590:         topic: 选题/主题
591:         persona: 博主人设风格描述
592:         reference_text: 参考内容
593:         mode: "image"（图文模式）、"video"（视频模式）或 "wechat"（公众号模式）
594:         model_name: OpenRouter 模型 ID
595:         search_data: websearch 返回的完整热点数据
596:     
597:     Returns:
598:         对应模式的内容结构
599:     """
600:     if mode == "video":
601:         return generate_video_script(topic, persona, reference_text, model_name, temperature)
602:     elif mode == "wechat":
603:         return generate_wechat_article(topic, persona, reference_text, model_name, search_data, temperature)
604:     else:
605:         return generate_image_note(topic, persona, reference_text, model_name, search_data, temperature)
606: 
607: 
608: def generate_note_package_with_retry(
609:     topic: str,
610:     persona: str = None,
611:     reference_text: str = None,
612:     mode: str = "image",
613:     model_name: str = "deepseek/deepseek-chat",
614:     search_data: dict = None,
615:     temperature: float = 0.8,
616:     max_retries: int = 2,
617:     quality_threshold: int = 70
618: ) -> dict:
619:     """
620:     带质量检测的生成函数
621:     
622:     如果生成的内容质量不达标，会自动重试（降低 temperature 提升稳定性）
623:     
624:     Args:
625:         max_retries: 最大重试次数
626:         quality_threshold: 质量分数阈值（0-100）
627:         其他参数同 generate_note_package
628:     
629:     Returns:
630:         生成结果（同 generate_note_package）
631:     """
632:     current_temp = temperature
633:     
634:     for attempt in range(max_retries + 1):
635:         print(f"[Writer] 生成尝试 {attempt + 1}/{max_retries + 1}，temperature={current_temp:.2f}")
636:         
637:         result = generate_note_package(
638:             topic=topic,
639:             persona=persona,
640:             reference_text=reference_text,
641:             mode=mode,
642:             model_name=model_name,
643:             search_data=search_data,
644:             temperature=current_temp
645:         )
646:         
647:         # 只检测图文模式的正文质量（视频和公众号模式跳过）
648:         if mode == "image" and result.get("content"):
649:             quality = check_content_quality(result["content"])
650:             print(f"[Quality] 评分: {quality['score']}/100")
651:             
652:             if quality["is_acceptable"]:
653:                 print("[Quality] ✅ 质量合格")
654:                 return result
655:             
656:             if attempt < max_retries:
657:                 print(f"[Quality] ❌ 质量不达标 ({quality['score']}分 < {quality_threshold}分)")
658:                 print(f"[Quality] 问题: {', '.join(quality['issues'])}")
659:                 print(f"[Quality] 准备重试...")
660:                 # 降低 temperature 提升稳定性
661:                 current_temp = max(0.5, current_temp - 0.15)
662:             else:
663:                 print(f"[Quality] ⚠️ 已达最大重试次数，返回当前结果")
664:                 print(format_quality_report(quality))
665:         else:
666:             # 视频模式或无内容，直接返回
667:             return result
668:     
669:     return result
</file>

</files>
